{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "# Importing TF and checking the version\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing helper functions\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"NLP_text/train.csv\")\n",
    "test_df = pd.read_csv(\"NLP_text/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking test dataframe\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of training records\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking total number of samples\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Just burst out in actual tears of joy when Cain survived #SummerFate @emmerdale\n",
      "---\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "I WAS PEACEFULLY SITTING IN MY ROOM AND I HEARD THIS LOUD BANG OF SOMETHING FALLING\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "catastrophic-fallen-angel: reveillertm: macabrelolita: I was supposed to write Û÷amino acidsÛª and I nearly... http://t.co/dIoBzGHFju\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "'if you can't summon the flames directly from hell store bought is fine'-me \n",
      "mom-*dies*\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Back in 02 to 03 would never said that 50 would have ended ja like obliteration\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Visualising random samples\n",
    "import random\n",
    "\n",
    "random_index = random.randint(0, len(train_df) - 5)\n",
    "\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index : random_index + 5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size=0.1, # Allocating 10% to validation data\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dataset length\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting text to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using text vectorisation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=None,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=None,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the average number of tokens\n",
    "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up text vectorisation variables\n",
    "max_vocab_length = 10000\n",
    "max_length = 15\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting text vectorisation to the training dataset\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentnence and tokenise it\n",
    "sample_sentence = \"There is a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      ":StarMade: :Stardate 3: :Planetary Annihilation:: http://t.co/I2hHvIUmTm via @YouTube,\n",
      "tokenised version:\n",
      "[[8124 8129  118 9745  796    1   49  114    0    0    0    0    0    0\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenising random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\ntokenised version:\\n{text_vectorizer([random_sentence])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " ['', '[UNK]', 'the', 'a', 'in'],\n",
       " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "\n",
    "len(words_in_vocab), top_5_words, bottom_5_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x2e908771100>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the layer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    input_length=max_length\n",
    ")\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "#coppednews Haunting memories drawn by survivors http://t.co/Wx11d69gEZ,\n",
      "embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.0482146 ,  0.00141467,  0.0006489 , ..., -0.03964548,\n",
       "          0.00649532, -0.01446352],\n",
       "        [ 0.02889968,  0.00261052, -0.01813287, ...,  0.03159357,\n",
       "         -0.00732244, -0.04590104],\n",
       "        [ 0.04569519,  0.019184  , -0.01567925, ..., -0.04832131,\n",
       "         -0.00740236, -0.00515512],\n",
       "        ...,\n",
       "        [-0.02449301,  0.04503146, -0.00013989, ...,  0.04820264,\n",
       "          0.02470479,  0.00629938],\n",
       "        [-0.02449301,  0.04503146, -0.00013989, ...,  0.04820264,\n",
       "          0.02470479,  0.00629938],\n",
       "        [-0.02449301,  0.04503146, -0.00013989, ...,  0.04820264,\n",
       "          0.02470479,  0.00629938]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\nembedded version:\"\n",
    ")\n",
    "\n",
    "# Embed random sentence\n",
    "embed_sentence = embedding(text_vectorizer([random_sentence]))\n",
    "embed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([ 4.82146032e-02,  1.41466781e-03,  6.48904592e-04, -3.17060128e-02,\n",
       "         3.39596979e-02, -1.66074634e-02, -4.27815430e-02,  3.70967276e-02,\n",
       "         4.30469997e-02,  1.70935504e-02, -7.97186047e-03, -2.64096502e-02,\n",
       "        -2.76947152e-02,  4.25736643e-02,  3.00921313e-02,  3.61675024e-03,\n",
       "        -2.64711268e-02,  4.46351208e-02,  1.83727406e-02,  1.63631104e-02,\n",
       "        -3.10757514e-02, -4.00121100e-02,  4.04410101e-02, -2.31368430e-02,\n",
       "         3.30212377e-02, -2.83353683e-02, -2.41894480e-02,  1.55380853e-02,\n",
       "         4.21239771e-02, -4.85050343e-02, -1.21449456e-02, -1.46930590e-02,\n",
       "         1.14526525e-02, -1.98781025e-02, -1.34878047e-02, -4.26018611e-02,\n",
       "         3.04788686e-02, -1.39357671e-02, -4.50526848e-02, -3.62474918e-02,\n",
       "        -3.73585150e-03, -2.60752439e-02, -4.68716137e-02, -2.49554161e-02,\n",
       "        -1.95369255e-02, -3.43961343e-02, -4.15502675e-02, -1.72795169e-02,\n",
       "         2.75067203e-02,  4.52498235e-02,  4.04786505e-02, -2.54372954e-02,\n",
       "        -2.38896534e-03, -2.32781898e-02,  2.36021169e-02, -1.13863833e-02,\n",
       "         2.68682502e-02, -2.01747417e-02,  4.85526212e-02,  1.14652291e-02,\n",
       "        -4.04612198e-02,  2.69715302e-02, -1.58545971e-02, -2.36952789e-02,\n",
       "         1.74033754e-02,  3.16608660e-02, -4.72462550e-02, -2.58141756e-02,\n",
       "         2.38912366e-02,  1.82577856e-02,  3.00363414e-02, -4.78017814e-02,\n",
       "        -1.73638090e-02, -1.28931515e-02,  3.67597826e-02,  2.29378790e-03,\n",
       "         2.75811292e-02,  4.82762493e-02,  2.74605863e-02, -3.38988379e-03,\n",
       "        -3.43315378e-02,  2.35022046e-02, -1.78098790e-02,  1.74374469e-02,\n",
       "        -3.03041339e-02, -4.50811759e-02,  6.76293299e-03,  3.29621546e-02,\n",
       "        -7.76034594e-03, -5.90310246e-03, -4.95511666e-02,  2.17311457e-03,\n",
       "         1.89427286e-03,  2.31018402e-02, -2.95441393e-02, -4.44498174e-02,\n",
       "         3.71497758e-02, -2.67551187e-02,  1.97990052e-02, -4.01072502e-02,\n",
       "        -4.83744219e-03, -4.38706763e-02, -3.25935856e-02, -4.20060009e-03,\n",
       "        -3.48634124e-02,  8.13684613e-03, -4.61214893e-02, -2.59678494e-02,\n",
       "         1.86904930e-02,  3.53771485e-02, -4.91961837e-05, -1.79481506e-02,\n",
       "         4.32471745e-02, -3.39389220e-02, -3.68380062e-02, -4.98723984e-02,\n",
       "        -4.06792052e-02, -3.42835784e-02, -4.87547405e-02, -3.93310077e-02,\n",
       "        -3.80987637e-02,  4.22075391e-06, -2.07043290e-02, -4.66613173e-02,\n",
       "        -3.83257493e-02, -3.96454819e-02,  6.49531931e-03, -1.44635215e-02],\n",
       "       dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " '#coppednews Haunting memories drawn by survivors http://t.co/Wx11d69gEZ')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking single token's embedding\n",
    "embed_sentence[0][0], embed_sentence[0][0].shape, random_sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using SKLearn to build base model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenisation and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # Convert words to numbers\n",
    "    (\"clf\", MultinomialNB()) # Model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved accuracy: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Achieved accuracy: {baseline_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "baseline_predictions = model_0.predict(val_sentences)\n",
    "baseline_predictions[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SKLearn functions\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Developing function to evaluate accuracy, precision, recall and F1 scor\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate binary classification model\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and F1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1\n",
    "    }\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting baseline results\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=baseline_predictions\n",
    ")\n",
    "baseline_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: a simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensorboard callback\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback\n",
    "\n",
    "# Creating log directory\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model with Functional API\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype=tf.string)\n",
    "x = text_vectorizer(inputs) # Turn the input text into numbers\n",
    "x = embedding(x) # Create embedding of numberised inputs\n",
    "x = layers.GlobalAveragePooling1D()(x) # Condence the feature vector\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20230112-145540\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 22ms/step - loss: 0.6149 - accuracy: 0.6819 - val_loss: 0.5390 - val_accuracy: 0.7520\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.4433 - accuracy: 0.8189 - val_loss: 0.4738 - val_accuracy: 0.7861\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.3484 - accuracy: 0.8605 - val_loss: 0.4555 - val_accuracy: 0.7900\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.2851 - accuracy: 0.8886 - val_loss: 0.4616 - val_accuracy: 0.7848\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.2392 - accuracy: 0.9121 - val_loss: 0.4802 - val_accuracy: 0.7730\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_1 = model_1.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_1_dense\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48020386695861816, 0.7729659080505371]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41229996],\n",
       "       [0.8003307 ],\n",
       "       [0.9976994 ],\n",
       "       [0.16048601],\n",
       "       [0.11926699],\n",
       "       [0.9481536 ],\n",
       "       [0.91662616],\n",
       "       [0.9933026 ],\n",
       "       [0.9622181 ],\n",
       "       [0.35727417]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 10 predictions\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model predictions to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.29658792650919,\n",
       " 'precision': 0.7750482481613202,\n",
       " 'recall': 0.7729658792650919,\n",
       " 'f1': 0.7707112186521387}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating model 1 results\n",
    "model_1_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_1_preds\n",
    ")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving baseline results\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing model results\n",
    "import numpy as np\n",
    "\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting vocabulary from the text vectorisation layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model 1 details\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[-0.0404411 ,  0.06279347, -0.0157323 , ...,  0.03764051,\n",
       "           0.04109191, -0.00942513],\n",
       "         [ 0.04339883,  0.00482864, -0.00190559, ..., -0.03837091,\n",
       "           0.00996654, -0.01673735],\n",
       "         [-0.0106418 ,  0.05169463, -0.04265122, ..., -0.04813926,\n",
       "          -0.0225852 ,  0.00864779],\n",
       "         ...,\n",
       "         [-0.04103322, -0.02331314, -0.04005098, ...,  0.03088905,\n",
       "          -0.02233095, -0.0283983 ],\n",
       "         [-0.07649511, -0.00106899, -0.07819299, ..., -0.05638961,\n",
       "           0.0213847 , -0.07861589],\n",
       "         [-0.10111035,  0.07923838, -0.05001825, ..., -0.05546221,\n",
       "           0.09209304, -0.08262438]], dtype=float32)],\n",
       " (10000, 128))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the weights\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()\n",
    "embed_weights, embed_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating embedding files (sample from TF Word Embedding documentation)\n",
    "import io\n",
    "\n",
    "out_v = io.open(\"vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
    "out_m = io.open(\"metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "    if index == 0:\n",
    "        continue # Skip 0, as it's a padding\n",
    "    vec = embed_weights[0][index]\n",
    "    out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated vectors.tsv and metadata.tsv can be uploaded into Tensorflow Embedding Projector tool at https://projector.tensorflow.org/ to visualise weights in 3D space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - RNN (Recurrent Neural Network) with LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# CReating an RNN model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(units=64, return_sequences=True)(x) # Sequences required when you stack LSTM layers\n",
    "# print(x.shape)\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model's summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230112-145608\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 18s 53ms/step - loss: 0.2177 - accuracy: 0.9242 - val_loss: 0.5184 - val_accuracy: 0.7822\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 10s 45ms/step - loss: 0.1591 - accuracy: 0.9404 - val_loss: 0.6117 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 10s 46ms/step - loss: 0.1279 - accuracy: 0.9546 - val_loss: 0.6723 - val_accuracy: 0.7808\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 10s 49ms/step - loss: 0.1059 - accuracy: 0.9599 - val_loss: 0.7377 - val_accuracy: 0.7861\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 10s 46ms/step - loss: 0.0970 - accuracy: 0.9631 - val_loss: 0.9170 - val_accuracy: 0.7808\n"
     ]
    }
   ],
   "source": [
    "# Fittting the model\n",
    "history_2 = model_2.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_2_LSTM\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.0079665e-02],\n",
       "       [8.3447516e-01],\n",
       "       [9.9944711e-01],\n",
       "       [4.8051752e-02],\n",
       "       [6.0482870e-04],\n",
       "       [9.9836874e-01],\n",
       "       [9.8421943e-01],\n",
       "       [9.9959338e-01],\n",
       "       [9.9933261e-01],\n",
       "       [6.4048135e-01]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting pred probs to label format\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.08398950131233,\n",
       " 'precision': 0.7805869752989146,\n",
       " 'recall': 0.7808398950131233,\n",
       " 'f1': 0.7802226438066691}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate model 2 results\n",
    "model_2_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_2_preds\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - RNN with GRU (gated recurrent unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True)(x) # Sequences, if GRU are stuck on each other\n",
    "x = layers.GRU(64)(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x) # If we want to consolidate GRU layer with sequences\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_3.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20230112-225336\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 13s 32ms/step - loss: 0.1558 - accuracy: 0.9391 - val_loss: 0.7063 - val_accuracy: 0.7822\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 9s 40ms/step - loss: 0.0833 - accuracy: 0.9672 - val_loss: 0.8373 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 8s 38ms/step - loss: 0.0726 - accuracy: 0.9724 - val_loss: 0.9299 - val_accuracy: 0.7822\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 6s 26ms/step - loss: 0.0623 - accuracy: 0.9765 - val_loss: 1.0888 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0540 - accuracy: 0.9772 - val_loss: 1.0876 - val_accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_3 = model_3.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_3_GRU\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.72325332e-04],\n",
       "       [8.49102855e-01],\n",
       "       [9.99928713e-01],\n",
       "       [1.10626847e-01],\n",
       "       [1.93399159e-04],\n",
       "       [9.99847233e-01],\n",
       "       [9.90021825e-01],\n",
       "       [9.99963224e-01],\n",
       "       [9.99937415e-01],\n",
       "       [9.73562539e-01],\n",
       "       [1.58786529e-03],\n",
       "       [9.11857605e-01],\n",
       "       [4.70924308e-04],\n",
       "       [1.76280648e-01],\n",
       "       [4.39951546e-04],\n",
       "       [1.98987946e-02],\n",
       "       [3.40970536e-03],\n",
       "       [1.09538785e-03],\n",
       "       [2.22330466e-02],\n",
       "       [9.99863148e-01],\n",
       "       [9.99954641e-01],\n",
       "       [8.78216597e-05],\n",
       "       [9.99867797e-01],\n",
       "       [7.23323273e-03],\n",
       "       [9.99938309e-01],\n",
       "       [9.99930620e-01],\n",
       "       [2.40431679e-03],\n",
       "       [6.59356941e-04],\n",
       "       [8.96699203e-04],\n",
       "       [4.24539566e-01],\n",
       "       [9.99599218e-01],\n",
       "       [3.83899547e-03],\n",
       "       [6.15034997e-01],\n",
       "       [8.02152697e-03],\n",
       "       [9.24085557e-01],\n",
       "       [1.60042137e-01],\n",
       "       [9.99902964e-01],\n",
       "       [2.06088558e-01],\n",
       "       [8.06857795e-02],\n",
       "       [9.99952853e-01],\n",
       "       [5.06587148e-01],\n",
       "       [1.30837769e-04],\n",
       "       [1.52490720e-01],\n",
       "       [4.17470175e-04],\n",
       "       [9.67011690e-01],\n",
       "       [9.99887109e-01],\n",
       "       [9.99065399e-01],\n",
       "       [9.15507019e-01],\n",
       "       [1.16802100e-02],\n",
       "       [4.01546180e-01],\n",
       "       [8.39313343e-02],\n",
       "       [4.80480790e-01],\n",
       "       [5.54484036e-03],\n",
       "       [1.26706585e-02],\n",
       "       [8.41759741e-01],\n",
       "       [2.68619638e-02],\n",
       "       [1.05897058e-02],\n",
       "       [9.99923170e-01],\n",
       "       [3.24548484e-04],\n",
       "       [4.67112008e-03],\n",
       "       [6.12894036e-02],\n",
       "       [9.99918938e-01],\n",
       "       [9.99114573e-01],\n",
       "       [3.39026928e-01],\n",
       "       [9.99964118e-01],\n",
       "       [9.99956846e-01],\n",
       "       [9.95528162e-01],\n",
       "       [7.56802484e-02],\n",
       "       [9.82163548e-01],\n",
       "       [6.73009679e-02],\n",
       "       [3.20762470e-02],\n",
       "       [7.50630647e-02],\n",
       "       [9.99952197e-01],\n",
       "       [2.55930517e-03],\n",
       "       [9.87867773e-01],\n",
       "       [9.86683428e-01],\n",
       "       [9.68349352e-02],\n",
       "       [9.99744534e-01],\n",
       "       [2.33463690e-01],\n",
       "       [5.30348301e-01],\n",
       "       [1.83042102e-02],\n",
       "       [1.17696784e-01],\n",
       "       [9.99948502e-01],\n",
       "       [1.33381959e-03],\n",
       "       [2.05467902e-02],\n",
       "       [1.26897963e-02],\n",
       "       [2.20308802e-03],\n",
       "       [3.70384636e-03],\n",
       "       [2.37260037e-03],\n",
       "       [9.99902666e-01],\n",
       "       [9.99898016e-01],\n",
       "       [2.48394179e-04],\n",
       "       [9.36784804e-01],\n",
       "       [2.57581472e-04],\n",
       "       [9.99936461e-01],\n",
       "       [8.40739608e-01],\n",
       "       [9.89814222e-01],\n",
       "       [9.99964356e-01],\n",
       "       [9.99816537e-01],\n",
       "       [9.98892844e-01],\n",
       "       [9.99983490e-01],\n",
       "       [1.84318330e-02],\n",
       "       [2.38160617e-04],\n",
       "       [9.99559879e-01],\n",
       "       [9.99866009e-01],\n",
       "       [6.44393414e-02],\n",
       "       [9.95720863e-01],\n",
       "       [9.97775853e-01],\n",
       "       [3.59358895e-03],\n",
       "       [9.99879301e-01],\n",
       "       [9.98894274e-01],\n",
       "       [6.31401723e-04],\n",
       "       [1.59331962e-01],\n",
       "       [1.98526122e-03],\n",
       "       [6.68285647e-04],\n",
       "       [5.92359453e-02],\n",
       "       [9.04252708e-01],\n",
       "       [9.99870956e-01],\n",
       "       [1.61078535e-02],\n",
       "       [1.45325577e-03],\n",
       "       [9.99961495e-01],\n",
       "       [3.35252960e-04],\n",
       "       [2.10423692e-04],\n",
       "       [9.88292575e-01],\n",
       "       [5.92131615e-02],\n",
       "       [1.72246550e-03],\n",
       "       [9.99885619e-01],\n",
       "       [2.26679986e-04],\n",
       "       [4.27731266e-03],\n",
       "       [9.99672294e-01],\n",
       "       [2.34670229e-02],\n",
       "       [9.99961495e-01],\n",
       "       [9.99971390e-01],\n",
       "       [9.99930620e-01],\n",
       "       [9.99898612e-01],\n",
       "       [9.72901704e-04],\n",
       "       [9.99918342e-01],\n",
       "       [1.64457589e-01],\n",
       "       [7.76426075e-03],\n",
       "       [8.25458148e-04],\n",
       "       [9.99961078e-01],\n",
       "       [9.42868352e-01],\n",
       "       [1.76280648e-01],\n",
       "       [9.99473214e-01],\n",
       "       [1.45437285e-01],\n",
       "       [6.38636015e-03],\n",
       "       [8.33537662e-04],\n",
       "       [3.97419353e-04],\n",
       "       [3.30568254e-01],\n",
       "       [9.99900937e-01],\n",
       "       [8.79524101e-04],\n",
       "       [6.13586679e-02],\n",
       "       [3.99108976e-03],\n",
       "       [1.04289001e-03],\n",
       "       [2.06098449e-03],\n",
       "       [9.99799311e-01],\n",
       "       [9.88826573e-01],\n",
       "       [6.99216127e-03],\n",
       "       [9.99678135e-01],\n",
       "       [5.50210301e-04],\n",
       "       [9.99888539e-01],\n",
       "       [3.80826439e-03],\n",
       "       [2.66925246e-01],\n",
       "       [9.99774218e-01],\n",
       "       [1.14514492e-01],\n",
       "       [1.09804925e-04],\n",
       "       [9.99942183e-01],\n",
       "       [3.72106768e-02],\n",
       "       [9.99930024e-01],\n",
       "       [9.86294389e-01],\n",
       "       [9.99914527e-01],\n",
       "       [9.99297738e-01],\n",
       "       [9.99833405e-01],\n",
       "       [4.58586466e-04],\n",
       "       [9.99978006e-01],\n",
       "       [2.15052557e-03],\n",
       "       [5.51328398e-02],\n",
       "       [7.79769495e-02],\n",
       "       [9.49599385e-01],\n",
       "       [9.99931753e-01],\n",
       "       [5.82989538e-03],\n",
       "       [9.90452170e-01],\n",
       "       [9.99884307e-01],\n",
       "       [9.99937892e-01],\n",
       "       [9.99949574e-01],\n",
       "       [5.16181206e-03],\n",
       "       [1.50499807e-03],\n",
       "       [9.99981284e-01],\n",
       "       [3.67826171e-04],\n",
       "       [2.69331213e-04],\n",
       "       [2.35538222e-02],\n",
       "       [9.99844372e-01],\n",
       "       [3.43202660e-03],\n",
       "       [6.14304212e-04],\n",
       "       [1.25357555e-03],\n",
       "       [4.56652138e-03],\n",
       "       [1.37095002e-03],\n",
       "       [9.74983256e-03],\n",
       "       [9.99843180e-01],\n",
       "       [3.60298567e-02],\n",
       "       [2.39862531e-01],\n",
       "       [9.99921143e-01],\n",
       "       [9.99897361e-01],\n",
       "       [1.26285490e-03],\n",
       "       [1.08293863e-03],\n",
       "       [9.99885380e-01],\n",
       "       [9.99871254e-01],\n",
       "       [9.99778688e-01],\n",
       "       [9.74099219e-01],\n",
       "       [9.97025669e-01],\n",
       "       [4.58777435e-02],\n",
       "       [9.99917567e-01],\n",
       "       [1.94470515e-03],\n",
       "       [2.48439563e-03],\n",
       "       [1.26675505e-03],\n",
       "       [2.63090275e-04],\n",
       "       [9.99948740e-01],\n",
       "       [9.96659756e-01],\n",
       "       [9.98086452e-01],\n",
       "       [2.57589310e-01],\n",
       "       [9.45930123e-01],\n",
       "       [2.76546343e-03],\n",
       "       [3.62829529e-02],\n",
       "       [6.42373692e-03],\n",
       "       [9.99906480e-01],\n",
       "       [2.12204963e-01],\n",
       "       [9.80321318e-02],\n",
       "       [9.99974787e-01],\n",
       "       [9.99747872e-01],\n",
       "       [1.62552461e-01],\n",
       "       [3.47975874e-04],\n",
       "       [9.78520699e-03],\n",
       "       [9.99709368e-01],\n",
       "       [3.36820424e-01],\n",
       "       [5.78816772e-01],\n",
       "       [5.26445247e-02],\n",
       "       [4.14469421e-01],\n",
       "       [1.59992039e-01],\n",
       "       [1.80503761e-03],\n",
       "       [1.44800788e-03],\n",
       "       [9.99610305e-01],\n",
       "       [9.94193740e-03],\n",
       "       [9.99928117e-01],\n",
       "       [9.99892890e-01],\n",
       "       [6.77314296e-04],\n",
       "       [9.57751472e-04],\n",
       "       [9.99895751e-01],\n",
       "       [4.23701335e-04],\n",
       "       [2.31569130e-02],\n",
       "       [3.20475668e-01],\n",
       "       [1.50719390e-03],\n",
       "       [9.99431312e-01],\n",
       "       [1.58714131e-04],\n",
       "       [2.17439495e-02],\n",
       "       [9.99885678e-01],\n",
       "       [1.15384325e-01],\n",
       "       [9.99899805e-01],\n",
       "       [9.99969065e-01],\n",
       "       [1.06448114e-01],\n",
       "       [3.36567231e-04],\n",
       "       [2.42891768e-03],\n",
       "       [4.21790144e-04],\n",
       "       [2.59034947e-04],\n",
       "       [9.99830604e-01],\n",
       "       [9.99925196e-01],\n",
       "       [1.85085163e-02],\n",
       "       [9.99875665e-01],\n",
       "       [4.99817124e-03],\n",
       "       [4.76440080e-02],\n",
       "       [6.49439811e-04],\n",
       "       [7.03556638e-04],\n",
       "       [6.44915330e-04],\n",
       "       [9.99874473e-01],\n",
       "       [9.07924399e-03],\n",
       "       [5.36297099e-04],\n",
       "       [9.99888480e-01],\n",
       "       [3.15796654e-03],\n",
       "       [2.46817159e-04],\n",
       "       [9.99879420e-01],\n",
       "       [3.43741121e-04],\n",
       "       [3.85082513e-02],\n",
       "       [6.98078016e-04],\n",
       "       [9.99891758e-01],\n",
       "       [9.69742477e-01],\n",
       "       [5.26144266e-01],\n",
       "       [6.79670274e-02],\n",
       "       [9.99687433e-01],\n",
       "       [4.10381937e-03],\n",
       "       [9.99945700e-01],\n",
       "       [1.62343457e-02],\n",
       "       [9.86963987e-01],\n",
       "       [9.92080092e-01],\n",
       "       [5.38767099e-01],\n",
       "       [2.80414410e-02],\n",
       "       [3.33482563e-03],\n",
       "       [6.14398956e-01],\n",
       "       [9.24459994e-02],\n",
       "       [9.49126203e-03],\n",
       "       [1.73436664e-03],\n",
       "       [5.95855825e-02],\n",
       "       [7.72015192e-05],\n",
       "       [2.91600497e-03],\n",
       "       [1.29503250e-01],\n",
       "       [9.99939203e-01],\n",
       "       [2.49006017e-03],\n",
       "       [5.56144193e-02],\n",
       "       [6.00254536e-02],\n",
       "       [1.72724411e-01],\n",
       "       [6.46462068e-02],\n",
       "       [7.86745269e-03],\n",
       "       [1.37009833e-03],\n",
       "       [9.99849021e-01],\n",
       "       [1.36710867e-01],\n",
       "       [3.65430713e-01],\n",
       "       [9.99975145e-01],\n",
       "       [1.13881612e-03],\n",
       "       [9.93227780e-01],\n",
       "       [1.43399119e-01],\n",
       "       [2.13501342e-02],\n",
       "       [9.91204903e-02],\n",
       "       [1.16509979e-03],\n",
       "       [4.18794565e-02],\n",
       "       [9.99819160e-01],\n",
       "       [4.99372631e-01],\n",
       "       [9.99912202e-01],\n",
       "       [3.06220472e-01],\n",
       "       [4.12431138e-04],\n",
       "       [9.99922752e-01],\n",
       "       [4.34828398e-04],\n",
       "       [9.99931812e-01],\n",
       "       [2.88662873e-02],\n",
       "       [1.32416254e-02],\n",
       "       [9.99926567e-01],\n",
       "       [5.87838178e-04],\n",
       "       [1.51892973e-03],\n",
       "       [9.99865651e-01],\n",
       "       [2.84153013e-03],\n",
       "       [8.05899501e-03],\n",
       "       [9.79207993e-01],\n",
       "       [9.99675512e-01],\n",
       "       [3.77287623e-04],\n",
       "       [9.36602056e-03],\n",
       "       [9.99889731e-01],\n",
       "       [9.99964476e-01],\n",
       "       [9.99600053e-01],\n",
       "       [2.38432050e-01],\n",
       "       [9.98437285e-01],\n",
       "       [9.99031544e-01],\n",
       "       [1.47772767e-02],\n",
       "       [1.15810952e-03],\n",
       "       [5.83314225e-02],\n",
       "       [7.97207355e-02],\n",
       "       [5.17460343e-04],\n",
       "       [6.61883280e-02],\n",
       "       [4.18958753e-01],\n",
       "       [8.99299455e-04],\n",
       "       [9.99902666e-01],\n",
       "       [9.99930620e-01],\n",
       "       [9.99940932e-01],\n",
       "       [6.08315319e-03],\n",
       "       [3.83518279e-01],\n",
       "       [1.37593210e-01],\n",
       "       [1.57575384e-01],\n",
       "       [9.84251142e-01],\n",
       "       [3.61870021e-01],\n",
       "       [1.89026759e-04],\n",
       "       [2.41837604e-03],\n",
       "       [9.20502120e-04],\n",
       "       [9.99688983e-01],\n",
       "       [3.13894404e-03],\n",
       "       [1.16879959e-02],\n",
       "       [1.78712001e-03],\n",
       "       [1.20862981e-03],\n",
       "       [2.07363307e-01],\n",
       "       [9.86480653e-01],\n",
       "       [8.72605518e-02],\n",
       "       [1.83166715e-03],\n",
       "       [7.20395381e-03],\n",
       "       [1.77674333e-03],\n",
       "       [9.99943793e-01],\n",
       "       [9.99810100e-01],\n",
       "       [9.39842820e-01],\n",
       "       [9.98508155e-01],\n",
       "       [6.80615020e-04],\n",
       "       [9.75978434e-01],\n",
       "       [9.99939978e-01],\n",
       "       [9.74063814e-01],\n",
       "       [1.12627305e-01],\n",
       "       [9.99831259e-01],\n",
       "       [4.04417999e-02],\n",
       "       [9.99953508e-01],\n",
       "       [3.47178406e-03],\n",
       "       [4.24224604e-03],\n",
       "       [3.41239363e-01],\n",
       "       [1.00892484e-02],\n",
       "       [9.99909520e-01],\n",
       "       [1.14630461e-01],\n",
       "       [1.78509261e-04],\n",
       "       [1.10662298e-03],\n",
       "       [3.61870021e-01],\n",
       "       [9.99984205e-01],\n",
       "       [8.40336143e-05],\n",
       "       [4.08592701e-01],\n",
       "       [9.99969780e-01],\n",
       "       [1.27874606e-04],\n",
       "       [9.99961495e-01],\n",
       "       [2.57395487e-03],\n",
       "       [3.02630221e-03],\n",
       "       [4.06036124e-04],\n",
       "       [9.99872148e-01],\n",
       "       [9.99739468e-01],\n",
       "       [4.81284689e-03],\n",
       "       [3.51896486e-03],\n",
       "       [9.99548912e-01],\n",
       "       [9.99926984e-01],\n",
       "       [6.63795292e-01],\n",
       "       [4.51911386e-04],\n",
       "       [7.79483933e-03],\n",
       "       [1.36153638e-01],\n",
       "       [6.20515738e-03],\n",
       "       [9.99958098e-01],\n",
       "       [9.35352027e-01],\n",
       "       [9.99946773e-01],\n",
       "       [9.99891520e-01],\n",
       "       [1.42791778e-01],\n",
       "       [2.00712889e-01],\n",
       "       [1.05504168e-03],\n",
       "       [9.99732018e-01],\n",
       "       [9.83200490e-01],\n",
       "       [9.85548794e-01],\n",
       "       [1.01747848e-02],\n",
       "       [2.36832686e-02],\n",
       "       [8.41393229e-03],\n",
       "       [2.12013474e-04],\n",
       "       [4.43822332e-02],\n",
       "       [9.45296735e-02],\n",
       "       [9.97831523e-01],\n",
       "       [4.02760087e-03],\n",
       "       [9.99962866e-01],\n",
       "       [9.99946117e-01],\n",
       "       [8.15351773e-03],\n",
       "       [8.49102855e-01],\n",
       "       [6.16708910e-03],\n",
       "       [4.94996039e-03],\n",
       "       [4.50484902e-01],\n",
       "       [9.99658883e-01],\n",
       "       [5.96111408e-03],\n",
       "       [6.57545775e-02],\n",
       "       [7.46450038e-04],\n",
       "       [4.97944057e-02],\n",
       "       [7.51979242e-05],\n",
       "       [9.99925494e-01],\n",
       "       [9.99305010e-01],\n",
       "       [9.99927878e-01],\n",
       "       [9.98073578e-01],\n",
       "       [9.79762554e-01],\n",
       "       [2.26677097e-02],\n",
       "       [3.88637010e-04],\n",
       "       [9.94269907e-01],\n",
       "       [9.99656022e-01],\n",
       "       [9.99927342e-01],\n",
       "       [5.03686909e-03],\n",
       "       [2.16011796e-02],\n",
       "       [2.19589751e-03],\n",
       "       [9.99937356e-01],\n",
       "       [9.99928236e-01],\n",
       "       [1.08271022e-03],\n",
       "       [1.04669854e-01],\n",
       "       [9.99968648e-01],\n",
       "       [8.41469225e-03],\n",
       "       [2.47754026e-02],\n",
       "       [9.98115182e-01],\n",
       "       [3.11901816e-03],\n",
       "       [2.10985448e-03],\n",
       "       [9.98838902e-01],\n",
       "       [2.69670546e-01],\n",
       "       [1.63621277e-01],\n",
       "       [9.99975085e-01],\n",
       "       [4.70259023e-04],\n",
       "       [1.69070326e-02],\n",
       "       [3.37161997e-04],\n",
       "       [3.41082516e-04],\n",
       "       [5.27835591e-03],\n",
       "       [9.99918997e-01],\n",
       "       [9.80395940e-04],\n",
       "       [8.17059398e-01],\n",
       "       [9.98914182e-01],\n",
       "       [8.81661177e-02],\n",
       "       [1.08410746e-01],\n",
       "       [2.36682637e-04],\n",
       "       [5.23737306e-03],\n",
       "       [9.99957085e-01],\n",
       "       [9.99864995e-01],\n",
       "       [1.32119944e-02],\n",
       "       [1.66618894e-03],\n",
       "       [2.06596684e-03],\n",
       "       [9.36286000e-04],\n",
       "       [9.99789715e-01],\n",
       "       [2.21334328e-03],\n",
       "       [9.99826491e-01],\n",
       "       [9.99641657e-01],\n",
       "       [9.27875221e-01],\n",
       "       [9.95707393e-01],\n",
       "       [1.16217799e-01],\n",
       "       [3.00692953e-02],\n",
       "       [2.87219626e-03],\n",
       "       [1.41740382e-01],\n",
       "       [6.72817647e-01],\n",
       "       [9.20780659e-01],\n",
       "       [1.29993767e-01],\n",
       "       [1.08190894e-03],\n",
       "       [2.11017206e-04],\n",
       "       [3.33651714e-03],\n",
       "       [4.13365364e-02],\n",
       "       [2.84743845e-01],\n",
       "       [1.06056236e-01],\n",
       "       [9.99953866e-01],\n",
       "       [9.99795794e-01],\n",
       "       [8.40739608e-01],\n",
       "       [9.99933302e-01],\n",
       "       [5.68325184e-02],\n",
       "       [1.08888689e-02],\n",
       "       [9.99848306e-01],\n",
       "       [1.12238079e-02],\n",
       "       [4.89014434e-03],\n",
       "       [2.81097710e-01],\n",
       "       [9.98180926e-01],\n",
       "       [8.91519594e-04],\n",
       "       [6.36870861e-01],\n",
       "       [9.88355160e-01],\n",
       "       [9.99799788e-01],\n",
       "       [9.99874651e-01],\n",
       "       [1.14641327e-03],\n",
       "       [6.85394630e-02],\n",
       "       [9.91876483e-01],\n",
       "       [5.29474171e-04],\n",
       "       [2.66287886e-02],\n",
       "       [3.56342494e-01],\n",
       "       [9.99188423e-01],\n",
       "       [9.90314186e-01],\n",
       "       [6.39692228e-03],\n",
       "       [3.06049408e-03],\n",
       "       [9.92962599e-01],\n",
       "       [1.36303459e-03],\n",
       "       [1.11988522e-02],\n",
       "       [2.16379340e-04],\n",
       "       [3.71053815e-01],\n",
       "       [9.99945402e-01],\n",
       "       [9.99775350e-01],\n",
       "       [3.43873608e-03],\n",
       "       [9.99867797e-01],\n",
       "       [9.99935269e-01],\n",
       "       [1.95052897e-04],\n",
       "       [9.99903500e-01],\n",
       "       [1.18244477e-01],\n",
       "       [9.86931860e-01],\n",
       "       [1.61538228e-01],\n",
       "       [3.91145423e-03],\n",
       "       [6.16871286e-04],\n",
       "       [5.42281952e-04],\n",
       "       [5.84780378e-03],\n",
       "       [1.37997384e-04],\n",
       "       [5.85991442e-01],\n",
       "       [1.29277748e-03],\n",
       "       [9.99921620e-01],\n",
       "       [3.66913294e-03],\n",
       "       [9.97352898e-01],\n",
       "       [9.95405436e-01],\n",
       "       [9.27163940e-03],\n",
       "       [1.92346948e-03],\n",
       "       [9.99961674e-01],\n",
       "       [2.56083142e-02],\n",
       "       [9.99920070e-01],\n",
       "       [3.15995038e-01],\n",
       "       [4.58298773e-02],\n",
       "       [3.01180363e-01],\n",
       "       [3.66860628e-03],\n",
       "       [1.16079576e-01],\n",
       "       [9.99935269e-01],\n",
       "       [4.53463144e-04],\n",
       "       [2.30136677e-03],\n",
       "       [8.64524394e-02],\n",
       "       [9.99937773e-01],\n",
       "       [1.49169695e-02],\n",
       "       [1.55036862e-03],\n",
       "       [9.99274433e-01],\n",
       "       [1.71522319e-04],\n",
       "       [8.62867513e-04],\n",
       "       [5.73797093e-04],\n",
       "       [2.71289051e-01],\n",
       "       [3.16761471e-02],\n",
       "       [3.79745483e-01],\n",
       "       [6.85755685e-02],\n",
       "       [7.07520172e-02],\n",
       "       [2.29706595e-04],\n",
       "       [2.34282408e-02],\n",
       "       [3.19776853e-04],\n",
       "       [9.99747515e-01],\n",
       "       [9.98631597e-01],\n",
       "       [3.82401794e-02],\n",
       "       [4.41388169e-04],\n",
       "       [9.39880777e-03],\n",
       "       [9.99948204e-01],\n",
       "       [9.89777267e-01],\n",
       "       [9.99973953e-01],\n",
       "       [2.45383452e-03],\n",
       "       [9.99832332e-01],\n",
       "       [1.22885569e-03],\n",
       "       [9.99072254e-01],\n",
       "       [9.96721387e-01],\n",
       "       [6.43432315e-04],\n",
       "       [9.99946654e-01],\n",
       "       [2.70028189e-02],\n",
       "       [9.99226630e-01],\n",
       "       [9.99971569e-01],\n",
       "       [3.30650397e-02],\n",
       "       [7.60698575e-04],\n",
       "       [9.97028649e-01],\n",
       "       [1.20966742e-03],\n",
       "       [2.10013911e-02],\n",
       "       [9.99885380e-01],\n",
       "       [3.17783952e-01],\n",
       "       [9.99827325e-01],\n",
       "       [6.31987974e-02],\n",
       "       [9.99882579e-01],\n",
       "       [9.94354963e-01],\n",
       "       [4.29178625e-02],\n",
       "       [8.08997022e-04],\n",
       "       [9.98963714e-01],\n",
       "       [9.90758999e-04],\n",
       "       [1.96389139e-01],\n",
       "       [9.99938548e-01],\n",
       "       [9.99493361e-01],\n",
       "       [9.99949276e-01],\n",
       "       [9.99867976e-01],\n",
       "       [3.22189420e-01],\n",
       "       [9.99001324e-01],\n",
       "       [5.91458636e-04],\n",
       "       [8.60137522e-01],\n",
       "       [9.99420166e-01],\n",
       "       [9.99841452e-01],\n",
       "       [2.16292706e-03],\n",
       "       [9.99209285e-01],\n",
       "       [9.99913692e-01],\n",
       "       [4.36639553e-03],\n",
       "       [1.14074023e-02],\n",
       "       [1.29993767e-01],\n",
       "       [4.02102666e-03],\n",
       "       [9.65882242e-01],\n",
       "       [9.99057353e-01],\n",
       "       [9.99923706e-01],\n",
       "       [2.67058774e-03],\n",
       "       [3.64759559e-04],\n",
       "       [6.04752335e-04],\n",
       "       [1.07470587e-01],\n",
       "       [8.59441981e-03],\n",
       "       [7.90323541e-02],\n",
       "       [9.92995203e-01],\n",
       "       [2.42744252e-04],\n",
       "       [3.72134387e-01],\n",
       "       [3.07606887e-02],\n",
       "       [7.52271041e-02],\n",
       "       [9.99832749e-01],\n",
       "       [2.71440996e-03],\n",
       "       [9.99735475e-01],\n",
       "       [2.00928911e-03],\n",
       "       [1.62388576e-04],\n",
       "       [1.64457958e-03],\n",
       "       [9.99950290e-01],\n",
       "       [9.73164201e-01],\n",
       "       [9.50631744e-04],\n",
       "       [2.94853598e-01],\n",
       "       [6.76001534e-02],\n",
       "       [2.12868690e-04],\n",
       "       [9.99892831e-01],\n",
       "       [4.09271801e-03],\n",
       "       [9.98576880e-01],\n",
       "       [8.84985387e-01],\n",
       "       [3.54810595e-03],\n",
       "       [5.45848906e-01],\n",
       "       [1.56919912e-01],\n",
       "       [9.59355906e-02],\n",
       "       [9.99884248e-01],\n",
       "       [6.86067045e-02],\n",
       "       [6.65689111e-01],\n",
       "       [9.99950886e-01],\n",
       "       [5.34597874e-01],\n",
       "       [2.09309086e-01],\n",
       "       [8.91519594e-04],\n",
       "       [2.23776504e-01],\n",
       "       [9.99345303e-01],\n",
       "       [9.99961495e-01],\n",
       "       [9.81407821e-01],\n",
       "       [4.69415635e-02],\n",
       "       [9.99936938e-01],\n",
       "       [2.40564093e-01],\n",
       "       [9.99835074e-01],\n",
       "       [2.40564093e-01],\n",
       "       [9.99942005e-01],\n",
       "       [4.78301605e-04],\n",
       "       [1.56387519e-02],\n",
       "       [1.81458949e-04],\n",
       "       [9.99954402e-01],\n",
       "       [1.61444247e-02],\n",
       "       [1.37452453e-01],\n",
       "       [4.10387060e-04],\n",
       "       [7.16115162e-03],\n",
       "       [2.32959469e-03],\n",
       "       [2.54690205e-03],\n",
       "       [4.08195071e-02],\n",
       "       [2.78375368e-03],\n",
       "       [8.11031088e-03],\n",
       "       [9.98908222e-01],\n",
       "       [6.89030346e-03],\n",
       "       [5.49988337e-02],\n",
       "       [2.01717019e-03],\n",
       "       [1.39736687e-03],\n",
       "       [1.18441068e-01],\n",
       "       [9.99722421e-01],\n",
       "       [2.38812324e-02],\n",
       "       [4.38210368e-02],\n",
       "       [3.38737965e-02],\n",
       "       [9.99424040e-01],\n",
       "       [9.99901175e-01],\n",
       "       [1.44415267e-03],\n",
       "       [6.29518006e-04],\n",
       "       [8.81023763e-04],\n",
       "       [8.92957614e-05],\n",
       "       [9.99916494e-01],\n",
       "       [1.39736687e-03],\n",
       "       [9.22844931e-02],\n",
       "       [9.99915719e-01],\n",
       "       [9.99934375e-01],\n",
       "       [9.99930203e-01],\n",
       "       [9.99973953e-01],\n",
       "       [9.99990940e-01],\n",
       "       [3.25516541e-03],\n",
       "       [9.36796365e-04],\n",
       "       [1.00013517e-01],\n",
       "       [9.99445319e-01],\n",
       "       [9.99942064e-01],\n",
       "       [9.75701869e-01],\n",
       "       [3.61969508e-03],\n",
       "       [9.99713123e-01],\n",
       "       [8.47396255e-01],\n",
       "       [3.42827057e-04],\n",
       "       [1.02806499e-03],\n",
       "       [2.07280479e-02],\n",
       "       [6.93151057e-02],\n",
       "       [2.72018689e-04],\n",
       "       [2.28313860e-02],\n",
       "       [9.85741615e-01],\n",
       "       [9.99971211e-01],\n",
       "       [1.06483081e-03],\n",
       "       [9.99912500e-01],\n",
       "       [9.99463558e-01],\n",
       "       [5.21530993e-02],\n",
       "       [8.91597867e-02],\n",
       "       [9.13717031e-01],\n",
       "       [8.34441245e-01],\n",
       "       [1.49472477e-02],\n",
       "       [1.02867233e-03]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model 3 pred probs to label format\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8230a386d8e0083990873cddb8ebb5b6213275a10339230a8504f0ef8ce7f888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
