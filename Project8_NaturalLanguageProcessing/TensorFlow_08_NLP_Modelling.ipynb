{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "# Importing TF and checking the version\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing helper functions\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"NLP_text/train.csv\")\n",
    "test_df = pd.read_csv(\"NLP_text/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking test dataframe\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of training records\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking total number of samples\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Rolling sandunes the gentle lapping of the sea the call of gulls and a nuclear reactor #sizewell http://t.co/X9CUiHIb5n\n",
      "---\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "#WorldWatchesFerguson #Florida @GovJayNixon @clairecmc How dare you turn our streets into a war zone -a war against CITIZENS?\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@KristinDavis @UN @Refugees Thank you @UN and @Refugees for helping so many people in need all over the world.... https://t.co/yPvJgzqqqB Û_\n",
      "---\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "abcnews - Obama Declares Disaster for Typhoon-Devastated Saipan: Obama signs disaster declaration for Northern... http://t.co/mg5eAJElul\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Keep thinking about it until I stepped on a broken glass pun tak sedar and I don't feel the pain also it's bleeding. Shit\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Visualising random samples\n",
    "import random\n",
    "\n",
    "random_index = random.randint(0, len(train_df) - 5)\n",
    "\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index : random_index + 5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size=0.1, # Allocating 10% to validation data\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dataset length\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting text to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using text vectorisation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=None,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=None,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the average number of tokens\n",
    "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up text vectorisation variables\n",
    "max_vocab_length = 10000\n",
    "max_length = 15\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting text vectorisation to the training dataset\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentnence and tokenise it\n",
    "sample_sentence = \"There is a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "News Wrap: UN warns female and child casualties are on the rise in Afghanistan http://t.co/vSvY1qe69t #pbs #iraq,\n",
      "tokenised version:\n",
      "[[  58 6666 1348 2234 2115    7  785  518   22   11    2  727    4 1439\n",
      "     1]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenising random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\ntokenised version:\\n{text_vectorizer([random_sentence])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " ['', '[UNK]', 'the', 'a', 'in'],\n",
       " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "\n",
    "len(words_in_vocab), top_5_words, bottom_5_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x1a32fc32610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the layer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    input_length=max_length\n",
    ")\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "CIVIL WAR GENERAL BATTLE BULL RUN HERO COLONEL 2nd NEW HAMPSHIRE LETTER SIGNED ! http://t.co/Ot0tFFpBYB http://t.co/zaRBwep9LD,\n",
      "embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.03910953,  0.04944987, -0.00075934, ..., -0.03403198,\n",
       "         -0.00348186, -0.01742106],\n",
       "        [ 0.0041035 , -0.00746389,  0.01504979, ...,  0.0236407 ,\n",
       "          0.02998877,  0.01439286],\n",
       "        [ 0.01736666,  0.02454226,  0.01020164, ...,  0.00234209,\n",
       "          0.00887488,  0.03583899],\n",
       "        ...,\n",
       "        [-0.04179144,  0.02842022,  0.04328972, ..., -0.043797  ,\n",
       "         -0.00254587, -0.04064964],\n",
       "        [-0.03600398,  0.01793792, -0.01776426, ..., -0.02122303,\n",
       "          0.02432457,  0.04955358],\n",
       "        [-0.03600398,  0.01793792, -0.01776426, ..., -0.02122303,\n",
       "          0.02432457,  0.04955358]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\nembedded version:\"\n",
    ")\n",
    "\n",
    "# Embed random sentence\n",
    "embed_sentence = embedding(text_vectorizer([random_sentence]))\n",
    "embed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([ 0.03910953,  0.04944987, -0.00075934, -0.00431272, -0.03259523,\n",
       "        -0.03593317,  0.01212875, -0.04515864, -0.01814132, -0.0021026 ,\n",
       "        -0.01968093, -0.04616164,  0.0139874 , -0.03467422, -0.00062526,\n",
       "        -0.03975097, -0.01643282, -0.02727976,  0.03836131,  0.04831917,\n",
       "        -0.03405396, -0.04437586,  0.02378335, -0.04233317, -0.0256915 ,\n",
       "        -0.00028577, -0.01532711,  0.01004393,  0.00557385, -0.00929018,\n",
       "        -0.01044401,  0.04870481, -0.04779059,  0.02947042, -0.01351601,\n",
       "        -0.04520537, -0.01884643,  0.01876217,  0.01113417,  0.03018364,\n",
       "        -0.01309311, -0.01971263,  0.03411776, -0.03056052,  0.01944895,\n",
       "         0.02422663, -0.03748114,  0.04300738, -0.0125602 ,  0.00091909,\n",
       "         0.03636278, -0.0338579 ,  0.03670966, -0.03747848, -0.02095756,\n",
       "         0.01968366, -0.01550616,  0.02724976, -0.01771086,  0.01087459,\n",
       "        -0.01535462,  0.03529755, -0.03348463, -0.04700742,  0.02658183,\n",
       "        -0.04869416, -0.03891566, -0.02362402,  0.02103522, -0.03613283,\n",
       "         0.02887965, -0.00378617, -0.0382463 , -0.03517503, -0.00476098,\n",
       "         0.0247885 ,  0.0354155 ,  0.04796238,  0.04351649,  0.03395578,\n",
       "        -0.04893851, -0.02806433,  0.01207074, -0.00430292,  0.02266968,\n",
       "        -0.0077432 ,  0.00604472, -0.00095461,  0.01051351, -0.01014906,\n",
       "        -0.00992327,  0.01492852,  0.043776  , -0.0450129 , -0.03517976,\n",
       "        -0.04745059, -0.006003  ,  0.01881311,  0.04593866, -0.00437643,\n",
       "         0.01672466, -0.01142593,  0.03139224, -0.02089128, -0.01264224,\n",
       "        -0.00705726, -0.00136539,  0.02143217, -0.01851468, -0.0165812 ,\n",
       "        -0.00711315, -0.02947583, -0.03083721, -0.02764605,  0.02922564,\n",
       "         0.01931835,  0.01226445,  0.02661398, -0.02302613,  0.02419574,\n",
       "        -0.02619389, -0.04132899,  0.02007331,  0.02730272,  0.00808807,\n",
       "        -0.03403198, -0.00348186, -0.01742106], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " 'CIVIL WAR GENERAL BATTLE BULL RUN HERO COLONEL 2nd NEW HAMPSHIRE LETTER SIGNED ! http://t.co/Ot0tFFpBYB http://t.co/zaRBwep9LD')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking single token's embedding\n",
    "embed_sentence[0][0], embed_sentence[0][0].shape, random_sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using SKLearn to build base model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenisation and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # Convert words to numbers\n",
    "    (\"clf\", MultinomialNB()) # Model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved accuracy: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Achieved accuracy: {baseline_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "baseline_predictions = model_0.predict(val_sentences)\n",
    "baseline_predictions[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SKLearn functions\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Developing function to evaluate accuracy, precision, recall and F1 scor\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate binary classification model\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and F1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1\n",
    "    }\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting baseline results\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=baseline_predictions\n",
    ")\n",
    "baseline_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: a simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensorboard callback\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback\n",
    "\n",
    "# Creating log directory\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model with Functional API\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype=tf.string)\n",
    "x = text_vectorizer(inputs) # Turn the input text into numbers\n",
    "x = embedding(x) # Create embedding of numberised inputs\n",
    "x = layers.GlobalAveragePooling1D()(x) # Condence the feature vector\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20230115-140355\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 15ms/step - loss: 0.6130 - accuracy: 0.6961 - val_loss: 0.5354 - val_accuracy: 0.7612\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.4429 - accuracy: 0.8171 - val_loss: 0.4738 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.3474 - accuracy: 0.8608 - val_loss: 0.4595 - val_accuracy: 0.7940\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.2849 - accuracy: 0.8882 - val_loss: 0.4596 - val_accuracy: 0.7848\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.2386 - accuracy: 0.9140 - val_loss: 0.4764 - val_accuracy: 0.7848\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_1 = model_1.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_1_dense\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47637301683425903, 0.7847769260406494]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44770905],\n",
       "       [0.7105849 ],\n",
       "       [0.9981582 ],\n",
       "       [0.14486265],\n",
       "       [0.11354049],\n",
       "       [0.947634  ],\n",
       "       [0.88502544],\n",
       "       [0.9941534 ],\n",
       "       [0.97123855],\n",
       "       [0.29792026]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 10 predictions\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model predictions to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.4776902887139,\n",
       " 'precision': 0.7867627887573655,\n",
       " 'recall': 0.7847769028871391,\n",
       " 'f1': 0.7828250820874111}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating model 1 results\n",
    "model_1_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_1_preds\n",
    ")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving baseline results\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing model results\n",
    "import numpy as np\n",
    "\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting vocabulary from the text vectorisation layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model 1 details\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 0.06417161,  0.01519952, -0.06827231, ..., -0.00054693,\n",
       "          -0.02690474, -0.00448329],\n",
       "         [-0.03435826,  0.01822414, -0.02051552, ..., -0.02347109,\n",
       "           0.02209371,  0.04865316],\n",
       "         [ 0.04357785,  0.01337285, -0.02630139, ...,  0.06265885,\n",
       "           0.02366419, -0.05968196],\n",
       "         ...,\n",
       "         [ 0.01998829, -0.00305961,  0.00864701, ..., -0.00789784,\n",
       "          -0.01902278, -0.04017846],\n",
       "         [ 0.07212634,  0.01228446, -0.02136814, ...,  0.04640999,\n",
       "           0.02045361,  0.01623856],\n",
       "         [ 0.02796545,  0.10167719, -0.0370875 , ...,  0.03066149,\n",
       "           0.02718702, -0.08076494]], dtype=float32)],\n",
       " (10000, 128))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the weights\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()\n",
    "embed_weights, embed_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating embedding files (sample from TF Word Embedding documentation)\n",
    "import io\n",
    "\n",
    "out_v = io.open(\"vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
    "out_m = io.open(\"metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "    if index == 0:\n",
    "        continue # Skip 0, as it's a padding\n",
    "    vec = embed_weights[0][index]\n",
    "    out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated vectors.tsv and metadata.tsv can be uploaded into Tensorflow Embedding Projector tool at https://projector.tensorflow.org/ to visualise weights in 3D space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - RNN (Recurrent Neural Network) with LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# CReating an RNN model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(units=64, return_sequences=True)(x) # Sequences required when you stack LSTM layers\n",
    "# print(x.shape)\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model's summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230115-140414\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 29ms/step - loss: 0.2168 - accuracy: 0.9204 - val_loss: 0.5235 - val_accuracy: 0.7808\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 6s 28ms/step - loss: 0.1558 - accuracy: 0.9418 - val_loss: 0.6328 - val_accuracy: 0.7782\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 25ms/step - loss: 0.1272 - accuracy: 0.9523 - val_loss: 0.6671 - val_accuracy: 0.7730\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 26ms/step - loss: 0.1010 - accuracy: 0.9606 - val_loss: 0.7766 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0831 - accuracy: 0.9672 - val_loss: 0.9561 - val_accuracy: 0.7756\n"
     ]
    }
   ],
   "source": [
    "# Fittting the model\n",
    "history_2 = model_2.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_2_LSTM\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.0655664e-03],\n",
       "       [7.9005218e-01],\n",
       "       [9.9976742e-01],\n",
       "       [2.2368792e-02],\n",
       "       [2.8219089e-04],\n",
       "       [9.9891210e-01],\n",
       "       [6.4708853e-01],\n",
       "       [9.9987787e-01],\n",
       "       [9.9974960e-01],\n",
       "       [3.0192614e-01]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting pred probs to label format\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.55905511811024,\n",
       " 'precision': 0.7802047087708873,\n",
       " 'recall': 0.7755905511811023,\n",
       " 'f1': 0.7723569237171506}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate model 2 results\n",
    "model_2_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_2_preds\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - RNN with GRU (gated recurrent unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True)(x) # Sequences, if GRU are stuck on each other\n",
    "x = layers.GRU(64)(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x) # If we want to consolidate GRU layer with sequences\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_3.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20230115-140448\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 27ms/step - loss: 0.1524 - accuracy: 0.9391 - val_loss: 0.7385 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0839 - accuracy: 0.9688 - val_loss: 0.9156 - val_accuracy: 0.7756\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0729 - accuracy: 0.9724 - val_loss: 0.8051 - val_accuracy: 0.7782\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0582 - accuracy: 0.9762 - val_loss: 0.9416 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0502 - accuracy: 0.9787 - val_loss: 1.1723 - val_accuracy: 0.7808\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_3 = model_3.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_3_GRU\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.04508489e-04],\n",
       "       [8.72708082e-01],\n",
       "       [9.99888122e-01],\n",
       "       [1.35886058e-01],\n",
       "       [6.78687502e-05],\n",
       "       [9.99800086e-01],\n",
       "       [9.63634968e-01],\n",
       "       [9.99961257e-01],\n",
       "       [9.99915898e-01],\n",
       "       [9.07369256e-01],\n",
       "       [4.41405660e-04],\n",
       "       [9.64353502e-01],\n",
       "       [2.16167988e-04],\n",
       "       [2.30987623e-01],\n",
       "       [1.32624322e-04],\n",
       "       [9.43428662e-04],\n",
       "       [4.87239042e-04],\n",
       "       [2.85887305e-04],\n",
       "       [1.76380444e-02],\n",
       "       [9.99717772e-01],\n",
       "       [9.99981284e-01],\n",
       "       [5.44067079e-05],\n",
       "       [9.99554098e-01],\n",
       "       [1.21992640e-03],\n",
       "       [9.99890745e-01],\n",
       "       [9.99933243e-01],\n",
       "       [8.98943923e-04],\n",
       "       [2.49236095e-04],\n",
       "       [1.35301292e-04],\n",
       "       [3.88348907e-01],\n",
       "       [9.95594323e-01],\n",
       "       [5.57709427e-04],\n",
       "       [1.15396708e-01],\n",
       "       [5.90767944e-03],\n",
       "       [4.85753030e-01],\n",
       "       [3.25351954e-01],\n",
       "       [9.99820113e-01],\n",
       "       [1.82585508e-01],\n",
       "       [3.22926678e-02],\n",
       "       [9.99943733e-01],\n",
       "       [5.83833575e-01],\n",
       "       [3.86066495e-05],\n",
       "       [5.29478937e-02],\n",
       "       [2.56189815e-04],\n",
       "       [9.57490444e-01],\n",
       "       [9.99848306e-01],\n",
       "       [9.99419570e-01],\n",
       "       [9.90046024e-01],\n",
       "       [8.84722173e-03],\n",
       "       [9.27360296e-01],\n",
       "       [2.45706979e-02],\n",
       "       [5.24756610e-01],\n",
       "       [2.78116600e-03],\n",
       "       [8.24077986e-04],\n",
       "       [7.28496492e-01],\n",
       "       [4.51416150e-02],\n",
       "       [6.24466978e-04],\n",
       "       [9.99894202e-01],\n",
       "       [1.99934919e-04],\n",
       "       [1.19407917e-03],\n",
       "       [6.42702803e-02],\n",
       "       [9.99882221e-01],\n",
       "       [9.94468510e-01],\n",
       "       [1.10565359e-03],\n",
       "       [9.99936938e-01],\n",
       "       [9.99936759e-01],\n",
       "       [9.94050860e-01],\n",
       "       [5.33836633e-02],\n",
       "       [9.96240199e-01],\n",
       "       [3.52317877e-02],\n",
       "       [3.88656184e-02],\n",
       "       [8.08975399e-02],\n",
       "       [9.99928117e-01],\n",
       "       [1.20523898e-03],\n",
       "       [5.32312579e-02],\n",
       "       [9.88780439e-01],\n",
       "       [2.95880325e-02],\n",
       "       [9.99345541e-01],\n",
       "       [3.18053693e-01],\n",
       "       [3.15248102e-01],\n",
       "       [1.31549360e-03],\n",
       "       [1.11982279e-01],\n",
       "       [9.99933422e-01],\n",
       "       [6.15324068e-04],\n",
       "       [7.31657492e-04],\n",
       "       [1.02944975e-03],\n",
       "       [3.49172507e-04],\n",
       "       [2.87745148e-04],\n",
       "       [1.22234167e-03],\n",
       "       [9.99835253e-01],\n",
       "       [9.99864519e-01],\n",
       "       [1.23013931e-04],\n",
       "       [9.58718836e-01],\n",
       "       [1.58806637e-04],\n",
       "       [9.99916494e-01],\n",
       "       [8.82056296e-01],\n",
       "       [9.41016674e-01],\n",
       "       [9.99966979e-01],\n",
       "       [9.99789834e-01],\n",
       "       [9.99246895e-01],\n",
       "       [9.99978304e-01],\n",
       "       [5.32593764e-03],\n",
       "       [1.01681217e-04],\n",
       "       [9.99431074e-01],\n",
       "       [9.99776959e-01],\n",
       "       [4.75701690e-03],\n",
       "       [9.99726772e-01],\n",
       "       [9.97194171e-01],\n",
       "       [8.65101872e-04],\n",
       "       [9.99740124e-01],\n",
       "       [9.97571826e-01],\n",
       "       [2.43469753e-04],\n",
       "       [8.91805470e-01],\n",
       "       [5.19636669e-04],\n",
       "       [4.96027002e-04],\n",
       "       [4.41528186e-02],\n",
       "       [6.80009246e-01],\n",
       "       [9.99544561e-01],\n",
       "       [2.39041280e-02],\n",
       "       [2.28068951e-04],\n",
       "       [9.99950051e-01],\n",
       "       [1.15725954e-04],\n",
       "       [2.28525649e-04],\n",
       "       [9.48399663e-01],\n",
       "       [1.01919975e-02],\n",
       "       [7.23457662e-04],\n",
       "       [9.99766588e-01],\n",
       "       [7.41835538e-05],\n",
       "       [7.06753053e-04],\n",
       "       [9.99404311e-01],\n",
       "       [1.08999992e-03],\n",
       "       [9.99950051e-01],\n",
       "       [9.99961734e-01],\n",
       "       [9.99933243e-01],\n",
       "       [9.99824882e-01],\n",
       "       [3.72572133e-04],\n",
       "       [9.99866426e-01],\n",
       "       [1.78037807e-01],\n",
       "       [1.18688531e-02],\n",
       "       [5.02223498e-04],\n",
       "       [9.99946177e-01],\n",
       "       [9.38874006e-01],\n",
       "       [2.30987623e-01],\n",
       "       [9.99741852e-01],\n",
       "       [2.08168969e-01],\n",
       "       [2.16707727e-03],\n",
       "       [1.51615663e-04],\n",
       "       [7.06023638e-05],\n",
       "       [2.06878990e-01],\n",
       "       [9.99833405e-01],\n",
       "       [4.58419323e-04],\n",
       "       [1.32494206e-02],\n",
       "       [4.95580817e-03],\n",
       "       [2.22176634e-04],\n",
       "       [1.60451396e-04],\n",
       "       [9.99748230e-01],\n",
       "       [9.96157765e-01],\n",
       "       [4.40432783e-03],\n",
       "       [9.99579966e-01],\n",
       "       [1.83252079e-04],\n",
       "       [9.99904990e-01],\n",
       "       [1.90214918e-03],\n",
       "       [5.30949198e-02],\n",
       "       [9.99043643e-01],\n",
       "       [1.00676998e-01],\n",
       "       [6.23351734e-05],\n",
       "       [9.99917805e-01],\n",
       "       [1.96612012e-02],\n",
       "       [9.99936342e-01],\n",
       "       [1.71678722e-01],\n",
       "       [9.99925792e-01],\n",
       "       [9.96599853e-01],\n",
       "       [9.99754727e-01],\n",
       "       [2.34582956e-04],\n",
       "       [9.99982119e-01],\n",
       "       [5.59876906e-04],\n",
       "       [5.09175612e-03],\n",
       "       [9.89375170e-03],\n",
       "       [8.73522401e-01],\n",
       "       [9.99904752e-01],\n",
       "       [3.99770448e-04],\n",
       "       [9.90260482e-01],\n",
       "       [9.99822259e-01],\n",
       "       [9.99894202e-01],\n",
       "       [9.99932885e-01],\n",
       "       [5.92868193e-04],\n",
       "       [3.23699031e-04],\n",
       "       [9.99980211e-01],\n",
       "       [8.28468765e-05],\n",
       "       [5.53883729e-05],\n",
       "       [2.06299988e-03],\n",
       "       [9.99647379e-01],\n",
       "       [9.43566149e-04],\n",
       "       [3.08283692e-04],\n",
       "       [4.08420077e-04],\n",
       "       [6.51244307e-04],\n",
       "       [2.52438855e-04],\n",
       "       [1.39220164e-03],\n",
       "       [9.99831915e-01],\n",
       "       [4.81305644e-03],\n",
       "       [2.39516590e-02],\n",
       "       [9.99898493e-01],\n",
       "       [9.99850571e-01],\n",
       "       [5.35870437e-04],\n",
       "       [3.32329801e-04],\n",
       "       [9.99920249e-01],\n",
       "       [9.99780238e-01],\n",
       "       [9.99878287e-01],\n",
       "       [9.98223662e-01],\n",
       "       [9.95421171e-01],\n",
       "       [1.22360550e-01],\n",
       "       [9.99870062e-01],\n",
       "       [6.61955040e-04],\n",
       "       [5.88761410e-04],\n",
       "       [2.51751422e-04],\n",
       "       [9.04829358e-05],\n",
       "       [9.99922097e-01],\n",
       "       [9.97308731e-01],\n",
       "       [9.99343574e-01],\n",
       "       [5.04015505e-01],\n",
       "       [8.11664283e-01],\n",
       "       [1.26918557e-03],\n",
       "       [6.37063337e-03],\n",
       "       [2.50919000e-03],\n",
       "       [9.99866009e-01],\n",
       "       [5.85456230e-02],\n",
       "       [5.95260691e-03],\n",
       "       [9.99964893e-01],\n",
       "       [9.99544740e-01],\n",
       "       [1.31490394e-01],\n",
       "       [2.86615716e-04],\n",
       "       [3.11651779e-03],\n",
       "       [9.99542236e-01],\n",
       "       [4.77105945e-01],\n",
       "       [3.98526341e-01],\n",
       "       [1.70550365e-02],\n",
       "       [6.15483403e-01],\n",
       "       [3.57162766e-02],\n",
       "       [1.02734624e-03],\n",
       "       [3.78523546e-04],\n",
       "       [9.98368025e-01],\n",
       "       [3.83324828e-03],\n",
       "       [9.99896586e-01],\n",
       "       [9.99853432e-01],\n",
       "       [9.71625617e-04],\n",
       "       [1.05911618e-04],\n",
       "       [9.99811411e-01],\n",
       "       [1.55360423e-04],\n",
       "       [1.36368768e-03],\n",
       "       [1.80533081e-01],\n",
       "       [3.64225329e-04],\n",
       "       [9.99218464e-01],\n",
       "       [6.74159965e-05],\n",
       "       [1.17331995e-02],\n",
       "       [9.99845088e-01],\n",
       "       [1.61795005e-01],\n",
       "       [9.99862492e-01],\n",
       "       [9.99956906e-01],\n",
       "       [1.84307992e-02],\n",
       "       [2.52789527e-04],\n",
       "       [1.44009176e-03],\n",
       "       [7.08647538e-04],\n",
       "       [4.63303586e-05],\n",
       "       [9.99770582e-01],\n",
       "       [9.99924123e-01],\n",
       "       [1.32966504e-01],\n",
       "       [9.99786854e-01],\n",
       "       [4.12367022e-04],\n",
       "       [4.90285037e-03],\n",
       "       [2.47546122e-04],\n",
       "       [3.50626273e-04],\n",
       "       [5.39906556e-04],\n",
       "       [9.99817967e-01],\n",
       "       [1.16268231e-03],\n",
       "       [1.23298611e-04],\n",
       "       [9.99827862e-01],\n",
       "       [1.22183221e-04],\n",
       "       [1.39533047e-04],\n",
       "       [9.99793351e-01],\n",
       "       [1.68603874e-04],\n",
       "       [1.03335399e-02],\n",
       "       [1.21873585e-04],\n",
       "       [9.99860406e-01],\n",
       "       [9.42463040e-01],\n",
       "       [7.00521111e-01],\n",
       "       [1.22118704e-01],\n",
       "       [9.99254644e-01],\n",
       "       [8.23986134e-04],\n",
       "       [9.99801934e-01],\n",
       "       [6.03534980e-03],\n",
       "       [9.97176826e-01],\n",
       "       [9.95128155e-01],\n",
       "       [9.99210179e-01],\n",
       "       [5.36971493e-03],\n",
       "       [6.95033465e-04],\n",
       "       [8.42888951e-01],\n",
       "       [1.34698721e-02],\n",
       "       [2.81888177e-03],\n",
       "       [7.77752488e-04],\n",
       "       [3.16344164e-02],\n",
       "       [2.90927910e-05],\n",
       "       [1.77814427e-03],\n",
       "       [2.85096243e-02],\n",
       "       [9.99921978e-01],\n",
       "       [9.96296294e-04],\n",
       "       [5.57089634e-02],\n",
       "       [1.02972880e-01],\n",
       "       [1.57668844e-01],\n",
       "       [1.23054653e-01],\n",
       "       [5.14006242e-04],\n",
       "       [1.61749107e-04],\n",
       "       [9.99704003e-01],\n",
       "       [7.33180568e-02],\n",
       "       [3.86193782e-01],\n",
       "       [9.99969721e-01],\n",
       "       [2.39583605e-04],\n",
       "       [9.69993949e-01],\n",
       "       [1.83603898e-01],\n",
       "       [6.21095952e-03],\n",
       "       [1.22370124e-01],\n",
       "       [3.78608325e-04],\n",
       "       [1.19447000e-02],\n",
       "       [9.99663651e-01],\n",
       "       [2.06014171e-01],\n",
       "       [9.99874234e-01],\n",
       "       [3.86031598e-01],\n",
       "       [1.80360643e-04],\n",
       "       [9.99894500e-01],\n",
       "       [2.44821742e-04],\n",
       "       [9.99904871e-01],\n",
       "       [3.80561105e-03],\n",
       "       [5.43594826e-04],\n",
       "       [9.99892712e-01],\n",
       "       [1.75937894e-04],\n",
       "       [4.98860085e-04],\n",
       "       [9.99846280e-01],\n",
       "       [1.09727716e-03],\n",
       "       [8.05144082e-04],\n",
       "       [7.65499711e-01],\n",
       "       [9.99527037e-01],\n",
       "       [9.96966555e-05],\n",
       "       [2.64156749e-03],\n",
       "       [9.99853432e-01],\n",
       "       [9.99939919e-01],\n",
       "       [9.99614239e-01],\n",
       "       [2.99578726e-01],\n",
       "       [9.99143302e-01],\n",
       "       [9.96668279e-01],\n",
       "       [6.30386034e-03],\n",
       "       [6.24395907e-04],\n",
       "       [2.70603243e-02],\n",
       "       [1.74049810e-02],\n",
       "       [1.06788742e-04],\n",
       "       [6.80128336e-02],\n",
       "       [4.28161472e-02],\n",
       "       [2.97469698e-04],\n",
       "       [9.99833584e-01],\n",
       "       [9.99933243e-01],\n",
       "       [9.99931931e-01],\n",
       "       [5.15311665e-04],\n",
       "       [3.18992078e-01],\n",
       "       [4.64256853e-02],\n",
       "       [3.27641666e-01],\n",
       "       [9.98227179e-01],\n",
       "       [3.77805740e-01],\n",
       "       [6.42591622e-05],\n",
       "       [9.52132745e-04],\n",
       "       [3.88929038e-04],\n",
       "       [9.98909712e-01],\n",
       "       [9.47119435e-04],\n",
       "       [2.14699726e-03],\n",
       "       [3.49324371e-04],\n",
       "       [6.43217703e-04],\n",
       "       [2.08875045e-01],\n",
       "       [9.92440283e-01],\n",
       "       [9.34061781e-02],\n",
       "       [2.69537501e-04],\n",
       "       [1.08696474e-02],\n",
       "       [2.48817727e-04],\n",
       "       [9.99919534e-01],\n",
       "       [9.99767721e-01],\n",
       "       [9.06308234e-01],\n",
       "       [9.86537397e-01],\n",
       "       [1.25683044e-04],\n",
       "       [9.75793719e-01],\n",
       "       [9.99922037e-01],\n",
       "       [9.92776692e-01],\n",
       "       [2.10049935e-02],\n",
       "       [9.99763310e-01],\n",
       "       [7.16707623e-03],\n",
       "       [9.99942005e-01],\n",
       "       [3.14650591e-03],\n",
       "       [5.37001935e-04],\n",
       "       [3.41964990e-01],\n",
       "       [2.48261213e-01],\n",
       "       [9.99851823e-01],\n",
       "       [8.69148225e-02],\n",
       "       [7.41581534e-05],\n",
       "       [3.62087128e-04],\n",
       "       [3.77805740e-01],\n",
       "       [9.99986410e-01],\n",
       "       [6.66622800e-05],\n",
       "       [6.96495831e-01],\n",
       "       [9.99961376e-01],\n",
       "       [4.89411141e-05],\n",
       "       [9.99950051e-01],\n",
       "       [3.28049035e-04],\n",
       "       [1.52760290e-03],\n",
       "       [1.34300353e-04],\n",
       "       [9.99728143e-01],\n",
       "       [9.99677896e-01],\n",
       "       [4.75731725e-03],\n",
       "       [5.80477237e-04],\n",
       "       [9.99557853e-01],\n",
       "       [9.99908209e-01],\n",
       "       [8.24651361e-01],\n",
       "       [1.86199672e-04],\n",
       "       [3.60948057e-03],\n",
       "       [3.95117044e-01],\n",
       "       [3.88556218e-04],\n",
       "       [9.99945462e-01],\n",
       "       [2.40137652e-01],\n",
       "       [9.99944389e-01],\n",
       "       [9.99840081e-01],\n",
       "       [8.08695182e-02],\n",
       "       [8.96614254e-01],\n",
       "       [2.56482104e-04],\n",
       "       [9.99769986e-01],\n",
       "       [9.97832954e-01],\n",
       "       [9.36787069e-01],\n",
       "       [1.19380408e-03],\n",
       "       [1.78838091e-03],\n",
       "       [2.67811725e-03],\n",
       "       [1.17115953e-04],\n",
       "       [1.96202882e-02],\n",
       "       [1.14295036e-01],\n",
       "       [9.92989898e-01],\n",
       "       [2.03925581e-03],\n",
       "       [9.99954641e-01],\n",
       "       [9.99928594e-01],\n",
       "       [8.03016592e-04],\n",
       "       [8.72708082e-01],\n",
       "       [2.32704496e-03],\n",
       "       [5.81987668e-04],\n",
       "       [4.28447306e-01],\n",
       "       [9.98775005e-01],\n",
       "       [1.54883030e-03],\n",
       "       [7.77927116e-02],\n",
       "       [1.03444530e-04],\n",
       "       [5.39919222e-03],\n",
       "       [2.41023827e-05],\n",
       "       [9.99907970e-01],\n",
       "       [9.98577118e-01],\n",
       "       [9.99908388e-01],\n",
       "       [9.95072842e-01],\n",
       "       [9.41012383e-01],\n",
       "       [1.37203066e-02],\n",
       "       [5.62618552e-05],\n",
       "       [9.98446882e-01],\n",
       "       [9.99509335e-01],\n",
       "       [9.99904692e-01],\n",
       "       [5.05459495e-04],\n",
       "       [5.53623540e-03],\n",
       "       [4.21076460e-04],\n",
       "       [9.99925673e-01],\n",
       "       [9.99896944e-01],\n",
       "       [2.57434149e-04],\n",
       "       [1.01860091e-02],\n",
       "       [9.99967635e-01],\n",
       "       [6.73021143e-03],\n",
       "       [7.41188414e-03],\n",
       "       [9.98032570e-01],\n",
       "       [7.07194675e-04],\n",
       "       [5.92094788e-04],\n",
       "       [9.98589516e-01],\n",
       "       [2.94556618e-01],\n",
       "       [1.08866476e-01],\n",
       "       [9.99973595e-01],\n",
       "       [2.53578881e-04],\n",
       "       [9.62301507e-04],\n",
       "       [3.01721611e-05],\n",
       "       [1.15396040e-04],\n",
       "       [8.69535084e-04],\n",
       "       [9.99893486e-01],\n",
       "       [2.80164764e-04],\n",
       "       [7.27186203e-01],\n",
       "       [9.85153019e-01],\n",
       "       [1.15799040e-01],\n",
       "       [5.08064106e-02],\n",
       "       [6.94959890e-05],\n",
       "       [1.16205786e-03],\n",
       "       [9.99947071e-01],\n",
       "       [9.99847174e-01],\n",
       "       [5.67003991e-03],\n",
       "       [2.04121578e-04],\n",
       "       [1.98069704e-03],\n",
       "       [2.59261054e-04],\n",
       "       [9.99705493e-01],\n",
       "       [6.13964454e-04],\n",
       "       [9.99536335e-01],\n",
       "       [9.98216987e-01],\n",
       "       [9.60711598e-01],\n",
       "       [9.97226000e-01],\n",
       "       [4.95976731e-02],\n",
       "       [1.00062033e-02],\n",
       "       [4.73497639e-04],\n",
       "       [4.90998663e-02],\n",
       "       [9.23344851e-01],\n",
       "       [9.08016682e-01],\n",
       "       [1.53158069e-01],\n",
       "       [5.14519226e-04],\n",
       "       [6.08019727e-05],\n",
       "       [4.42386896e-04],\n",
       "       [1.22721829e-02],\n",
       "       [3.27625982e-02],\n",
       "       [1.42473847e-01],\n",
       "       [9.99937892e-01],\n",
       "       [9.99769986e-01],\n",
       "       [8.82056296e-01],\n",
       "       [9.99943137e-01],\n",
       "       [2.20944230e-02],\n",
       "       [1.15467270e-03],\n",
       "       [9.99769390e-01],\n",
       "       [5.26877940e-01],\n",
       "       [1.18915259e-03],\n",
       "       [2.23100752e-01],\n",
       "       [9.90423083e-01],\n",
       "       [7.86667297e-05],\n",
       "       [5.51325619e-01],\n",
       "       [9.94426668e-01],\n",
       "       [9.99650061e-01],\n",
       "       [9.99855220e-01],\n",
       "       [3.43133172e-04],\n",
       "       [5.39930053e-02],\n",
       "       [9.88160551e-01],\n",
       "       [9.87062376e-05],\n",
       "       [1.12156458e-02],\n",
       "       [9.56365913e-02],\n",
       "       [9.98895168e-01],\n",
       "       [9.82156754e-01],\n",
       "       [1.97480596e-03],\n",
       "       [6.68962137e-04],\n",
       "       [9.81424510e-01],\n",
       "       [4.53758897e-04],\n",
       "       [1.50739984e-03],\n",
       "       [6.60820078e-05],\n",
       "       [4.45554376e-01],\n",
       "       [9.99926209e-01],\n",
       "       [9.99739289e-01],\n",
       "       [1.55166595e-03],\n",
       "       [9.99865949e-01],\n",
       "       [9.99916673e-01],\n",
       "       [6.86848216e-05],\n",
       "       [9.99879539e-01],\n",
       "       [2.84233745e-02],\n",
       "       [9.97603238e-01],\n",
       "       [1.30701974e-01],\n",
       "       [1.87647215e-03],\n",
       "       [2.30740479e-04],\n",
       "       [1.53590649e-04],\n",
       "       [1.05001824e-02],\n",
       "       [8.32396618e-05],\n",
       "       [5.84972680e-01],\n",
       "       [3.10880394e-04],\n",
       "       [9.99899685e-01],\n",
       "       [8.83332454e-04],\n",
       "       [9.96648669e-01],\n",
       "       [2.87856936e-01],\n",
       "       [3.34683619e-03],\n",
       "       [3.41912033e-04],\n",
       "       [9.99954939e-01],\n",
       "       [3.72751220e-03],\n",
       "       [9.99877214e-01],\n",
       "       [4.71913904e-01],\n",
       "       [2.50339583e-02],\n",
       "       [3.01532187e-02],\n",
       "       [9.04029352e-04],\n",
       "       [7.52308071e-02],\n",
       "       [9.99916673e-01],\n",
       "       [1.54900961e-04],\n",
       "       [3.57171812e-04],\n",
       "       [8.55318177e-03],\n",
       "       [9.99920726e-01],\n",
       "       [1.21691730e-02],\n",
       "       [4.90293896e-04],\n",
       "       [9.99576509e-01],\n",
       "       [1.00762714e-04],\n",
       "       [5.88014373e-04],\n",
       "       [3.48553411e-04],\n",
       "       [9.39346477e-02],\n",
       "       [1.22160139e-03],\n",
       "       [4.39370811e-01],\n",
       "       [2.94666197e-02],\n",
       "       [9.64577962e-03],\n",
       "       [8.05599193e-05],\n",
       "       [3.72205526e-01],\n",
       "       [6.51446680e-05],\n",
       "       [9.99808490e-01],\n",
       "       [9.93492067e-01],\n",
       "       [2.95488328e-01],\n",
       "       [1.48445892e-04],\n",
       "       [7.60109862e-03],\n",
       "       [9.99946237e-01],\n",
       "       [9.82056320e-01],\n",
       "       [9.99973476e-01],\n",
       "       [7.26055645e-04],\n",
       "       [9.99648809e-01],\n",
       "       [3.77116085e-04],\n",
       "       [9.61809814e-01],\n",
       "       [9.90059555e-01],\n",
       "       [1.58590090e-04],\n",
       "       [9.99937296e-01],\n",
       "       [2.05184845e-03],\n",
       "       [9.98714566e-01],\n",
       "       [9.99972761e-01],\n",
       "       [3.97544634e-03],\n",
       "       [2.34968844e-04],\n",
       "       [5.52318096e-01],\n",
       "       [2.60549132e-04],\n",
       "       [4.84787952e-03],\n",
       "       [9.99920249e-01],\n",
       "       [4.10656005e-01],\n",
       "       [9.99830067e-01],\n",
       "       [5.95489852e-02],\n",
       "       [9.99850810e-01],\n",
       "       [9.62257087e-01],\n",
       "       [1.16953626e-02],\n",
       "       [1.35034352e-04],\n",
       "       [9.98527527e-01],\n",
       "       [1.75947629e-04],\n",
       "       [2.28133649e-01],\n",
       "       [9.99934673e-01],\n",
       "       [9.99334514e-01],\n",
       "       [9.99940097e-01],\n",
       "       [9.99793887e-01],\n",
       "       [6.37628734e-02],\n",
       "       [5.62063038e-01],\n",
       "       [4.64027253e-04],\n",
       "       [9.89409506e-01],\n",
       "       [9.97285008e-01],\n",
       "       [9.99793410e-01],\n",
       "       [3.16435733e-04],\n",
       "       [9.95995343e-01],\n",
       "       [9.99892473e-01],\n",
       "       [2.06288765e-03],\n",
       "       [2.76950211e-03],\n",
       "       [1.53158069e-01],\n",
       "       [4.03752259e-04],\n",
       "       [9.47008729e-01],\n",
       "       [9.98931468e-01],\n",
       "       [9.99906540e-01],\n",
       "       [3.25024419e-04],\n",
       "       [1.55996342e-04],\n",
       "       [2.25544281e-04],\n",
       "       [2.05597207e-01],\n",
       "       [1.46410440e-03],\n",
       "       [6.34453073e-02],\n",
       "       [9.98816311e-01],\n",
       "       [1.32135188e-04],\n",
       "       [3.21514428e-01],\n",
       "       [1.73029415e-02],\n",
       "       [9.93025899e-02],\n",
       "       [9.99782979e-01],\n",
       "       [1.51372887e-03],\n",
       "       [9.95798409e-01],\n",
       "       [1.04028545e-02],\n",
       "       [5.80051892e-05],\n",
       "       [4.02676786e-04],\n",
       "       [9.99937177e-01],\n",
       "       [9.12970006e-01],\n",
       "       [1.68159298e-04],\n",
       "       [1.22749656e-01],\n",
       "       [1.04834661e-01],\n",
       "       [1.15999959e-04],\n",
       "       [9.99836206e-01],\n",
       "       [6.52601884e-04],\n",
       "       [9.29306209e-01],\n",
       "       [9.11301747e-02],\n",
       "       [5.88406285e-04],\n",
       "       [6.02779448e-01],\n",
       "       [8.64554793e-02],\n",
       "       [7.15286657e-03],\n",
       "       [9.99915242e-01],\n",
       "       [1.22223329e-02],\n",
       "       [4.80873525e-01],\n",
       "       [9.99955535e-01],\n",
       "       [5.89119673e-01],\n",
       "       [4.62757170e-01],\n",
       "       [7.86667297e-05],\n",
       "       [3.38889539e-01],\n",
       "       [9.95754004e-01],\n",
       "       [9.99950051e-01],\n",
       "       [9.87759829e-01],\n",
       "       [1.09161679e-02],\n",
       "       [9.99926865e-01],\n",
       "       [3.51703167e-01],\n",
       "       [9.99852598e-01],\n",
       "       [3.51703167e-01],\n",
       "       [9.99935627e-01],\n",
       "       [2.02799303e-04],\n",
       "       [6.27751797e-02],\n",
       "       [1.35651499e-04],\n",
       "       [9.99939203e-01],\n",
       "       [3.04049533e-03],\n",
       "       [1.18203044e-01],\n",
       "       [1.88852369e-04],\n",
       "       [3.51833762e-03],\n",
       "       [1.77260919e-03],\n",
       "       [1.84643257e-03],\n",
       "       [4.12724689e-02],\n",
       "       [2.21104850e-03],\n",
       "       [1.28924113e-03],\n",
       "       [9.96482670e-01],\n",
       "       [4.66621201e-03],\n",
       "       [5.83321899e-02],\n",
       "       [3.35039222e-04],\n",
       "       [1.11347836e-04],\n",
       "       [4.09680307e-02],\n",
       "       [9.99236882e-01],\n",
       "       [2.87386682e-03],\n",
       "       [2.63054907e-01],\n",
       "       [9.84418392e-03],\n",
       "       [9.99128044e-01],\n",
       "       [9.99848545e-01],\n",
       "       [2.70615885e-04],\n",
       "       [1.96344728e-04],\n",
       "       [2.25444281e-04],\n",
       "       [3.26018489e-05],\n",
       "       [9.99918401e-01],\n",
       "       [1.11347836e-04],\n",
       "       [2.53042057e-02],\n",
       "       [9.99821424e-01],\n",
       "       [9.99885499e-01],\n",
       "       [9.99900281e-01],\n",
       "       [9.99977112e-01],\n",
       "       [9.99992967e-01],\n",
       "       [4.40247502e-04],\n",
       "       [1.16886564e-04],\n",
       "       [4.18021865e-02],\n",
       "       [9.44651723e-01],\n",
       "       [9.99924004e-01],\n",
       "       [8.80478084e-01],\n",
       "       [8.54411162e-04],\n",
       "       [9.99485672e-01],\n",
       "       [8.98972094e-01],\n",
       "       [6.84676488e-05],\n",
       "       [2.25035823e-04],\n",
       "       [6.34569256e-03],\n",
       "       [5.42496592e-02],\n",
       "       [1.07534397e-04],\n",
       "       [1.15183461e-03],\n",
       "       [9.90993381e-01],\n",
       "       [9.99966681e-01],\n",
       "       [2.60351459e-04],\n",
       "       [9.99913156e-01],\n",
       "       [9.96555865e-01],\n",
       "       [5.95235117e-02],\n",
       "       [1.01708630e-02],\n",
       "       [9.99680255e-04],\n",
       "       [8.62937093e-01],\n",
       "       [2.26891655e-02],\n",
       "       [1.68845028e-04]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model 3 pred probs to label format\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.08398950131233,\n",
       " 'precision': 0.7823342077218286,\n",
       " 'recall': 0.7808398950131233,\n",
       " 'f1': 0.7790338643605079}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 3 results\n",
    "model_3_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_3_preds\n",
    ")\n",
    "model_3_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidir\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model details\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_4.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidir/20230115-140520\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 16s 36ms/step - loss: 0.1061 - accuracy: 0.9693 - val_loss: 0.8600 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0516 - accuracy: 0.9761 - val_loss: 1.1719 - val_accuracy: 0.7677\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0464 - accuracy: 0.9794 - val_loss: 1.2445 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 6s 27ms/step - loss: 0.0418 - accuracy: 0.9800 - val_loss: 1.4125 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 6s 26ms/step - loss: 0.0371 - accuracy: 0.9801 - val_loss: 1.3751 - val_accuracy: 0.7690\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_4 = model_4.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_4_bidir\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.4174721e-01],\n",
       "       [7.5514436e-01],\n",
       "       [9.9996418e-01],\n",
       "       [9.8600216e-02],\n",
       "       [1.1236031e-05],\n",
       "       [9.9976200e-01],\n",
       "       [9.4622087e-01],\n",
       "       [9.9999058e-01],\n",
       "       [9.9997622e-01],\n",
       "       [8.7807655e-01]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting model's probs to the label format\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.9028871391076,\n",
       " 'precision': 0.7693974434525301,\n",
       " 'recall': 0.7690288713910761,\n",
       " 'f1': 0.7676527036976099}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking results of predictions\n",
    "model_4_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_4_preds\n",
    ")\n",
    "model_4_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 - Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing embedding layer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding_test = embedding(text_vectorizer(\"This is a test sentence\"))\n",
    "# print(embedding_test.shape)\n",
    "embedding_test = tf.expand_dims(embedding_test, axis=0)\n",
    "# print(embedding_test.shape)\n",
    "conv_1d = layers.Conv1D(\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    activation=\"relu\",\n",
    "    padding=\"valid\"\n",
    ")\n",
    "conv_1d_output = conv_1d(embedding_test)\n",
    "max_pool = layers.GlobalMaxPool1D()\n",
    "max_pool_output = max_pool(conv_1d_output)\n",
    "\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 - 1D Convolutional Network layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"input_layer\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(\n",
    "    filters=64,\n",
    "    kernel_size=5,\n",
    "    strides=1,\n",
    "    activation=\"relu\",\n",
    "    padding=\"valid\"\n",
    ")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_conv1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_conv1d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321,089\n",
      "Trainable params: 1,321,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model details\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_5.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_conv1d/20230115-140601\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 23ms/step - loss: 0.1282 - accuracy: 0.9555 - val_loss: 0.8809 - val_accuracy: 0.7730\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0754 - accuracy: 0.9720 - val_loss: 1.0246 - val_accuracy: 0.7651\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.0615 - accuracy: 0.9762 - val_loss: 1.1349 - val_accuracy: 0.7598\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.0558 - accuracy: 0.9772 - val_loss: 1.1829 - val_accuracy: 0.7638\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.0505 - accuracy: 0.9788 - val_loss: 1.2500 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_5 = model_5.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_5_conv1d\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.3906347e-01],\n",
       "       [8.8784599e-01],\n",
       "       [9.9995393e-01],\n",
       "       [5.0555877e-02],\n",
       "       [5.5122968e-08],\n",
       "       [9.9883574e-01],\n",
       "       [9.8082507e-01],\n",
       "       [9.9998611e-01],\n",
       "       [9.9999970e-01],\n",
       "       [9.3652105e-01]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting probs into label format\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.77165354330708,\n",
       " 'precision': 0.7681410880728078,\n",
       " 'recall': 0.7677165354330708,\n",
       " 'f1': 0.7662770891654436}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model's predictions\n",
    "model_5_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_5_preds\n",
    ")\n",
    "model_5_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6 - TensorflowHub pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01602832  0.01068848  0.02425467 -0.01405769  0.01434426  0.08292625\n",
      "  0.01963372  0.06160142 -0.00352702 -0.01216412  0.00978647 -0.01248495\n",
      "  0.01232345  0.09748451  0.06141113 -0.03728353  0.01860884 -0.04669856\n",
      "  0.00413913 -0.06363907 -0.02469898  0.02713691  0.02284444 -0.00210026\n",
      " -0.00630592 -0.03964961  0.02220404  0.00115077 -0.03132177  0.00119527\n",
      " -0.0401255   0.04561892 -0.01530598 -0.00175918  0.02173131 -0.08450424\n",
      "  0.03340026  0.04604554 -0.0248025  -0.08681665  0.00702694 -0.00770478\n",
      " -0.01434539  0.07814164 -0.10676058 -0.05152997 -0.00858155 -0.03232232\n",
      " -0.03871097  0.02581467], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Reusing USE (Universal Sentence Encoder) model\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embed_samples = embed([\n",
    "    sample_sentence,\n",
    "    \"When you apple USE to text, it converts it into numbers\"\n",
    "])\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling shape\n",
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "# Creating layer with USE pretrained model\n",
    "sentence_encoder_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "    input_shape=[],\n",
    "    dtype=tf.string,\n",
    "    trainable=False,\n",
    "    name=\"USE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a new model with pretrained layer\n",
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    # layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_6.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_6_use/20230115-182143\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 11s 23ms/step - loss: 0.6476 - accuracy: 0.7399 - val_loss: 0.6137 - val_accuracy: 0.7717\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.5809 - accuracy: 0.7889 - val_loss: 0.5641 - val_accuracy: 0.7822\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.5384 - accuracy: 0.7962 - val_loss: 0.5328 - val_accuracy: 0.7848\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.5097 - accuracy: 0.7994 - val_loss: 0.5114 - val_accuracy: 0.7900\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.4897 - accuracy: 0.8009 - val_loss: 0.4971 - val_accuracy: 0.7913\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_6 = model_6.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_6_use\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_use\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,798,337\n",
      "Trainable params: 513\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking the model details\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.36288318],\n",
       "       [0.6738508 ],\n",
       "       [0.8496174 ],\n",
       "       [0.37130713],\n",
       "       [0.64633924],\n",
       "       [0.7301284 ],\n",
       "       [0.825036  ],\n",
       "       [0.8416656 ],\n",
       "       [0.75820655],\n",
       "       [0.18755515]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting prediction probs into label format\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.13385826771653,\n",
       " 'precision': 0.7918101082010836,\n",
       " 'recall': 0.7913385826771654,\n",
       " 'f1': 0.7902401820506462}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating model's performance metrics\n",
    "model_6_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_6_preds\n",
    ")\n",
    "model_6_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 - Pretrained USE with 10% of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761, 761)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating subset of 10% training data\n",
    "train_data_10p = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
    "train_sentences_10p = train_data_10p[\"text\"].to_list()\n",
    "train_labels_10p = train_data_10p[\"target\"].to_list()\n",
    "len(train_sentences_10p), len(train_labels_10p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the length of original dataset\n",
    "len(train_df_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    413\n",
       "1    348\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of targets - 10%\n",
    "train_data_10p[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of targets - Full set\n",
    "train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_use\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,798,337\n",
      "Trainable params: 513\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cloning model 6\n",
    "model_7 = tf.keras.models.clone_model(model_6)\n",
    "\n",
    "# Compiling the model\n",
    "model_7.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Checking the model details\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_7_use/20230115-210344\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 7s 69ms/step - loss: 0.6809 - accuracy: 0.6715 - val_loss: 0.6737 - val_accuracy: 0.7152\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.6685 - accuracy: 0.7385 - val_loss: 0.6622 - val_accuracy: 0.7533\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 1s 25ms/step - loss: 0.6572 - accuracy: 0.7530 - val_loss: 0.6512 - val_accuracy: 0.7651\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.6466 - accuracy: 0.7661 - val_loss: 0.6406 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 1s 30ms/step - loss: 0.6364 - accuracy: 0.7740 - val_loss: 0.6308 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_7 = model_7.fit(\n",
    "    train_sentences_10p,\n",
    "    train_labels_10p,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_7_use\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48890504],\n",
       "       [0.51846015],\n",
       "       [0.5969771 ],\n",
       "       [0.4629081 ],\n",
       "       [0.5366968 ],\n",
       "       [0.5619528 ],\n",
       "       [0.5732625 ],\n",
       "       [0.62088543],\n",
       "       [0.5592856 ],\n",
       "       [0.42308325]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting pred probs to label format\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7798994748039346,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7796651050286317}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model predictions\n",
    "model_7_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_7_preds\n",
    ")\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8230a386d8e0083990873cddb8ebb5b6213275a10339230a8504f0ef8ce7f888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
