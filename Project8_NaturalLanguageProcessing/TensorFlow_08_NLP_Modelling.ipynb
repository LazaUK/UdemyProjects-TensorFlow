{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "# Importing TF and checking the version\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing helper functions\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"NLP_text/train.csv\")\n",
    "test_df = pd.read_csv(\"NLP_text/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking test dataframe\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of training records\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking total number of samples\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Myanmar Flooding: Heavy monsoon rains during the month of July have caused flooding flash floods and landsli... http://t.co/9TG7A5OqFP\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "I've just watched episode S01E09 of Bloody Monday! http://t.co/vRptHvPymt #bloodymonday #tvshowtime http://t.co/NkKvknBvOz\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@whvholst @leashless And this is a structural problem rather than just a failure of competence by traditional soc democratic parties.\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "I SCREAMED 'WHATS A CHONCe' http://t.co/GXYivsWki7\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@FaZe_Rain all hail the Cloud\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Visualising random samples\n",
    "import random\n",
    "\n",
    "random_index = random.randint(0, len(train_df) - 5)\n",
    "\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index : random_index + 5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size=0.1, # Allocating 10% to validation data\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dataset length\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting text to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using text vectorisation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=None,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=None,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the average number of tokens\n",
    "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up text vectorisation variables\n",
    "max_vocab_length = 10000\n",
    "max_length = 15\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting text vectorisation to the training dataset\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentnence and tokenise it\n",
    "sample_sentence = \"There is a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Las Vegas in top 5 cities for red-light running fatalities - News3LV http://t.co/eXdbcx4gCR,\n",
      "tokenised version:\n",
      "[[3691 3284    4  212  180 2523   10 2752  876  301    1    1    0    0\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenising random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\ntokenised version:\\n{text_vectorizer([random_sentence])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " ['', '[UNK]', 'the', 'a', 'in'],\n",
       " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "\n",
    "len(words_in_vocab), top_5_words, bottom_5_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x20d95cffa00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the layer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    input_length=max_length\n",
    ")\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "One man fatally shot another wounded on Vermont Street #Buffalo - http://t.co/KakY4mpCO4,\n",
      "embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.00968846,  0.01396506, -0.0358798 , ...,  0.00607602,\n",
       "         -0.03935768, -0.03889903],\n",
       "        [-0.04239941, -0.03526977,  0.02661167, ..., -0.02152009,\n",
       "          0.00812198,  0.04224873],\n",
       "        [-0.01915747, -0.02273409, -0.03975364, ..., -0.00230503,\n",
       "         -0.03034551, -0.02134173],\n",
       "        ...,\n",
       "        [-0.02363898, -0.03911495,  0.00859547, ..., -0.01244408,\n",
       "         -0.04660244,  0.04752853],\n",
       "        [-0.02363898, -0.03911495,  0.00859547, ..., -0.01244408,\n",
       "         -0.04660244,  0.04752853],\n",
       "        [-0.02363898, -0.03911495,  0.00859547, ..., -0.01244408,\n",
       "         -0.04660244,  0.04752853]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\nembedded version:\"\n",
    ")\n",
    "\n",
    "# Embed random sentence\n",
    "embed_sentence = embedding(text_vectorizer([random_sentence]))\n",
    "embed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-0.00968846,  0.01396506, -0.0358798 , -0.00579258,  0.02711185,\n",
       "         0.03818165,  0.02656038, -0.0049054 , -0.03423984, -0.03988526,\n",
       "         0.0453656 ,  0.03061196,  0.03256241,  0.03272395, -0.01565869,\n",
       "         0.01551572,  0.03512523,  0.00894897, -0.03341515,  0.04608497,\n",
       "        -0.03900247, -0.00272442, -0.03066324, -0.00293616, -0.00038679,\n",
       "        -0.01755118,  0.00121274, -0.03629506,  0.0486945 , -0.02841423,\n",
       "        -0.01149614,  0.00770857, -0.01488087,  0.00182436, -0.02239796,\n",
       "        -0.02087336, -0.04782781,  0.03007961,  0.02408793,  0.01827877,\n",
       "         0.03313423, -0.02629081,  0.02351326, -0.01033636,  0.04921806,\n",
       "        -0.02374013, -0.04042191,  0.01003786,  0.03435279, -0.03145609,\n",
       "         0.02293422, -0.00025246, -0.04681561,  0.03124117,  0.02302232,\n",
       "         0.04082045,  0.00339414, -0.0206479 , -0.04246751,  0.02989384,\n",
       "        -0.02727183, -0.04942685,  0.00523769, -0.0419889 ,  0.02113746,\n",
       "        -0.00034474,  0.00938748, -0.01737405, -0.01774981, -0.02294124,\n",
       "        -0.00934278,  0.01263738, -0.01781274,  0.03540291, -0.04630768,\n",
       "         0.0040959 ,  0.02506126,  0.03152034,  0.00030104, -0.0343575 ,\n",
       "        -0.04470892, -0.04193069,  0.02916275,  0.01703059,  0.01609406,\n",
       "         0.02240164, -0.01800882, -0.00673274, -0.01236082,  0.04360266,\n",
       "         0.01634199, -0.03923428, -0.04334262, -0.03932346, -0.03010086,\n",
       "        -0.03726643,  0.04640952,  0.0366088 , -0.01611609,  0.03331215,\n",
       "        -0.03637252, -0.03427546,  0.00386994,  0.00114913,  0.01422044,\n",
       "         0.00789623, -0.03652866, -0.03639565,  0.03054387, -0.0408236 ,\n",
       "         0.04420468,  0.01720489,  0.01876105, -0.03964525, -0.03252466,\n",
       "        -0.03457095, -0.0030582 , -0.02690776,  0.04203186,  0.00449472,\n",
       "        -0.00913781, -0.02008848, -0.01395677,  0.00898371,  0.01542449,\n",
       "         0.00607602, -0.03935768, -0.03889903], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " 'One man fatally shot another wounded on Vermont Street #Buffalo - http://t.co/KakY4mpCO4')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking single token's embedding\n",
    "embed_sentence[0][0], embed_sentence[0][0].shape, random_sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using SKLearn to build base model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenisation and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # Convert words to numbers\n",
    "    (\"clf\", MultinomialNB()) # Model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved accuracy: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Achieved accuracy: {baseline_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "baseline_predictions = model_0.predict(val_sentences)\n",
    "baseline_predictions[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SKLearn functions\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Developing function to evaluate accuracy, precision, recall and F1 scor\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate binary classification model\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and F1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1\n",
    "    }\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting baseline results\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=baseline_predictions\n",
    ")\n",
    "baseline_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: a simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensorboard callback\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback\n",
    "\n",
    "# Creating log directory\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model with Functional API\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype=tf.string)\n",
    "x = text_vectorizer(inputs) # Turn the input text into numbers\n",
    "x = embedding(x) # Create embedding of numberised inputs\n",
    "x = layers.GlobalAveragePooling1D()(x) # Condence the feature vector\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20230113-184557\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.6140 - accuracy: 0.6967 - val_loss: 0.5370 - val_accuracy: 0.7520\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.4437 - accuracy: 0.8187 - val_loss: 0.4720 - val_accuracy: 0.7874\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.3488 - accuracy: 0.8597 - val_loss: 0.4568 - val_accuracy: 0.7913\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.2870 - accuracy: 0.8863 - val_loss: 0.4637 - val_accuracy: 0.7900\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.2395 - accuracy: 0.9083 - val_loss: 0.4765 - val_accuracy: 0.7808\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_1 = model_1.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_1_dense\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4765395522117615, 0.7808399200439453]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43406558],\n",
       "       [0.795222  ],\n",
       "       [0.9969521 ],\n",
       "       [0.13736199],\n",
       "       [0.13006048],\n",
       "       [0.9461528 ],\n",
       "       [0.9262485 ],\n",
       "       [0.99350214],\n",
       "       [0.9615118 ],\n",
       "       [0.31837198]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 10 predictions\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model predictions to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.08398950131233,\n",
       " 'precision': 0.783783808499639,\n",
       " 'recall': 0.7808398950131233,\n",
       " 'f1': 0.7783998521836788}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating model 1 results\n",
    "model_1_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_1_preds\n",
    ")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving baseline results\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing model results\n",
    "import numpy as np\n",
    "\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting vocabulary from the text vectorisation layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model 1 details\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[-0.00769289, -0.05575653, -0.00751088, ..., -0.02065393,\n",
       "          -0.06312703,  0.06436224],\n",
       "         [ 0.0389185 ,  0.00975791,  0.02301645, ...,  0.01619697,\n",
       "          -0.02994848, -0.03841233],\n",
       "         [-0.03964905, -0.02566376, -0.00914194, ..., -0.02870046,\n",
       "           0.02779888,  0.00269444],\n",
       "         ...,\n",
       "         [-0.01721511,  0.02341035, -0.02402272, ..., -0.01825237,\n",
       "           0.0126978 , -0.04923532],\n",
       "         [ 0.05241601, -0.06995192, -0.03782928, ..., -0.04998912,\n",
       "          -0.02318824,  0.02081083],\n",
       "         [ 0.03481236, -0.09860085, -0.09675076, ..., -0.01369869,\n",
       "          -0.03498197,  0.04565519]], dtype=float32)],\n",
       " (10000, 128))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the weights\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()\n",
    "embed_weights, embed_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating embedding files (sample from TF Word Embedding documentation)\n",
    "import io\n",
    "\n",
    "out_v = io.open(\"vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
    "out_m = io.open(\"metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "    if index == 0:\n",
    "        continue # Skip 0, as it's a padding\n",
    "    vec = embed_weights[0][index]\n",
    "    out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated vectors.tsv and metadata.tsv can be uploaded into Tensorflow Embedding Projector tool at https://projector.tensorflow.org/ to visualise weights in 3D space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - RNN (Recurrent Neural Network) with LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# CReating an RNN model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(units=64, return_sequences=True)(x) # Sequences required when you stack LSTM layers\n",
    "# print(x.shape)\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model's summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230113-184617\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 19ms/step - loss: 0.2174 - accuracy: 0.9212 - val_loss: 0.6148 - val_accuracy: 0.7848\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.1570 - accuracy: 0.9400 - val_loss: 0.6301 - val_accuracy: 0.7743\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 16ms/step - loss: 0.1285 - accuracy: 0.9505 - val_loss: 0.6412 - val_accuracy: 0.7795\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.1042 - accuracy: 0.9585 - val_loss: 0.7806 - val_accuracy: 0.7795\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0821 - accuracy: 0.9677 - val_loss: 1.0548 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "# Fittting the model\n",
    "history_2 = model_2.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_2_LSTM\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.5964566e-02],\n",
       "       [9.4831741e-01],\n",
       "       [9.9968791e-01],\n",
       "       [1.8260200e-01],\n",
       "       [1.4974400e-04],\n",
       "       [9.9891931e-01],\n",
       "       [9.2977363e-01],\n",
       "       [9.9983412e-01],\n",
       "       [9.9968874e-01],\n",
       "       [6.6843361e-01]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting pred probs to label format\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7797634583030512,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7784163768415738}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate model 2 results\n",
    "model_2_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_2_preds\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - RNN with GRU (gated recurrent unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True)(x) # Sequences, if GRU are stuck on each other\n",
    "x = layers.GRU(64)(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x) # If we want to consolidate GRU layer with sequences\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_3.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20230113-184639\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 7s 18ms/step - loss: 0.1575 - accuracy: 0.9393 - val_loss: 0.7278 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0828 - accuracy: 0.9695 - val_loss: 0.7587 - val_accuracy: 0.7769\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0673 - accuracy: 0.9739 - val_loss: 0.8129 - val_accuracy: 0.7703\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0616 - accuracy: 0.9747 - val_loss: 1.3231 - val_accuracy: 0.7690\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0515 - accuracy: 0.9764 - val_loss: 1.1933 - val_accuracy: 0.7717\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_3 = model_3.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_3_GRU\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.95823042e-04],\n",
       "       [6.76481485e-01],\n",
       "       [9.99863863e-01],\n",
       "       [1.01334974e-01],\n",
       "       [7.28685191e-05],\n",
       "       [9.99664783e-01],\n",
       "       [8.81450176e-01],\n",
       "       [9.99928951e-01],\n",
       "       [9.99872983e-01],\n",
       "       [7.25330830e-01],\n",
       "       [2.27102675e-04],\n",
       "       [7.77818561e-01],\n",
       "       [1.62134995e-04],\n",
       "       [1.95992500e-01],\n",
       "       [6.43431049e-05],\n",
       "       [1.33154762e-03],\n",
       "       [5.01151837e-04],\n",
       "       [1.76692920e-04],\n",
       "       [8.54680687e-03],\n",
       "       [9.99755621e-01],\n",
       "       [9.99021292e-01],\n",
       "       [3.96493997e-05],\n",
       "       [9.99305308e-01],\n",
       "       [1.75265118e-03],\n",
       "       [9.99880791e-01],\n",
       "       [9.99903202e-01],\n",
       "       [9.19120561e-04],\n",
       "       [5.27382188e-04],\n",
       "       [1.56360591e-04],\n",
       "       [2.04580560e-01],\n",
       "       [9.98946130e-01],\n",
       "       [6.88185915e-04],\n",
       "       [3.36996443e-03],\n",
       "       [1.66688778e-03],\n",
       "       [2.31705040e-01],\n",
       "       [2.85641432e-01],\n",
       "       [9.99790013e-01],\n",
       "       [2.04382196e-01],\n",
       "       [2.57885996e-02],\n",
       "       [9.99939203e-01],\n",
       "       [1.82670653e-01],\n",
       "       [3.63120089e-05],\n",
       "       [9.55181122e-02],\n",
       "       [2.51295540e-04],\n",
       "       [9.27942455e-01],\n",
       "       [9.99782205e-01],\n",
       "       [9.97064531e-01],\n",
       "       [9.11797583e-01],\n",
       "       [4.01332462e-03],\n",
       "       [4.53872263e-01],\n",
       "       [3.36087705e-03],\n",
       "       [4.60294336e-01],\n",
       "       [2.70376983e-03],\n",
       "       [1.05773134e-03],\n",
       "       [7.68244147e-01],\n",
       "       [1.92000475e-02],\n",
       "       [2.13886931e-04],\n",
       "       [9.99748230e-01],\n",
       "       [2.07949692e-04],\n",
       "       [1.08836323e-03],\n",
       "       [3.25662941e-02],\n",
       "       [9.99831975e-01],\n",
       "       [9.95625138e-01],\n",
       "       [1.14021115e-02],\n",
       "       [9.99903500e-01],\n",
       "       [9.99931991e-01],\n",
       "       [9.91302371e-01],\n",
       "       [2.70030797e-02],\n",
       "       [9.65670466e-01],\n",
       "       [1.32527323e-02],\n",
       "       [9.27992072e-03],\n",
       "       [4.94830869e-02],\n",
       "       [9.99927163e-01],\n",
       "       [6.94679155e-04],\n",
       "       [4.77986634e-02],\n",
       "       [9.96980667e-01],\n",
       "       [3.60265896e-02],\n",
       "       [9.99164045e-01],\n",
       "       [8.66198242e-02],\n",
       "       [2.61600703e-01],\n",
       "       [5.22443152e-04],\n",
       "       [9.36402157e-02],\n",
       "       [9.99905705e-01],\n",
       "       [4.76470916e-04],\n",
       "       [6.73480274e-04],\n",
       "       [5.67227020e-04],\n",
       "       [3.30313604e-04],\n",
       "       [4.32390079e-04],\n",
       "       [5.84634580e-03],\n",
       "       [9.99725401e-01],\n",
       "       [9.99804676e-01],\n",
       "       [7.83936994e-05],\n",
       "       [9.76406455e-01],\n",
       "       [1.38475341e-04],\n",
       "       [9.99897063e-01],\n",
       "       [7.19238758e-01],\n",
       "       [9.45781171e-01],\n",
       "       [9.99938011e-01],\n",
       "       [9.99581218e-01],\n",
       "       [9.91366446e-01],\n",
       "       [9.99965668e-01],\n",
       "       [4.92247567e-03],\n",
       "       [8.28621996e-05],\n",
       "       [9.96519804e-01],\n",
       "       [9.99655604e-01],\n",
       "       [1.31771136e-02],\n",
       "       [9.98408318e-01],\n",
       "       [9.96257484e-01],\n",
       "       [3.84946616e-04],\n",
       "       [9.99727905e-01],\n",
       "       [9.98774946e-01],\n",
       "       [4.06933133e-04],\n",
       "       [9.46391895e-02],\n",
       "       [1.10380177e-03],\n",
       "       [3.88082583e-04],\n",
       "       [2.44937707e-02],\n",
       "       [5.08424640e-01],\n",
       "       [9.99758661e-01],\n",
       "       [3.88216157e-03],\n",
       "       [1.26351035e-04],\n",
       "       [9.99921858e-01],\n",
       "       [7.63301941e-05],\n",
       "       [9.48594316e-05],\n",
       "       [9.75155592e-01],\n",
       "       [1.13530515e-03],\n",
       "       [4.50927095e-04],\n",
       "       [9.99534488e-01],\n",
       "       [8.72928140e-05],\n",
       "       [1.04966608e-03],\n",
       "       [9.98765409e-01],\n",
       "       [1.88057241e-03],\n",
       "       [9.99921858e-01],\n",
       "       [9.99936521e-01],\n",
       "       [9.99903202e-01],\n",
       "       [9.99783218e-01],\n",
       "       [3.04546527e-04],\n",
       "       [9.99833465e-01],\n",
       "       [6.62367642e-02],\n",
       "       [2.12859293e-03],\n",
       "       [2.31632730e-04],\n",
       "       [9.99912322e-01],\n",
       "       [8.43615055e-01],\n",
       "       [1.95992500e-01],\n",
       "       [9.99362171e-01],\n",
       "       [1.31954491e-01],\n",
       "       [7.59369868e-04],\n",
       "       [1.13239345e-04],\n",
       "       [5.26645781e-05],\n",
       "       [6.60391569e-01],\n",
       "       [9.99831796e-01],\n",
       "       [3.53811105e-04],\n",
       "       [1.24713415e-02],\n",
       "       [8.10855883e-04],\n",
       "       [2.36068954e-04],\n",
       "       [1.69489766e-04],\n",
       "       [9.99597013e-01],\n",
       "       [9.93804276e-01],\n",
       "       [1.14402862e-03],\n",
       "       [9.98663425e-01],\n",
       "       [2.00189577e-04],\n",
       "       [9.99813616e-01],\n",
       "       [1.32085301e-03],\n",
       "       [7.89734945e-02],\n",
       "       [9.99261796e-01],\n",
       "       [1.67073935e-01],\n",
       "       [4.62266944e-05],\n",
       "       [9.99899745e-01],\n",
       "       [4.72149476e-02],\n",
       "       [9.99881446e-01],\n",
       "       [4.60958123e-01],\n",
       "       [9.99889672e-01],\n",
       "       [9.98741269e-01],\n",
       "       [9.99718368e-01],\n",
       "       [3.08969553e-04],\n",
       "       [9.99972463e-01],\n",
       "       [4.01208643e-04],\n",
       "       [3.42038693e-03],\n",
       "       [8.18136893e-03],\n",
       "       [6.66354954e-01],\n",
       "       [9.99884546e-01],\n",
       "       [4.29430889e-04],\n",
       "       [9.90256846e-01],\n",
       "       [9.99801040e-01],\n",
       "       [9.99892473e-01],\n",
       "       [9.99896348e-01],\n",
       "       [2.54543673e-04],\n",
       "       [3.86337546e-04],\n",
       "       [9.99974906e-01],\n",
       "       [9.08250877e-05],\n",
       "       [7.24627243e-05],\n",
       "       [1.92574726e-03],\n",
       "       [9.99481380e-01],\n",
       "       [3.49107926e-04],\n",
       "       [2.64074886e-04],\n",
       "       [1.25596780e-04],\n",
       "       [2.99005682e-04],\n",
       "       [3.00164422e-04],\n",
       "       [1.16409513e-03],\n",
       "       [9.99691665e-01],\n",
       "       [7.82378658e-04],\n",
       "       [1.43518865e-01],\n",
       "       [9.99861062e-01],\n",
       "       [9.99797046e-01],\n",
       "       [7.03621004e-03],\n",
       "       [3.01163702e-04],\n",
       "       [9.99860466e-01],\n",
       "       [9.99719083e-01],\n",
       "       [9.99835610e-01],\n",
       "       [5.84647775e-01],\n",
       "       [9.91919577e-01],\n",
       "       [6.57642484e-02],\n",
       "       [9.99810696e-01],\n",
       "       [1.94528591e-04],\n",
       "       [7.78544403e-04],\n",
       "       [1.40961565e-04],\n",
       "       [1.14607457e-04],\n",
       "       [9.99861479e-01],\n",
       "       [9.50297415e-01],\n",
       "       [9.98018384e-01],\n",
       "       [4.29205716e-01],\n",
       "       [3.00087780e-01],\n",
       "       [4.56270704e-04],\n",
       "       [4.24933014e-03],\n",
       "       [1.05144561e-03],\n",
       "       [9.99826491e-01],\n",
       "       [1.33259315e-02],\n",
       "       [2.77839904e-03],\n",
       "       [9.99959707e-01],\n",
       "       [9.99019504e-01],\n",
       "       [1.06001180e-02],\n",
       "       [1.70411833e-04],\n",
       "       [4.85576503e-03],\n",
       "       [9.99018967e-01],\n",
       "       [3.74538571e-01],\n",
       "       [4.87043738e-01],\n",
       "       [2.55397893e-02],\n",
       "       [1.24674305e-01],\n",
       "       [6.19723424e-02],\n",
       "       [3.30561539e-04],\n",
       "       [3.00851505e-04],\n",
       "       [9.99347508e-01],\n",
       "       [1.71489792e-03],\n",
       "       [9.99875665e-01],\n",
       "       [9.99781013e-01],\n",
       "       [3.89891095e-04],\n",
       "       [9.11217794e-05],\n",
       "       [9.99758720e-01],\n",
       "       [1.50788663e-04],\n",
       "       [4.86331247e-03],\n",
       "       [1.30117089e-01],\n",
       "       [3.08492745e-04],\n",
       "       [9.98147070e-01],\n",
       "       [8.12492508e-05],\n",
       "       [1.85176765e-03],\n",
       "       [9.99758601e-01],\n",
       "       [9.58585218e-02],\n",
       "       [9.99830782e-01],\n",
       "       [9.99937773e-01],\n",
       "       [2.75358688e-02],\n",
       "       [2.22926974e-04],\n",
       "       [6.50324509e-04],\n",
       "       [2.54882209e-04],\n",
       "       [3.00275187e-05],\n",
       "       [9.99663651e-01],\n",
       "       [9.99875426e-01],\n",
       "       [4.58397064e-03],\n",
       "       [9.99708772e-01],\n",
       "       [2.00748298e-04],\n",
       "       [1.76625443e-03],\n",
       "       [2.13625259e-04],\n",
       "       [2.44595896e-04],\n",
       "       [1.50993117e-04],\n",
       "       [9.99750376e-01],\n",
       "       [1.16586755e-03],\n",
       "       [1.04317340e-04],\n",
       "       [9.99766946e-01],\n",
       "       [8.24406889e-05],\n",
       "       [1.70643689e-04],\n",
       "       [9.99563575e-01],\n",
       "       [1.48051069e-04],\n",
       "       [3.45679559e-02],\n",
       "       [7.86617020e-05],\n",
       "       [9.99812663e-01],\n",
       "       [9.66610193e-01],\n",
       "       [5.85137129e-01],\n",
       "       [1.08468831e-02],\n",
       "       [9.98262942e-01],\n",
       "       [2.19465559e-03],\n",
       "       [9.98316109e-01],\n",
       "       [2.04345286e-02],\n",
       "       [9.84154463e-01],\n",
       "       [9.85093951e-01],\n",
       "       [9.68259633e-01],\n",
       "       [3.77633749e-03],\n",
       "       [6.56149816e-04],\n",
       "       [2.95107454e-01],\n",
       "       [3.88078648e-03],\n",
       "       [1.35896401e-03],\n",
       "       [5.68524178e-04],\n",
       "       [1.60731599e-02],\n",
       "       [3.62044048e-05],\n",
       "       [6.70849055e-04],\n",
       "       [4.24082624e-03],\n",
       "       [9.99893963e-01],\n",
       "       [4.79597977e-04],\n",
       "       [2.01792475e-02],\n",
       "       [3.07746734e-02],\n",
       "       [1.79209366e-01],\n",
       "       [3.13347690e-02],\n",
       "       [5.10168669e-04],\n",
       "       [1.21159806e-04],\n",
       "       [9.99543846e-01],\n",
       "       [2.04503417e-01],\n",
       "       [2.52806216e-01],\n",
       "       [9.99953270e-01],\n",
       "       [2.48784287e-04],\n",
       "       [8.20893466e-01],\n",
       "       [4.35831770e-02],\n",
       "       [2.05482077e-03],\n",
       "       [6.85440227e-02],\n",
       "       [3.17566883e-04],\n",
       "       [1.16913682e-02],\n",
       "       [9.99431193e-01],\n",
       "       [6.93632197e-03],\n",
       "       [9.99821544e-01],\n",
       "       [1.14865027e-01],\n",
       "       [1.73753098e-04],\n",
       "       [9.99862552e-01],\n",
       "       [1.89821105e-04],\n",
       "       [9.99870837e-01],\n",
       "       [2.10023671e-03],\n",
       "       [7.87847675e-04],\n",
       "       [9.99857187e-01],\n",
       "       [1.36072136e-04],\n",
       "       [2.16327797e-04],\n",
       "       [9.99728680e-01],\n",
       "       [4.40062897e-04],\n",
       "       [2.53934576e-03],\n",
       "       [8.41470718e-01],\n",
       "       [9.99240220e-01],\n",
       "       [1.35939219e-04],\n",
       "       [1.14729512e-03],\n",
       "       [9.99789774e-01],\n",
       "       [9.99893606e-01],\n",
       "       [9.99574244e-01],\n",
       "       [7.70206898e-02],\n",
       "       [9.87480760e-01],\n",
       "       [9.97074783e-01],\n",
       "       [2.83313706e-03],\n",
       "       [3.00738466e-04],\n",
       "       [2.07864307e-02],\n",
       "       [1.85230281e-02],\n",
       "       [1.38376345e-04],\n",
       "       [1.06843840e-02],\n",
       "       [9.01025161e-02],\n",
       "       [1.20381083e-04],\n",
       "       [9.99756813e-01],\n",
       "       [9.99903202e-01],\n",
       "       [9.99912381e-01],\n",
       "       [5.36653271e-04],\n",
       "       [2.16833264e-01],\n",
       "       [2.91670691e-02],\n",
       "       [2.54139286e-02],\n",
       "       [9.86321867e-01],\n",
       "       [3.55723619e-01],\n",
       "       [7.01967510e-05],\n",
       "       [3.46195709e-04],\n",
       "       [3.25226487e-04],\n",
       "       [9.98638630e-01],\n",
       "       [1.15910429e-03],\n",
       "       [1.12838121e-02],\n",
       "       [1.19584904e-04],\n",
       "       [3.94354545e-04],\n",
       "       [6.49290979e-02],\n",
       "       [9.16595459e-01],\n",
       "       [4.62606400e-02],\n",
       "       [1.45465485e-04],\n",
       "       [6.35404373e-04],\n",
       "       [2.17585897e-04],\n",
       "       [9.99910712e-01],\n",
       "       [9.99556541e-01],\n",
       "       [8.62610757e-01],\n",
       "       [9.68515396e-01],\n",
       "       [1.13006136e-04],\n",
       "       [8.87130320e-01],\n",
       "       [9.99894083e-01],\n",
       "       [9.88915443e-01],\n",
       "       [5.92581220e-02],\n",
       "       [9.99748170e-01],\n",
       "       [1.94284495e-03],\n",
       "       [9.99882340e-01],\n",
       "       [1.25783980e-02],\n",
       "       [7.33405817e-04],\n",
       "       [1.49122745e-01],\n",
       "       [8.31166580e-02],\n",
       "       [9.99788523e-01],\n",
       "       [5.96251301e-02],\n",
       "       [3.52909701e-05],\n",
       "       [1.55198737e-04],\n",
       "       [3.55723619e-01],\n",
       "       [9.99976873e-01],\n",
       "       [7.32699991e-05],\n",
       "       [2.92639405e-01],\n",
       "       [9.99940872e-01],\n",
       "       [4.12029658e-05],\n",
       "       [9.99921858e-01],\n",
       "       [2.43071729e-04],\n",
       "       [6.68723427e-04],\n",
       "       [1.26761341e-04],\n",
       "       [9.99654174e-01],\n",
       "       [9.88284528e-01],\n",
       "       [2.12999713e-03],\n",
       "       [2.89156218e-04],\n",
       "       [9.98932779e-01],\n",
       "       [9.99860525e-01],\n",
       "       [7.04268038e-01],\n",
       "       [2.56864383e-04],\n",
       "       [1.69231638e-03],\n",
       "       [1.16793476e-01],\n",
       "       [3.13209806e-04],\n",
       "       [9.99915183e-01],\n",
       "       [3.59011292e-01],\n",
       "       [9.99916136e-01],\n",
       "       [9.99766171e-01],\n",
       "       [1.32539356e-02],\n",
       "       [2.95302898e-01],\n",
       "       [5.42852329e-04],\n",
       "       [9.99641538e-01],\n",
       "       [9.83412504e-01],\n",
       "       [9.85976398e-01],\n",
       "       [1.04073267e-02],\n",
       "       [1.32394384e-03],\n",
       "       [5.57050982e-04],\n",
       "       [1.01129175e-04],\n",
       "       [4.44593281e-03],\n",
       "       [1.85853289e-03],\n",
       "       [9.88884628e-01],\n",
       "       [1.23948068e-03],\n",
       "       [9.99932885e-01],\n",
       "       [9.99903738e-01],\n",
       "       [1.23961642e-03],\n",
       "       [6.76481485e-01],\n",
       "       [4.27700626e-03],\n",
       "       [2.19727837e-04],\n",
       "       [3.47901255e-01],\n",
       "       [9.96153831e-01],\n",
       "       [1.44095114e-03],\n",
       "       [8.48031938e-02],\n",
       "       [8.22364673e-05],\n",
       "       [1.91190676e-03],\n",
       "       [2.66432125e-05],\n",
       "       [9.99842763e-01],\n",
       "       [9.99206007e-01],\n",
       "       [9.99875486e-01],\n",
       "       [9.95280027e-01],\n",
       "       [9.60366309e-01],\n",
       "       [9.94865433e-04],\n",
       "       [8.49042699e-05],\n",
       "       [8.92222464e-01],\n",
       "       [9.98778284e-01],\n",
       "       [9.99864936e-01],\n",
       "       [2.42609589e-04],\n",
       "       [5.13108214e-03],\n",
       "       [2.90934811e-04],\n",
       "       [9.99898136e-01],\n",
       "       [9.99876499e-01],\n",
       "       [5.75193670e-04],\n",
       "       [5.84705779e-03],\n",
       "       [9.99946535e-01],\n",
       "       [3.62746301e-03],\n",
       "       [1.13491658e-02],\n",
       "       [9.96657670e-01],\n",
       "       [3.82126484e-04],\n",
       "       [6.93820301e-04],\n",
       "       [9.98062849e-01],\n",
       "       [8.35815594e-02],\n",
       "       [7.56024644e-02],\n",
       "       [9.99950826e-01],\n",
       "       [1.77296402e-04],\n",
       "       [1.18903990e-03],\n",
       "       [5.48208009e-05],\n",
       "       [1.41325625e-04],\n",
       "       [3.25744099e-04],\n",
       "       [9.99859273e-01],\n",
       "       [2.30071542e-04],\n",
       "       [8.25243592e-01],\n",
       "       [9.77869987e-01],\n",
       "       [8.42910111e-02],\n",
       "       [3.93360443e-02],\n",
       "       [4.81890565e-05],\n",
       "       [3.34155280e-04],\n",
       "       [9.99887109e-01],\n",
       "       [9.99750793e-01],\n",
       "       [3.86682991e-03],\n",
       "       [3.13309545e-04],\n",
       "       [6.78912504e-04],\n",
       "       [2.47226068e-04],\n",
       "       [9.99490201e-01],\n",
       "       [2.50346638e-04],\n",
       "       [9.98969734e-01],\n",
       "       [9.98763502e-01],\n",
       "       [6.58903599e-01],\n",
       "       [9.78151321e-01],\n",
       "       [3.93402437e-03],\n",
       "       [6.53050700e-03],\n",
       "       [7.77252717e-04],\n",
       "       [2.88205966e-02],\n",
       "       [6.89569712e-01],\n",
       "       [7.92520761e-01],\n",
       "       [1.45868883e-01],\n",
       "       [2.69416458e-04],\n",
       "       [8.12818034e-05],\n",
       "       [3.28335329e-04],\n",
       "       [2.26189638e-03],\n",
       "       [1.76111776e-02],\n",
       "       [1.13385133e-01],\n",
       "       [9.99913514e-01],\n",
       "       [9.99611616e-01],\n",
       "       [7.19238758e-01],\n",
       "       [9.99900222e-01],\n",
       "       [2.40162760e-02],\n",
       "       [6.29759510e-04],\n",
       "       [9.99688625e-01],\n",
       "       [1.01884101e-02],\n",
       "       [5.42390218e-04],\n",
       "       [1.84826493e-01],\n",
       "       [9.78292584e-01],\n",
       "       [6.98986987e-05],\n",
       "       [6.89653039e-01],\n",
       "       [9.81859267e-01],\n",
       "       [9.99581873e-01],\n",
       "       [9.99727666e-01],\n",
       "       [1.61170796e-03],\n",
       "       [3.60443294e-02],\n",
       "       [9.93369043e-01],\n",
       "       [8.37907573e-05],\n",
       "       [2.00803205e-02],\n",
       "       [1.06074013e-01],\n",
       "       [9.94117379e-01],\n",
       "       [9.86488402e-01],\n",
       "       [1.89059030e-03],\n",
       "       [7.26258382e-04],\n",
       "       [8.58355463e-01],\n",
       "       [3.93827650e-04],\n",
       "       [1.37017330e-03],\n",
       "       [5.79850675e-05],\n",
       "       [2.63915330e-01],\n",
       "       [9.99912560e-01],\n",
       "       [9.99127984e-01],\n",
       "       [1.20759755e-03],\n",
       "       [9.99801457e-01],\n",
       "       [9.99870598e-01],\n",
       "       [6.07917682e-05],\n",
       "       [9.99831080e-01],\n",
       "       [2.59518661e-02],\n",
       "       [9.60410893e-01],\n",
       "       [2.00326964e-01],\n",
       "       [4.21782490e-04],\n",
       "       [1.92333478e-04],\n",
       "       [1.59529664e-04],\n",
       "       [6.96575153e-04],\n",
       "       [4.76702371e-05],\n",
       "       [9.03934315e-02],\n",
       "       [1.35568180e-03],\n",
       "       [9.99859571e-01],\n",
       "       [4.96454770e-04],\n",
       "       [9.95391905e-01],\n",
       "       [6.15849257e-01],\n",
       "       [9.70283407e-04],\n",
       "       [1.95897781e-04],\n",
       "       [9.99936938e-01],\n",
       "       [1.62405754e-03],\n",
       "       [9.99839604e-01],\n",
       "       [2.15437680e-01],\n",
       "       [1.03483852e-02],\n",
       "       [1.36452228e-01],\n",
       "       [3.87099746e-04],\n",
       "       [6.77214041e-02],\n",
       "       [9.99870598e-01],\n",
       "       [1.34127215e-04],\n",
       "       [2.48994533e-04],\n",
       "       [3.31231058e-02],\n",
       "       [9.99888122e-01],\n",
       "       [4.01631463e-03],\n",
       "       [4.83211188e-04],\n",
       "       [9.99277592e-01],\n",
       "       [6.51100199e-05],\n",
       "       [2.77812127e-04],\n",
       "       [3.40804749e-04],\n",
       "       [3.43378156e-01],\n",
       "       [6.72322058e-04],\n",
       "       [3.61334562e-01],\n",
       "       [1.40069248e-02],\n",
       "       [4.28306591e-03],\n",
       "       [1.05538114e-04],\n",
       "       [5.34786051e-03],\n",
       "       [4.61636155e-05],\n",
       "       [9.99568045e-01],\n",
       "       [9.89733577e-01],\n",
       "       [3.53190415e-02],\n",
       "       [1.65758785e-04],\n",
       "       [5.55362087e-03],\n",
       "       [9.99932587e-01],\n",
       "       [8.71452808e-01],\n",
       "       [9.99960899e-01],\n",
       "       [3.88890679e-04],\n",
       "       [9.99403059e-01],\n",
       "       [3.20635270e-04],\n",
       "       [9.90247309e-01],\n",
       "       [9.41411793e-01],\n",
       "       [1.21168690e-04],\n",
       "       [9.99890924e-01],\n",
       "       [2.54060118e-03],\n",
       "       [9.60726261e-01],\n",
       "       [9.99966860e-01],\n",
       "       [6.30239910e-03],\n",
       "       [2.41789356e-04],\n",
       "       [3.30292940e-01],\n",
       "       [1.99432470e-04],\n",
       "       [6.15384541e-02],\n",
       "       [9.99860466e-01],\n",
       "       [3.59937459e-01],\n",
       "       [9.99616802e-01],\n",
       "       [5.83825447e-02],\n",
       "       [9.99772847e-01],\n",
       "       [9.56658840e-01],\n",
       "       [4.96067945e-03],\n",
       "       [1.40938457e-04],\n",
       "       [9.68210340e-01],\n",
       "       [4.13008500e-04],\n",
       "       [1.99289948e-01],\n",
       "       [9.99899328e-01],\n",
       "       [9.98898208e-01],\n",
       "       [9.99915719e-01],\n",
       "       [9.99649704e-01],\n",
       "       [5.58324568e-02],\n",
       "       [8.99600327e-01],\n",
       "       [1.42159945e-04],\n",
       "       [7.09265649e-01],\n",
       "       [9.92284715e-01],\n",
       "       [9.99544084e-01],\n",
       "       [1.59977964e-04],\n",
       "       [9.94350374e-01],\n",
       "       [9.99826133e-01],\n",
       "       [1.56664185e-03],\n",
       "       [3.82120581e-03],\n",
       "       [1.45868883e-01],\n",
       "       [5.12114144e-04],\n",
       "       [7.44010448e-01],\n",
       "       [9.73798037e-01],\n",
       "       [9.99910414e-01],\n",
       "       [4.54030029e-04],\n",
       "       [1.38131407e-04],\n",
       "       [1.55126545e-04],\n",
       "       [1.46867692e-01],\n",
       "       [7.01054814e-04],\n",
       "       [3.14182527e-02],\n",
       "       [9.80680406e-01],\n",
       "       [1.29234526e-04],\n",
       "       [2.39404708e-01],\n",
       "       [1.96108986e-02],\n",
       "       [2.24902872e-02],\n",
       "       [9.99771535e-01],\n",
       "       [1.01165799e-03],\n",
       "       [9.98332500e-01],\n",
       "       [3.76640330e-03],\n",
       "       [3.47256355e-05],\n",
       "       [2.05678458e-04],\n",
       "       [9.99915302e-01],\n",
       "       [8.88756394e-01],\n",
       "       [2.06166573e-04],\n",
       "       [3.23093906e-02],\n",
       "       [1.26023382e-01],\n",
       "       [9.25232525e-05],\n",
       "       [9.99794841e-01],\n",
       "       [1.31126877e-03],\n",
       "       [9.18637455e-01],\n",
       "       [1.40918354e-02],\n",
       "       [1.10472541e-03],\n",
       "       [4.75160450e-01],\n",
       "       [1.02201775e-01],\n",
       "       [4.17956617e-03],\n",
       "       [9.99895334e-01],\n",
       "       [2.67968755e-02],\n",
       "       [3.67254436e-01],\n",
       "       [9.99903977e-01],\n",
       "       [3.70700151e-01],\n",
       "       [1.63261518e-01],\n",
       "       [6.98986987e-05],\n",
       "       [2.81883985e-01],\n",
       "       [1.31609470e-01],\n",
       "       [9.99921858e-01],\n",
       "       [9.50734079e-01],\n",
       "       [9.30930022e-03],\n",
       "       [9.99890804e-01],\n",
       "       [3.75538111e-01],\n",
       "       [9.99436736e-01],\n",
       "       [3.75538111e-01],\n",
       "       [9.99900699e-01],\n",
       "       [9.68546010e-05],\n",
       "       [3.32676200e-03],\n",
       "       [8.30865174e-05],\n",
       "       [9.99911189e-01],\n",
       "       [6.63953309e-04],\n",
       "       [1.61381625e-03],\n",
       "       [1.59703632e-04],\n",
       "       [1.92751992e-03],\n",
       "       [6.05188543e-04],\n",
       "       [8.52648285e-04],\n",
       "       [3.93162202e-03],\n",
       "       [8.37399857e-04],\n",
       "       [8.17820255e-04],\n",
       "       [9.94065702e-01],\n",
       "       [1.36182597e-03],\n",
       "       [2.36325338e-02],\n",
       "       [4.51995642e-04],\n",
       "       [1.05579871e-04],\n",
       "       [2.59712413e-02],\n",
       "       [9.97483134e-01],\n",
       "       [8.59350839e-04],\n",
       "       [4.69777703e-01],\n",
       "       [3.38431704e-03],\n",
       "       [9.96598244e-01],\n",
       "       [9.99778390e-01],\n",
       "       [1.80556788e-04],\n",
       "       [1.25462349e-04],\n",
       "       [1.48976062e-04],\n",
       "       [4.74272383e-05],\n",
       "       [9.99895751e-01],\n",
       "       [1.05579871e-04],\n",
       "       [6.24359876e-04],\n",
       "       [9.99853790e-01],\n",
       "       [9.99877632e-01],\n",
       "       [9.99879777e-01],\n",
       "       [9.99957979e-01],\n",
       "       [9.99988556e-01],\n",
       "       [4.17871284e-04],\n",
       "       [1.49329062e-04],\n",
       "       [1.33709721e-02],\n",
       "       [9.91335928e-01],\n",
       "       [9.99905705e-01],\n",
       "       [9.19574916e-01],\n",
       "       [4.71546227e-04],\n",
       "       [9.97867644e-01],\n",
       "       [6.34778976e-01],\n",
       "       [5.28893506e-05],\n",
       "       [2.38486915e-04],\n",
       "       [8.00202135e-03],\n",
       "       [1.70039833e-02],\n",
       "       [8.19974011e-05],\n",
       "       [5.72431087e-03],\n",
       "       [9.95518625e-01],\n",
       "       [9.99946177e-01],\n",
       "       [3.10574978e-04],\n",
       "       [9.99809086e-01],\n",
       "       [3.15557659e-01],\n",
       "       [1.07836865e-01],\n",
       "       [4.51602461e-03],\n",
       "       [9.43714578e-04],\n",
       "       [7.33292937e-01],\n",
       "       [1.48552163e-02],\n",
       "       [1.32871282e-04]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model 3 pred probs to label format\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.16535433070865,\n",
       " 'precision': 0.7751367943413853,\n",
       " 'recall': 0.7716535433070866,\n",
       " 'f1': 0.7687482528669142}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 3 results\n",
    "model_3_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_3_preds\n",
    ")\n",
    "model_3_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidir\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model details\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_4.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidir/20230113-221315\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 14s 38ms/step - loss: 0.1065 - accuracy: 0.9692 - val_loss: 0.9630 - val_accuracy: 0.7690\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 11s 49ms/step - loss: 0.0535 - accuracy: 0.9768 - val_loss: 1.1336 - val_accuracy: 0.7677\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 12s 55ms/step - loss: 0.0430 - accuracy: 0.9803 - val_loss: 1.2939 - val_accuracy: 0.7612\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 11s 51ms/step - loss: 0.0425 - accuracy: 0.9803 - val_loss: 1.4314 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 12s 56ms/step - loss: 0.0409 - accuracy: 0.9794 - val_loss: 1.3663 - val_accuracy: 0.7625\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_5 = model_4.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_4_bidir\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.3874387e-03],\n",
       "       [8.2908392e-01],\n",
       "       [9.9998486e-01],\n",
       "       [3.0986142e-01],\n",
       "       [4.9365179e-05],\n",
       "       [9.9988669e-01],\n",
       "       [9.8795718e-01],\n",
       "       [9.9998981e-01],\n",
       "       [9.9997860e-01],\n",
       "       [9.9698669e-01]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting model's probs to the label format\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.24671916010499,\n",
       " 'precision': 0.7626600366229389,\n",
       " 'recall': 0.7624671916010499,\n",
       " 'f1': 0.7611077640788777}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking results of predictions\n",
    "model_4_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_4_preds\n",
    ")\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8230a386d8e0083990873cddb8ebb5b6213275a10339230a8504f0ef8ce7f888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
