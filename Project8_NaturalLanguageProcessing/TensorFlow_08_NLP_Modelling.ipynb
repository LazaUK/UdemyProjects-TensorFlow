{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "# Importing TF and checking the version\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing helper functions\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"NLP_text/train.csv\")\n",
    "test_df = pd.read_csv(\"NLP_text/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking test dataframe\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of training records\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking total number of samples\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Sad that biker beatdown derailed his pro-democracy work as @NYPDnews undercover: http://t.co/iHHRKG4V1S. http://t.co/aryU5qNgJJ\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "#BBShelli seems pretty sure she's the one that's going to stay! #BB17\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@engineshed Great atmosphere at the British Lion gig tonight. Hearing is wrecked. http://t.co/oMNBAtJEAO\n",
      "---\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/aueZxZA5ak\n",
      "---\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "24 killed in two simultaneous rail crash as acute floods derail the two trains #India #mumbai... http://t.co/b0ZwI0qPTU\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Visualising random samples\n",
    "import random\n",
    "\n",
    "random_index = random.randint(0, len(train_df) - 5)\n",
    "\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index : random_index + 5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size=0.1, # Allocating 10% to validation data\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dataset length\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting text to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using text vectorisation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=None,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=None,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the average number of tokens\n",
    "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up text vectorisation variables\n",
    "max_vocab_length = 10000\n",
    "max_length = 15\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting text vectorisation to the training dataset\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentnence and tokenise it\n",
    "sample_sentence = \"There is a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "FAAN orders evacuation of abandoned aircraft at MMA: FAAN noted that the action had become necessary due to re... http://t.co/ZUqgvJnEQA,\n",
      "tokenised version:\n",
      "[[1679 1268  245    6 1441  661   17 2041 1679 5022   16    2  866   94\n",
      "   791]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenising random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\ntokenised version:\\n{text_vectorizer([random_sentence])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " ['', '[UNK]', 'the', 'a', 'in'],\n",
       " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "\n",
    "len(words_in_vocab), top_5_words, bottom_5_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x26899a724f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the layer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    input_length=max_length\n",
    ")\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "The Martyrs Who Kept Udhampur Terrorists at Bay Averted a Massacre: It was two youngÛ_ http://t.co/nux5XfPV2d SPSå¨,\n",
      "embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.04659598, -0.01593012, -0.04225612, ...,  0.02433849,\n",
       "         -0.04441274, -0.0047609 ],\n",
       "        [-0.0398303 ,  0.0433728 ,  0.01470615, ...,  0.02150333,\n",
       "          0.04934101,  0.04634135],\n",
       "        [-0.02800899, -0.01728942,  0.02363263, ..., -0.01828502,\n",
       "          0.01993917,  0.00403327],\n",
       "        ...,\n",
       "        [ 0.02714442,  0.0467861 , -0.03147028, ...,  0.03364256,\n",
       "         -0.01096548,  0.04719095],\n",
       "        [-0.00249439, -0.04945217,  0.03234044, ...,  0.00763072,\n",
       "         -0.02132593, -0.03810417],\n",
       "        [ 0.0090407 ,  0.02881757,  0.04324982, ...,  0.02212656,\n",
       "          0.00751988, -0.02301532]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\nembedded version:\"\n",
    ")\n",
    "\n",
    "# Embed random sentence\n",
    "embed_sentence = embedding(text_vectorizer([random_sentence]))\n",
    "embed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-0.04659598, -0.01593012, -0.04225612,  0.00725685,  0.04245068,\n",
       "        -0.03796609, -0.04970623,  0.02677557,  0.04829607, -0.02060782,\n",
       "        -0.02805123, -0.01698004,  0.03496093, -0.01372444,  0.04992953,\n",
       "         0.0311836 , -0.02447726,  0.04033473, -0.04035126, -0.02185392,\n",
       "         0.00309285, -0.02325898,  0.02069867,  0.04724659,  0.02922959,\n",
       "        -0.0373191 , -0.04904573,  0.00363798,  0.03871217,  0.02440611,\n",
       "        -0.03709758,  0.03995449, -0.0329757 ,  0.03792864, -0.02959371,\n",
       "         0.02402164, -0.03080671, -0.02450016, -0.01905632,  0.0023818 ,\n",
       "         0.01369375,  0.02132415, -0.03098136,  0.03727745,  0.01019982,\n",
       "         0.00921239,  0.04298681,  0.01907262, -0.02483143, -0.00242788,\n",
       "         0.04751453, -0.02078112,  0.02486658,  0.04702964,  0.02970495,\n",
       "        -0.03114016, -0.02835112,  0.00191686,  0.0052084 , -0.02857051,\n",
       "         0.02991304, -0.0223396 , -0.01663087,  0.0491769 ,  0.02129206,\n",
       "         0.03216226, -0.00895383,  0.00284685, -0.02272656,  0.00072223,\n",
       "        -0.00501261, -0.01510769,  0.03694612,  0.00297412,  0.006619  ,\n",
       "        -0.00565261, -0.00254577,  0.04969882,  0.03707192, -0.02908233,\n",
       "        -0.0049537 , -0.04890844, -0.02351238,  0.03931036, -0.00757185,\n",
       "         0.03707052, -0.03146949, -0.04227231, -0.04214169, -0.00722457,\n",
       "         0.0494241 ,  0.02508428,  0.03530956, -0.02391477, -0.01203678,\n",
       "        -0.02108816,  0.04442563,  0.00946987,  0.03586146, -0.04982504,\n",
       "        -0.01368295,  0.00237656,  0.0439123 ,  0.03396055, -0.03792297,\n",
       "        -0.03529209, -0.01575764, -0.01886014, -0.04187558, -0.02583724,\n",
       "        -0.01443908, -0.0311555 , -0.02316159,  0.03064289, -0.04615135,\n",
       "        -0.03162582,  0.02155221,  0.03525792,  0.00180327, -0.0213634 ,\n",
       "        -0.04515079, -0.02839576,  0.03753496, -0.04390992,  0.00729669,\n",
       "         0.02433849, -0.04441274, -0.0047609 ], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " 'The Martyrs Who Kept Udhampur Terrorists at Bay Averted a Massacre: It was two young\\x89Û_ http://t.co/nux5XfPV2d SPSå¨')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking single token's embedding\n",
    "embed_sentence[0][0], embed_sentence[0][0].shape, random_sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using SKLearn to build base model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenisation and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # Convert words to numbers\n",
    "    (\"clf\", MultinomialNB()) # Model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved accuracy: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Achieved accuracy: {baseline_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "baseline_predictions = model_0.predict(val_sentences)\n",
    "baseline_predictions[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SKLearn functions\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Developing function to evaluate accuracy, precision, recall and F1 scor\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate binary classification model\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and F1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1\n",
    "    }\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting baseline results\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=baseline_predictions\n",
    ")\n",
    "baseline_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: a simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensorboard callback\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback\n",
    "\n",
    "# Creating log directory\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model with Functional API\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype=tf.string)\n",
    "x = text_vectorizer(inputs) # Turn the input text into numbers\n",
    "x = embedding(x) # Create embedding of numberised inputs\n",
    "x = layers.GlobalAveragePooling1D()(x) # Condence the feature vector\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20230113-231416\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 20ms/step - loss: 0.6115 - accuracy: 0.6970 - val_loss: 0.5357 - val_accuracy: 0.7664\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.4425 - accuracy: 0.8199 - val_loss: 0.4697 - val_accuracy: 0.7900\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 19ms/step - loss: 0.3470 - accuracy: 0.8608 - val_loss: 0.4606 - val_accuracy: 0.7966\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 21ms/step - loss: 0.2846 - accuracy: 0.8914 - val_loss: 0.4654 - val_accuracy: 0.7927\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 7s 32ms/step - loss: 0.2377 - accuracy: 0.9130 - val_loss: 0.4808 - val_accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_1 = model_1.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_1_dense\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48084497451782227, 0.787401556968689]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40274784],\n",
       "       [0.7934085 ],\n",
       "       [0.99762815],\n",
       "       [0.07621262],\n",
       "       [0.11843665],\n",
       "       [0.9315513 ],\n",
       "       [0.90787256],\n",
       "       [0.9928179 ],\n",
       "       [0.9659077 ],\n",
       "       [0.18009627]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 10 predictions\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model predictions to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.74015748031496,\n",
       " 'precision': 0.7932296029485675,\n",
       " 'recall': 0.7874015748031497,\n",
       " 'f1': 0.7841130596930417}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating model 1 results\n",
    "model_1_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_1_preds\n",
    ")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving baseline results\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing model results\n",
    "import numpy as np\n",
    "\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting vocabulary from the text vectorisation layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model 1 details\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[-0.01260132, -0.02912213, -0.01750636, ..., -0.00884185,\n",
       "           0.05371519,  0.04908132],\n",
       "         [-0.0499537 ,  0.04859574,  0.0076521 , ...,  0.01239407,\n",
       "           0.06055391,  0.05562896],\n",
       "         [-0.05615652, -0.00983749, -0.05030296, ...,  0.01532918,\n",
       "          -0.03331523,  0.00353365],\n",
       "         ...,\n",
       "         [-0.02765653,  0.01126231, -0.00529394, ...,  0.00481617,\n",
       "           0.04849471,  0.04487426],\n",
       "         [-0.06867731,  0.08982918, -0.01022235, ..., -0.00427938,\n",
       "           0.06332158,  0.01206129],\n",
       "         [-0.0603082 ,  0.06891461, -0.0374227 , ..., -0.04026163,\n",
       "           0.09135257,  0.08985952]], dtype=float32)],\n",
       " (10000, 128))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the weights\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()\n",
    "embed_weights, embed_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating embedding files (sample from TF Word Embedding documentation)\n",
    "import io\n",
    "\n",
    "out_v = io.open(\"vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
    "out_m = io.open(\"metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "    if index == 0:\n",
    "        continue # Skip 0, as it's a padding\n",
    "    vec = embed_weights[0][index]\n",
    "    out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated vectors.tsv and metadata.tsv can be uploaded into Tensorflow Embedding Projector tool at https://projector.tensorflow.org/ to visualise weights in 3D space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - RNN (Recurrent Neural Network) with LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# CReating an RNN model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(units=64, return_sequences=True)(x) # Sequences required when you stack LSTM layers\n",
    "# print(x.shape)\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model's summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230113-231447\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 11s 29ms/step - loss: 0.2252 - accuracy: 0.9127 - val_loss: 0.6077 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 7s 31ms/step - loss: 0.1565 - accuracy: 0.9426 - val_loss: 0.6063 - val_accuracy: 0.7769\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 9s 43ms/step - loss: 0.1284 - accuracy: 0.9520 - val_loss: 0.6545 - val_accuracy: 0.7861\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 9s 43ms/step - loss: 0.1090 - accuracy: 0.9585 - val_loss: 0.7608 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 9s 42ms/step - loss: 0.0853 - accuracy: 0.9667 - val_loss: 0.9968 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "# Fittting the model\n",
    "history_2 = model_2.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_2_LSTM\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.3442520e-03],\n",
       "       [8.8728398e-01],\n",
       "       [9.9965590e-01],\n",
       "       [3.2201298e-02],\n",
       "       [2.6737017e-04],\n",
       "       [9.9846673e-01],\n",
       "       [8.4208000e-01],\n",
       "       [9.9981773e-01],\n",
       "       [9.9961007e-01],\n",
       "       [6.0151535e-01]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting pred probs to label format\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7800661437025787,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7782139444386276}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate model 2 results\n",
    "model_2_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_2_preds\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - RNN with GRU (gated recurrent unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True)(x) # Sequences, if GRU are stuck on each other\n",
    "x = layers.GRU(64)(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x) # If we want to consolidate GRU layer with sequences\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_3.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20230113-231536\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 13s 28ms/step - loss: 0.1590 - accuracy: 0.9375 - val_loss: 0.6674 - val_accuracy: 0.7730\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0839 - accuracy: 0.9702 - val_loss: 0.8939 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 22ms/step - loss: 0.0709 - accuracy: 0.9755 - val_loss: 0.9400 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 5s 23ms/step - loss: 0.0607 - accuracy: 0.9766 - val_loss: 0.9204 - val_accuracy: 0.7677\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 24ms/step - loss: 0.0533 - accuracy: 0.9765 - val_loss: 1.0217 - val_accuracy: 0.7717\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_3 = model_3.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_3_GRU\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.24695238e-03],\n",
       "       [9.31467831e-01],\n",
       "       [9.99912560e-01],\n",
       "       [1.12920970e-01],\n",
       "       [1.24091821e-04],\n",
       "       [9.99471247e-01],\n",
       "       [3.05579334e-01],\n",
       "       [9.99956489e-01],\n",
       "       [9.99906123e-01],\n",
       "       [7.81440794e-01],\n",
       "       [8.54744168e-04],\n",
       "       [7.90591538e-01],\n",
       "       [7.48686201e-04],\n",
       "       [2.12362528e-01],\n",
       "       [9.02552638e-05],\n",
       "       [9.83669981e-03],\n",
       "       [9.45435779e-04],\n",
       "       [1.72430242e-03],\n",
       "       [3.62405442e-02],\n",
       "       [9.99589145e-01],\n",
       "       [9.99454677e-01],\n",
       "       [1.98438342e-04],\n",
       "       [9.98781800e-01],\n",
       "       [4.00665915e-03],\n",
       "       [9.99913454e-01],\n",
       "       [9.99920905e-01],\n",
       "       [3.58351227e-03],\n",
       "       [5.60379913e-03],\n",
       "       [4.53075598e-04],\n",
       "       [6.02238119e-01],\n",
       "       [9.19585764e-01],\n",
       "       [1.33129908e-02],\n",
       "       [4.43103850e-01],\n",
       "       [1.40487188e-02],\n",
       "       [3.67412508e-01],\n",
       "       [4.15496796e-01],\n",
       "       [9.99824762e-01],\n",
       "       [2.91292101e-01],\n",
       "       [3.79499234e-02],\n",
       "       [9.99941647e-01],\n",
       "       [4.68642056e-01],\n",
       "       [1.38366056e-04],\n",
       "       [5.71096726e-02],\n",
       "       [2.87897419e-04],\n",
       "       [9.93534625e-01],\n",
       "       [9.99823332e-01],\n",
       "       [9.97055173e-01],\n",
       "       [9.87003028e-01],\n",
       "       [8.23353603e-03],\n",
       "       [3.17465931e-01],\n",
       "       [3.07240356e-02],\n",
       "       [4.94534433e-01],\n",
       "       [3.40029672e-02],\n",
       "       [8.22695345e-02],\n",
       "       [9.18668211e-01],\n",
       "       [1.49155706e-01],\n",
       "       [9.82395932e-03],\n",
       "       [9.99866247e-01],\n",
       "       [7.16179493e-04],\n",
       "       [1.58511067e-03],\n",
       "       [9.85812247e-02],\n",
       "       [9.99851763e-01],\n",
       "       [9.79122281e-01],\n",
       "       [5.45273069e-03],\n",
       "       [9.99954045e-01],\n",
       "       [9.99969244e-01],\n",
       "       [9.97258902e-01],\n",
       "       [3.43999173e-03],\n",
       "       [9.71948266e-01],\n",
       "       [1.99409965e-02],\n",
       "       [4.05897386e-02],\n",
       "       [4.53784242e-02],\n",
       "       [9.99941945e-01],\n",
       "       [6.49361983e-02],\n",
       "       [3.12042207e-01],\n",
       "       [8.98181081e-01],\n",
       "       [1.25316307e-01],\n",
       "       [9.98955846e-01],\n",
       "       [2.88421214e-01],\n",
       "       [7.42328942e-01],\n",
       "       [8.35310016e-03],\n",
       "       [1.79138884e-01],\n",
       "       [9.99920130e-01],\n",
       "       [7.29177659e-03],\n",
       "       [1.94944860e-03],\n",
       "       [5.90624567e-03],\n",
       "       [1.26536656e-03],\n",
       "       [5.71823725e-03],\n",
       "       [5.08272741e-03],\n",
       "       [9.99709487e-01],\n",
       "       [9.99847651e-01],\n",
       "       [2.32669525e-04],\n",
       "       [9.79592741e-01],\n",
       "       [4.51229978e-04],\n",
       "       [9.99898672e-01],\n",
       "       [9.29690719e-01],\n",
       "       [9.51027691e-01],\n",
       "       [9.99948859e-01],\n",
       "       [9.98998821e-01],\n",
       "       [9.99571621e-01],\n",
       "       [9.99971390e-01],\n",
       "       [2.84188315e-02],\n",
       "       [1.69570587e-04],\n",
       "       [9.82280910e-01],\n",
       "       [9.99365449e-01],\n",
       "       [5.91898300e-02],\n",
       "       [9.82802212e-01],\n",
       "       [9.94467258e-01],\n",
       "       [1.41209771e-03],\n",
       "       [9.98636723e-01],\n",
       "       [8.42848659e-01],\n",
       "       [6.82110782e-04],\n",
       "       [1.80168435e-01],\n",
       "       [3.22027947e-03],\n",
       "       [3.94835928e-03],\n",
       "       [6.92795143e-02],\n",
       "       [7.52265930e-01],\n",
       "       [9.99158680e-01],\n",
       "       [9.47670825e-03],\n",
       "       [1.02085725e-03],\n",
       "       [9.99949276e-01],\n",
       "       [2.52645666e-04],\n",
       "       [1.44773177e-04],\n",
       "       [8.61756027e-01],\n",
       "       [1.74677949e-02],\n",
       "       [1.02395993e-02],\n",
       "       [9.99496996e-01],\n",
       "       [1.03353530e-04],\n",
       "       [4.64003533e-03],\n",
       "       [9.98702466e-01],\n",
       "       [4.43247333e-03],\n",
       "       [9.99949276e-01],\n",
       "       [9.99964237e-01],\n",
       "       [9.99920905e-01],\n",
       "       [9.99789715e-01],\n",
       "       [9.34171863e-03],\n",
       "       [9.99847293e-01],\n",
       "       [1.98022991e-01],\n",
       "       [1.41268894e-02],\n",
       "       [3.13260290e-03],\n",
       "       [9.99946356e-01],\n",
       "       [9.40592051e-01],\n",
       "       [2.12362528e-01],\n",
       "       [9.98853385e-01],\n",
       "       [2.34664425e-01],\n",
       "       [3.11007649e-02],\n",
       "       [3.66005901e-04],\n",
       "       [1.07521373e-04],\n",
       "       [6.10315911e-02],\n",
       "       [9.99813914e-01],\n",
       "       [4.00003325e-03],\n",
       "       [7.56108835e-02],\n",
       "       [6.98958570e-03],\n",
       "       [2.09408766e-03],\n",
       "       [1.33563171e-03],\n",
       "       [9.99631166e-01],\n",
       "       [6.28705025e-01],\n",
       "       [1.28963515e-02],\n",
       "       [9.97420549e-01],\n",
       "       [6.82837272e-04],\n",
       "       [9.99827683e-01],\n",
       "       [1.54547645e-02],\n",
       "       [1.90068871e-01],\n",
       "       [9.96152639e-01],\n",
       "       [1.60815760e-01],\n",
       "       [2.43854709e-04],\n",
       "       [9.99923229e-01],\n",
       "       [9.06027034e-02],\n",
       "       [9.99827683e-01],\n",
       "       [5.24766624e-01],\n",
       "       [9.99911189e-01],\n",
       "       [9.98171210e-01],\n",
       "       [9.98900235e-01],\n",
       "       [4.85114491e-04],\n",
       "       [9.99981642e-01],\n",
       "       [2.74563697e-03],\n",
       "       [1.77024990e-01],\n",
       "       [1.70996025e-01],\n",
       "       [9.60399270e-01],\n",
       "       [9.99896348e-01],\n",
       "       [5.03107952e-03],\n",
       "       [9.99380946e-01],\n",
       "       [9.99634802e-01],\n",
       "       [9.99903262e-01],\n",
       "       [9.99912858e-01],\n",
       "       [8.22163071e-04],\n",
       "       [1.87347748e-03],\n",
       "       [9.99974251e-01],\n",
       "       [1.39406853e-04],\n",
       "       [1.14592825e-04],\n",
       "       [1.85385197e-02],\n",
       "       [9.99380708e-01],\n",
       "       [9.09259194e-04],\n",
       "       [1.22092327e-03],\n",
       "       [5.22121554e-04],\n",
       "       [1.58656784e-03],\n",
       "       [7.47029961e-04],\n",
       "       [2.10014544e-02],\n",
       "       [9.99636173e-01],\n",
       "       [8.97957012e-03],\n",
       "       [7.06901699e-02],\n",
       "       [9.99884009e-01],\n",
       "       [9.99838710e-01],\n",
       "       [5.80680445e-02],\n",
       "       [7.82478193e-04],\n",
       "       [9.99806583e-01],\n",
       "       [9.99579310e-01],\n",
       "       [9.99870062e-01],\n",
       "       [9.81074154e-01],\n",
       "       [9.87876654e-01],\n",
       "       [3.82027626e-01],\n",
       "       [9.99835253e-01],\n",
       "       [5.78709471e-04],\n",
       "       [9.36998520e-03],\n",
       "       [3.50404880e-04],\n",
       "       [2.17734079e-04],\n",
       "       [9.99919355e-01],\n",
       "       [9.95622277e-01],\n",
       "       [9.97589707e-01],\n",
       "       [6.61273420e-01],\n",
       "       [4.80129458e-02],\n",
       "       [4.91587725e-03],\n",
       "       [4.71193194e-02],\n",
       "       [4.82793711e-03],\n",
       "       [9.99837458e-01],\n",
       "       [2.53660619e-01],\n",
       "       [1.81937128e-01],\n",
       "       [9.99976099e-01],\n",
       "       [9.98487890e-01],\n",
       "       [2.01371476e-01],\n",
       "       [5.62218833e-04],\n",
       "       [1.07251862e-02],\n",
       "       [9.98966575e-01],\n",
       "       [6.33922517e-01],\n",
       "       [7.48978436e-01],\n",
       "       [4.50626388e-02],\n",
       "       [3.70057344e-01],\n",
       "       [1.59259647e-01],\n",
       "       [1.71336648e-03],\n",
       "       [6.03084918e-03],\n",
       "       [9.97275591e-01],\n",
       "       [3.57748498e-03],\n",
       "       [9.99871016e-01],\n",
       "       [9.99834538e-01],\n",
       "       [1.21780811e-03],\n",
       "       [1.93159023e-04],\n",
       "       [9.99780536e-01],\n",
       "       [5.85534901e-04],\n",
       "       [1.44480700e-02],\n",
       "       [1.42224833e-01],\n",
       "       [1.30564265e-03],\n",
       "       [9.98781383e-01],\n",
       "       [1.81549622e-04],\n",
       "       [1.87995750e-02],\n",
       "       [9.99708354e-01],\n",
       "       [1.96569294e-01],\n",
       "       [9.99789715e-01],\n",
       "       [9.99962628e-01],\n",
       "       [2.05463812e-01],\n",
       "       [4.27599822e-04],\n",
       "       [1.92347867e-03],\n",
       "       [6.69085479e-04],\n",
       "       [5.02182338e-05],\n",
       "       [9.99750376e-01],\n",
       "       [9.99914825e-01],\n",
       "       [5.14130220e-02],\n",
       "       [9.99780893e-01],\n",
       "       [1.45085540e-03],\n",
       "       [1.15122326e-01],\n",
       "       [4.82592062e-04],\n",
       "       [9.03216947e-04],\n",
       "       [1.12975610e-03],\n",
       "       [9.99814272e-01],\n",
       "       [1.28639909e-02],\n",
       "       [1.76554138e-04],\n",
       "       [9.99815643e-01],\n",
       "       [9.35528427e-04],\n",
       "       [8.31102021e-04],\n",
       "       [9.99738574e-01],\n",
       "       [4.55361878e-04],\n",
       "       [1.21493675e-01],\n",
       "       [1.53033980e-04],\n",
       "       [9.99833584e-01],\n",
       "       [8.74720395e-01],\n",
       "       [7.57465541e-01],\n",
       "       [2.73160636e-01],\n",
       "       [9.97732818e-01],\n",
       "       [1.28371986e-02],\n",
       "       [9.99782622e-01],\n",
       "       [5.28557459e-03],\n",
       "       [9.98780966e-01],\n",
       "       [9.78248715e-01],\n",
       "       [4.16787207e-01],\n",
       "       [8.53151549e-03],\n",
       "       [1.70339923e-03],\n",
       "       [7.76958585e-01],\n",
       "       [2.28367671e-02],\n",
       "       [7.37794191e-02],\n",
       "       [1.91079779e-03],\n",
       "       [6.31493628e-02],\n",
       "       [6.03050794e-05],\n",
       "       [1.32930046e-03],\n",
       "       [3.76994200e-02],\n",
       "       [9.99918640e-01],\n",
       "       [8.13269347e-04],\n",
       "       [4.19168472e-02],\n",
       "       [5.22741564e-02],\n",
       "       [2.58362651e-01],\n",
       "       [7.35805258e-02],\n",
       "       [3.50607629e-03],\n",
       "       [9.92040732e-04],\n",
       "       [9.99719322e-01],\n",
       "       [1.25038937e-01],\n",
       "       [5.11482477e-01],\n",
       "       [9.99972761e-01],\n",
       "       [4.36808827e-04],\n",
       "       [9.08443928e-01],\n",
       "       [1.78073749e-01],\n",
       "       [1.04265613e-02],\n",
       "       [1.63351923e-01],\n",
       "       [8.50847689e-04],\n",
       "       [4.34764065e-02],\n",
       "       [9.99261200e-01],\n",
       "       [9.50733483e-01],\n",
       "       [9.99851823e-01],\n",
       "       [2.77260274e-01],\n",
       "       [3.93593626e-04],\n",
       "       [9.99893069e-01],\n",
       "       [1.00219785e-03],\n",
       "       [9.99902606e-01],\n",
       "       [1.31137399e-02],\n",
       "       [2.72467546e-03],\n",
       "       [9.99837577e-01],\n",
       "       [7.14591006e-04],\n",
       "       [2.79502856e-04],\n",
       "       [9.99768019e-01],\n",
       "       [3.25705274e-04],\n",
       "       [1.32835591e-02],\n",
       "       [9.93976712e-01],\n",
       "       [9.97998595e-01],\n",
       "       [2.60649016e-04],\n",
       "       [2.35523582e-02],\n",
       "       [9.99835014e-01],\n",
       "       [9.99724209e-01],\n",
       "       [9.99159396e-01],\n",
       "       [3.25566739e-01],\n",
       "       [9.63623166e-01],\n",
       "       [9.97155428e-01],\n",
       "       [1.90472379e-02],\n",
       "       [8.32131365e-04],\n",
       "       [6.09547198e-02],\n",
       "       [1.31496131e-01],\n",
       "       [3.41119739e-04],\n",
       "       [2.68416852e-01],\n",
       "       [3.01464111e-01],\n",
       "       [4.84678574e-04],\n",
       "       [9.99786854e-01],\n",
       "       [9.99920905e-01],\n",
       "       [9.99915421e-01],\n",
       "       [4.34650760e-03],\n",
       "       [3.28924060e-01],\n",
       "       [9.92546231e-02],\n",
       "       [3.16471457e-01],\n",
       "       [9.85275090e-01],\n",
       "       [3.54707271e-01],\n",
       "       [3.26799200e-04],\n",
       "       [3.20158107e-03],\n",
       "       [5.74912236e-04],\n",
       "       [9.96657610e-01],\n",
       "       [1.79710193e-03],\n",
       "       [3.85101466e-03],\n",
       "       [4.66901285e-04],\n",
       "       [1.02097692e-03],\n",
       "       [2.47643828e-01],\n",
       "       [9.73411918e-01],\n",
       "       [8.77702236e-02],\n",
       "       [7.57662172e-04],\n",
       "       [9.56618786e-03],\n",
       "       [1.12264440e-03],\n",
       "       [9.99936700e-01],\n",
       "       [9.99737382e-01],\n",
       "       [6.81428254e-01],\n",
       "       [9.95004237e-01],\n",
       "       [2.27962213e-04],\n",
       "       [9.08930957e-01],\n",
       "       [9.99905229e-01],\n",
       "       [9.96950865e-01],\n",
       "       [2.15525508e-01],\n",
       "       [9.99544263e-01],\n",
       "       [1.19418032e-01],\n",
       "       [9.99893904e-01],\n",
       "       [4.02182974e-02],\n",
       "       [1.02524720e-02],\n",
       "       [3.34684014e-01],\n",
       "       [3.44717801e-02],\n",
       "       [9.99739945e-01],\n",
       "       [2.14927033e-01],\n",
       "       [1.70486601e-04],\n",
       "       [7.58772017e-04],\n",
       "       [3.54707271e-01],\n",
       "       [9.99987483e-01],\n",
       "       [1.67658334e-04],\n",
       "       [4.15486515e-01],\n",
       "       [9.99970794e-01],\n",
       "       [1.02099577e-04],\n",
       "       [9.99949276e-01],\n",
       "       [2.30653374e-03],\n",
       "       [1.02417599e-02],\n",
       "       [5.76482853e-04],\n",
       "       [9.99431372e-01],\n",
       "       [9.94373620e-01],\n",
       "       [6.22524135e-03],\n",
       "       [3.27697693e-04],\n",
       "       [9.99564767e-01],\n",
       "       [9.99888837e-01],\n",
       "       [8.20245385e-01],\n",
       "       [1.94390293e-03],\n",
       "       [9.56537016e-03],\n",
       "       [2.28862688e-01],\n",
       "       [1.48517708e-03],\n",
       "       [9.99949932e-01],\n",
       "       [5.73623814e-02],\n",
       "       [9.99932230e-01],\n",
       "       [9.99836028e-01],\n",
       "       [6.79711848e-02],\n",
       "       [1.61541235e-02],\n",
       "       [7.64152268e-04],\n",
       "       [9.99758065e-01],\n",
       "       [9.98117089e-01],\n",
       "       [8.06705475e-01],\n",
       "       [1.37032503e-02],\n",
       "       [4.56395326e-03],\n",
       "       [5.52036287e-03],\n",
       "       [4.33457899e-04],\n",
       "       [1.11510366e-01],\n",
       "       [2.71037906e-01],\n",
       "       [9.93304253e-01],\n",
       "       [9.21471417e-03],\n",
       "       [9.99954939e-01],\n",
       "       [9.99933600e-01],\n",
       "       [3.60240671e-03],\n",
       "       [9.31467831e-01],\n",
       "       [1.23169320e-02],\n",
       "       [1.59149268e-03],\n",
       "       [5.95720768e-01],\n",
       "       [9.98372495e-01],\n",
       "       [1.04605136e-02],\n",
       "       [1.30097955e-01],\n",
       "       [1.46953025e-04],\n",
       "       [2.66537331e-02],\n",
       "       [6.61964223e-05],\n",
       "       [9.99867082e-01],\n",
       "       [9.98401582e-01],\n",
       "       [9.99895453e-01],\n",
       "       [9.56159830e-01],\n",
       "       [9.72400188e-01],\n",
       "       [1.10250814e-02],\n",
       "       [2.34593259e-04],\n",
       "       [6.48506284e-01],\n",
       "       [9.96378720e-01],\n",
       "       [9.99895275e-01],\n",
       "       [1.01938006e-03],\n",
       "       [4.06864937e-03],\n",
       "       [4.11217846e-03],\n",
       "       [9.99907076e-01],\n",
       "       [9.99885201e-01],\n",
       "       [4.11699852e-03],\n",
       "       [2.12721825e-02],\n",
       "       [9.99964476e-01],\n",
       "       [2.20146198e-02],\n",
       "       [3.11945323e-02],\n",
       "       [9.88283873e-01],\n",
       "       [2.13977671e-03],\n",
       "       [1.63606938e-03],\n",
       "       [9.98833120e-01],\n",
       "       [3.51108074e-01],\n",
       "       [1.62909642e-01],\n",
       "       [9.99973953e-01],\n",
       "       [3.85261752e-04],\n",
       "       [8.67031142e-03],\n",
       "       [9.99531912e-05],\n",
       "       [4.70221625e-04],\n",
       "       [3.56802647e-03],\n",
       "       [9.99871612e-01],\n",
       "       [1.22343143e-03],\n",
       "       [7.54071057e-01],\n",
       "       [9.81195629e-01],\n",
       "       [9.39787999e-02],\n",
       "       [2.50310570e-01],\n",
       "       [1.20000572e-04],\n",
       "       [3.90298967e-03],\n",
       "       [9.99929368e-01],\n",
       "       [9.99817789e-01],\n",
       "       [1.33852018e-02],\n",
       "       [1.31033175e-03],\n",
       "       [5.15486253e-03],\n",
       "       [1.72792736e-03],\n",
       "       [9.99067605e-01],\n",
       "       [9.59517376e-04],\n",
       "       [9.99510348e-01],\n",
       "       [9.96030509e-01],\n",
       "       [9.02903199e-01],\n",
       "       [9.95321274e-01],\n",
       "       [1.36530310e-01],\n",
       "       [1.70356825e-01],\n",
       "       [7.14967726e-03],\n",
       "       [1.91419050e-01],\n",
       "       [8.86668801e-01],\n",
       "       [7.31133044e-01],\n",
       "       [1.94752127e-01],\n",
       "       [2.07344769e-03],\n",
       "       [1.42753139e-04],\n",
       "       [9.58291348e-03],\n",
       "       [4.43702303e-02],\n",
       "       [1.69192165e-01],\n",
       "       [1.35375604e-01],\n",
       "       [9.99929488e-01],\n",
       "       [9.99747872e-01],\n",
       "       [9.29690719e-01],\n",
       "       [9.99904573e-01],\n",
       "       [1.16786025e-01],\n",
       "       [3.00041074e-03],\n",
       "       [9.99764740e-01],\n",
       "       [7.71234231e-03],\n",
       "       [4.69166506e-03],\n",
       "       [2.82623112e-01],\n",
       "       [9.58196580e-01],\n",
       "       [9.64819264e-05],\n",
       "       [8.06490958e-01],\n",
       "       [9.79536533e-01],\n",
       "       [9.97377634e-01],\n",
       "       [9.99736249e-01],\n",
       "       [2.74763256e-03],\n",
       "       [7.60786980e-02],\n",
       "       [9.97283220e-01],\n",
       "       [3.93909286e-04],\n",
       "       [4.38305177e-02],\n",
       "       [4.57171679e-01],\n",
       "       [9.87567961e-01],\n",
       "       [8.00896585e-01],\n",
       "       [9.23939236e-03],\n",
       "       [3.38646676e-03],\n",
       "       [9.46241736e-01],\n",
       "       [2.02691345e-03],\n",
       "       [8.06690473e-03],\n",
       "       [4.18670126e-04],\n",
       "       [4.74340647e-01],\n",
       "       [9.99910951e-01],\n",
       "       [9.99328077e-01],\n",
       "       [9.36130621e-03],\n",
       "       [9.99682665e-01],\n",
       "       [9.99906242e-01],\n",
       "       [1.89878308e-04],\n",
       "       [9.99840975e-01],\n",
       "       [2.80851424e-01],\n",
       "       [9.86952424e-01],\n",
       "       [2.02974707e-01],\n",
       "       [9.45335906e-03],\n",
       "       [3.11615341e-03],\n",
       "       [4.96114662e-04],\n",
       "       [1.92767698e-02],\n",
       "       [3.56841716e-04],\n",
       "       [8.57897401e-01],\n",
       "       [1.37084303e-03],\n",
       "       [9.99888420e-01],\n",
       "       [3.83310462e-03],\n",
       "       [9.85406101e-01],\n",
       "       [4.47129607e-01],\n",
       "       [1.23916601e-03],\n",
       "       [8.39157612e-04],\n",
       "       [9.99953389e-01],\n",
       "       [4.75443006e-02],\n",
       "       [9.99835789e-01],\n",
       "       [4.17302877e-01],\n",
       "       [2.02740040e-02],\n",
       "       [2.45783627e-01],\n",
       "       [1.01217236e-02],\n",
       "       [1.37591884e-01],\n",
       "       [9.99906242e-01],\n",
       "       [1.91983709e-04],\n",
       "       [1.82653940e-03],\n",
       "       [8.30462351e-02],\n",
       "       [9.99910057e-01],\n",
       "       [5.04270159e-02],\n",
       "       [3.74986231e-03],\n",
       "       [9.92758095e-01],\n",
       "       [2.59587046e-04],\n",
       "       [1.16761150e-02],\n",
       "       [1.86451618e-03],\n",
       "       [2.67092884e-01],\n",
       "       [1.43505810e-02],\n",
       "       [5.58805227e-01],\n",
       "       [4.17543203e-02],\n",
       "       [1.19708166e-01],\n",
       "       [1.81210999e-04],\n",
       "       [4.09041271e-02],\n",
       "       [1.23109683e-04],\n",
       "       [9.99562740e-01],\n",
       "       [9.96795475e-01],\n",
       "       [1.76370457e-01],\n",
       "       [2.52253813e-04],\n",
       "       [6.23657089e-03],\n",
       "       [9.99946237e-01],\n",
       "       [9.88570929e-01],\n",
       "       [9.99964893e-01],\n",
       "       [4.36818087e-03],\n",
       "       [9.99528229e-01],\n",
       "       [3.41382204e-03],\n",
       "       [9.79411840e-01],\n",
       "       [9.93079126e-01],\n",
       "       [4.02674079e-04],\n",
       "       [9.99934256e-01],\n",
       "       [2.39201281e-02],\n",
       "       [9.97672021e-01],\n",
       "       [9.99970496e-01],\n",
       "       [2.57778149e-02],\n",
       "       [1.30833546e-03],\n",
       "       [4.56559092e-01],\n",
       "       [4.49514046e-04],\n",
       "       [4.48312610e-02],\n",
       "       [9.99806583e-01],\n",
       "       [4.03110057e-01],\n",
       "       [9.99709249e-01],\n",
       "       [1.41506165e-01],\n",
       "       [9.99759436e-01],\n",
       "       [8.90571296e-01],\n",
       "       [8.22381973e-02],\n",
       "       [3.04617948e-04],\n",
       "       [9.80440795e-01],\n",
       "       [3.22697917e-04],\n",
       "       [2.57326126e-01],\n",
       "       [9.99887168e-01],\n",
       "       [9.99501050e-01],\n",
       "       [9.99935627e-01],\n",
       "       [9.99740243e-01],\n",
       "       [1.95483983e-01],\n",
       "       [9.18934166e-01],\n",
       "       [2.48598168e-04],\n",
       "       [8.28622103e-01],\n",
       "       [9.79434192e-01],\n",
       "       [9.99648929e-01],\n",
       "       [2.37423088e-03],\n",
       "       [9.98507440e-01],\n",
       "       [9.99830961e-01],\n",
       "       [1.44009572e-02],\n",
       "       [6.62136823e-03],\n",
       "       [1.94752127e-01],\n",
       "       [2.15307809e-03],\n",
       "       [9.45129752e-01],\n",
       "       [9.79734480e-01],\n",
       "       [9.99870062e-01],\n",
       "       [1.68230440e-02],\n",
       "       [3.87203094e-04],\n",
       "       [4.44115693e-04],\n",
       "       [1.15306914e-01],\n",
       "       [3.96800647e-03],\n",
       "       [5.08433245e-02],\n",
       "       [9.96273935e-01],\n",
       "       [1.95581262e-04],\n",
       "       [5.71918428e-01],\n",
       "       [7.22802728e-02],\n",
       "       [1.71845943e-01],\n",
       "       [9.99778867e-01],\n",
       "       [4.13813069e-02],\n",
       "       [9.37324941e-01],\n",
       "       [3.23160067e-02],\n",
       "       [6.55570329e-05],\n",
       "       [8.97867896e-04],\n",
       "       [9.99928176e-01],\n",
       "       [8.99981320e-01],\n",
       "       [4.05969535e-04],\n",
       "       [3.11005235e-01],\n",
       "       [1.36498988e-01],\n",
       "       [1.88038772e-04],\n",
       "       [9.99825120e-01],\n",
       "       [7.99796078e-03],\n",
       "       [7.95845211e-01],\n",
       "       [3.89954776e-01],\n",
       "       [1.45451166e-03],\n",
       "       [5.70871949e-01],\n",
       "       [1.71086669e-01],\n",
       "       [2.18488723e-02],\n",
       "       [9.99910593e-01],\n",
       "       [8.86748731e-02],\n",
       "       [7.73813426e-02],\n",
       "       [9.99734700e-01],\n",
       "       [5.34822583e-01],\n",
       "       [3.06745201e-01],\n",
       "       [9.64819264e-05],\n",
       "       [4.01222825e-01],\n",
       "       [2.08078767e-03],\n",
       "       [9.99949276e-01],\n",
       "       [9.02305126e-01],\n",
       "       [2.36588158e-02],\n",
       "       [9.99908268e-01],\n",
       "       [3.15125555e-01],\n",
       "       [9.99173105e-01],\n",
       "       [3.15125555e-01],\n",
       "       [9.99924600e-01],\n",
       "       [9.55244395e-05],\n",
       "       [1.83333196e-02],\n",
       "       [2.49061501e-04],\n",
       "       [9.99943018e-01],\n",
       "       [2.16334853e-02],\n",
       "       [7.34633068e-03],\n",
       "       [9.94684524e-04],\n",
       "       [3.67106572e-02],\n",
       "       [3.04889143e-03],\n",
       "       [1.10089197e-03],\n",
       "       [3.62133645e-02],\n",
       "       [5.22370450e-03],\n",
       "       [7.18036899e-03],\n",
       "       [9.99362290e-01],\n",
       "       [6.19603740e-03],\n",
       "       [2.03817300e-02],\n",
       "       [1.23320695e-03],\n",
       "       [1.26708401e-04],\n",
       "       [3.67345810e-01],\n",
       "       [9.96470630e-01],\n",
       "       [6.72257505e-03],\n",
       "       [5.78752905e-03],\n",
       "       [5.79642057e-02],\n",
       "       [9.92707133e-01],\n",
       "       [9.99814034e-01],\n",
       "       [5.85164409e-04],\n",
       "       [8.91087635e-04],\n",
       "       [1.52012985e-03],\n",
       "       [4.83074400e-05],\n",
       "       [9.99871671e-01],\n",
       "       [1.26708401e-04],\n",
       "       [1.74921349e-01],\n",
       "       [9.99614835e-01],\n",
       "       [9.99872983e-01],\n",
       "       [9.99898970e-01],\n",
       "       [9.99970734e-01],\n",
       "       [9.99994755e-01],\n",
       "       [1.56686513e-03],\n",
       "       [5.53648162e-04],\n",
       "       [1.05858013e-01],\n",
       "       [7.04140127e-01],\n",
       "       [9.99922574e-01],\n",
       "       [9.85686719e-01],\n",
       "       [2.16786726e-03],\n",
       "       [9.98561263e-01],\n",
       "       [8.75971079e-01],\n",
       "       [1.18850294e-04],\n",
       "       [3.27141752e-04],\n",
       "       [3.74005642e-03],\n",
       "       [6.62526637e-02],\n",
       "       [2.40312715e-04],\n",
       "       [4.10675518e-02],\n",
       "       [9.90624249e-01],\n",
       "       [9.99963880e-01],\n",
       "       [1.02126377e-03],\n",
       "       [9.99898970e-01],\n",
       "       [7.72988379e-01],\n",
       "       [8.81088898e-02],\n",
       "       [1.02506764e-01],\n",
       "       [3.53163220e-02],\n",
       "       [9.05151069e-01],\n",
       "       [1.71408549e-01],\n",
       "       [2.09032311e-04]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model 3 pred probs to label format\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.16535433070865,\n",
       " 'precision': 0.7732961359962456,\n",
       " 'recall': 0.7716535433070866,\n",
       " 'f1': 0.7695827090439606}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 3 results\n",
    "model_3_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_3_preds\n",
    ")\n",
    "model_3_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidir\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model details\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_4.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidir/20230113-231612\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 19s 54ms/step - loss: 0.1087 - accuracy: 0.9661 - val_loss: 0.9637 - val_accuracy: 0.7664\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 11s 49ms/step - loss: 0.0551 - accuracy: 0.9781 - val_loss: 1.1823 - val_accuracy: 0.7638\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 11s 51ms/step - loss: 0.0489 - accuracy: 0.9788 - val_loss: 1.2980 - val_accuracy: 0.7690\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 11s 51ms/step - loss: 0.0422 - accuracy: 0.9800 - val_loss: 1.2985 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 11s 51ms/step - loss: 0.0422 - accuracy: 0.9806 - val_loss: 1.2814 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_5 = model_4.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_4_bidir\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 4s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.0618695e-02],\n",
       "       [8.1061995e-01],\n",
       "       [9.9994409e-01],\n",
       "       [2.3289736e-01],\n",
       "       [8.4356689e-05],\n",
       "       [9.9965870e-01],\n",
       "       [9.1179651e-01],\n",
       "       [9.9998355e-01],\n",
       "       [9.9995202e-01],\n",
       "       [9.8412627e-01]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting model's probs to the label format\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.77165354330708,\n",
       " 'precision': 0.7676331847037146,\n",
       " 'recall': 0.7677165354330708,\n",
       " 'f1': 0.766696834597351}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking results of predictions\n",
    "model_4_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_4_preds\n",
    ")\n",
    "model_4_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 - Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing embedding layer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding_test = embedding(text_vectorizer(\"This is a test sentence\"))\n",
    "# print(embedding_test.shape)\n",
    "embedding_test = tf.expand_dims(embedding_test, axis=0)\n",
    "# print(embedding_test.shape)\n",
    "conv_1d = layers.Conv1D(\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    activation=\"relu\",\n",
    "    padding=\"valid\"\n",
    ")\n",
    "conv_1d_output = conv_1d(embedding_test)\n",
    "max_pool = layers.GlobalMaxPool1D()\n",
    "max_pool_output = max_pool(conv_1d_output)\n",
    "\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8230a386d8e0083990873cddb8ebb5b6213275a10339230a8504f0ef8ce7f888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
