{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "# Importing TF and checking the version\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing helper functions\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"NLP_text/train.csv\")\n",
    "test_df = pd.read_csv(\"NLP_text/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffling training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking test dataframe\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of training records\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking total number of samples\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Officially skipping out on #FantasticFour/#Fant4stic/whatever the hashtag is. It's getting ANNIHILATED in reviews. Bummer.\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "I liked a @YouTube video http://t.co/5fR41TPzte Thorin's Thoughts - Riot and Sandbox Mode (LoL)\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Parents are taking their kids to Burning Man and one 11 year old thinks it's 'better than... http://t.co/wp6V1BHhoQ\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Learn How I Gained Access To The Secrets Of The Top Earners &amp; Used Them To Explode My Home Business Here: http://t.co/8rABhQrTh5 Please #RT\n",
      "---\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "HereÛªs how media in Pakistan covered the capture of terrorist Mohammed Naved http://t.co/f7WqpCEkg2\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Visualising random samples\n",
    "import random\n",
    "\n",
    "random_index = random.randint(0, len(train_df) - 5)\n",
    "\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index : random_index + 5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size=0.1, # Allocating 10% to validation data\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dataset length\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first 10 samples\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting text to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using text vectorisation\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=None,\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=None,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the average number of tokens\n",
    "round(sum([len(i.split()) for i in train_sentences]) / len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up text vectorisation variables\n",
    "max_vocab_length = 10000\n",
    "max_length = 15\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting text vectorisation to the training dataset\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentnence and tokenise it\n",
    "sample_sentence = \"There is a flood in my street\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/yNXnvVKCDA | @djicemoon | #Dubstep #TrapMusic #DnB #EDM #Dance #IcesÛ_ http://t.co/weQPesENku,\n",
      "tokenised version:\n",
      "[[2582 2420 2428  966    1 2490 2133 2249 2138 1685 1307 2427    1    0\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "# Tokenising random sentence from the training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\ntokenised version:\\n{text_vectorizer([random_sentence])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,\n",
       " ['', '[UNK]', 'the', 'a', 'in'],\n",
       " ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5]\n",
    "bottom_5_words = words_in_vocab[-5:]\n",
    "\n",
    "len(words_in_vocab), top_5_words, bottom_5_words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x19ca5941c40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the layer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(\n",
    "    input_dim=max_vocab_length,\n",
    "    output_dim=128,\n",
    "    input_length=max_length\n",
    ")\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "@RosemaryTravale Do we all use the same weapon? 'cause we might be screwed XD,\n",
      "embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.02209502,  0.04833481,  0.02057297, ..., -0.0417004 ,\n",
       "          0.01724714,  0.00334507],\n",
       "        [ 0.0044282 ,  0.02959353, -0.02985519, ..., -0.00032227,\n",
       "          0.03369289, -0.0301164 ],\n",
       "        [ 0.02713615, -0.00702845, -0.00376241, ..., -0.01400626,\n",
       "         -0.0199459 , -0.00800296],\n",
       "        ...,\n",
       "        [-0.00922608, -0.04281855,  0.00149045, ..., -0.01199614,\n",
       "          0.04132703, -0.00422592],\n",
       "        [ 0.02289363, -0.01219679, -0.04508603, ...,  0.01462224,\n",
       "          0.0351765 , -0.02655279],\n",
       "        [ 0.04544933, -0.00372183,  0.03552462, ..., -0.03026444,\n",
       "         -0.0371375 ,  0.02856531]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(\n",
    "    f\"Original text:\\n{random_sentence},\\nembedded version:\"\n",
    ")\n",
    "\n",
    "# Embed random sentence\n",
    "embed_sentence = embedding(text_vectorizer([random_sentence]))\n",
    "embed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-0.02209502,  0.04833481,  0.02057297,  0.032789  ,  0.04318057,\n",
       "        -0.03431219,  0.01098975,  0.03514931,  0.03978893,  0.01736709,\n",
       "        -0.02824736, -0.02608452, -0.00248503, -0.02237294,  0.0012821 ,\n",
       "        -0.00635846, -0.01773519,  0.03112418,  0.01703538, -0.02766299,\n",
       "         0.03034944,  0.03847185, -0.00869383, -0.04557556, -0.04246776,\n",
       "        -0.02699394,  0.03543986,  0.01170706, -0.02990152, -0.04815678,\n",
       "         0.01021283,  0.01171887, -0.02144183,  0.04833951,  0.02251032,\n",
       "         0.00594647, -0.0025661 , -0.04159676, -0.04176854, -0.00442631,\n",
       "         0.02404336, -0.04970976, -0.00243689,  0.03470664, -0.02492545,\n",
       "         0.00792212,  0.03716299, -0.02514007,  0.04799393,  0.04344555,\n",
       "         0.0493938 , -0.04462188, -0.02766787,  0.04958842, -0.01133138,\n",
       "         0.01706865,  0.04976422,  0.02401492, -0.0471971 , -0.00576581,\n",
       "        -0.00843783, -0.0460158 , -0.0047438 , -0.02876973, -0.01069454,\n",
       "         0.01619888,  0.04037999,  0.01838851, -0.00422462, -0.04191711,\n",
       "        -0.00661899, -0.0099126 ,  0.00550188,  0.00955259, -0.04527506,\n",
       "        -0.03952737,  0.00068357,  0.01506237,  0.02933272,  0.03145499,\n",
       "         0.00036741, -0.02838404,  0.03360294, -0.00809816, -0.03861867,\n",
       "        -0.01535642, -0.01991108, -0.00284731, -0.00102241,  0.00881507,\n",
       "         0.04184842,  0.02010867, -0.03618548,  0.03027866,  0.03916322,\n",
       "         0.00805066, -0.03710666, -0.04139948,  0.00847573,  0.02389066,\n",
       "         0.01628243,  0.00759467,  0.00631318, -0.03897363,  0.00185246,\n",
       "        -0.02116649, -0.01038554,  0.01984959,  0.0469817 ,  0.02188386,\n",
       "         0.01445884, -0.03468984,  0.04734352, -0.04908769, -0.00561147,\n",
       "        -0.01057572,  0.01363671,  0.00763376, -0.01649905,  0.00951245,\n",
       "         0.04764811, -0.01827   , -0.00726034,  0.04098501,  0.04254693,\n",
       "        -0.0417004 ,  0.01724714,  0.00334507], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " \"@RosemaryTravale Do we all use the same weapon? 'cause we might be screwed XD\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking single token's embedding\n",
    "embed_sentence[0][0], embed_sentence[0][0].shape, random_sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using SKLearn to build base model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenisation and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # Convert words to numbers\n",
    "    (\"clf\", MultinomialNB()) # Model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved accuracy: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating baseline model\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Achieved accuracy: {baseline_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "baseline_predictions = model_0.predict(val_sentences)\n",
    "baseline_predictions[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SKLearn functions\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Developing function to evaluate accuracy, precision, recall and F1 scor\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate binary classification model\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and F1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1\n",
    "    }\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting baseline results\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=baseline_predictions\n",
    ")\n",
    "baseline_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: a simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensorboard callback\n",
    "from DanielBourke_HelperFunctions import create_tensorboard_callback\n",
    "\n",
    "# Creating log directory\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building model with Functional API\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1, ), dtype=tf.string)\n",
    "x = text_vectorizer(inputs) # Turn the input text into numbers\n",
    "x = embedding(x) # Create embedding of numberised inputs\n",
    "x = layers.GlobalAveragePooling1D()(x) # Condence the feature vector\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model_1.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20230116-103108\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 15ms/step - loss: 0.6101 - accuracy: 0.6920 - val_loss: 0.5347 - val_accuracy: 0.7651\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.4408 - accuracy: 0.8173 - val_loss: 0.4692 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.3457 - accuracy: 0.8608 - val_loss: 0.4593 - val_accuracy: 0.7874\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 14ms/step - loss: 0.2831 - accuracy: 0.8930 - val_loss: 0.4635 - val_accuracy: 0.7874\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.2358 - accuracy: 0.9123 - val_loss: 0.4821 - val_accuracy: 0.7848\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_1 = model_1.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_1_dense\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48205941915512085, 0.7847769260406494]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the results\n",
    "model_1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3532249 ],\n",
       "       [0.75160396],\n",
       "       [0.99763644],\n",
       "       [0.09741288],\n",
       "       [0.09976958],\n",
       "       [0.93916947],\n",
       "       [0.91113394],\n",
       "       [0.9932434 ],\n",
       "       [0.9641323 ],\n",
       "       [0.26156282]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 10 predictions\n",
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model predictions to label format\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.4776902887139,\n",
       " 'precision': 0.790955383689072,\n",
       " 'recall': 0.7847769028871391,\n",
       " 'f1': 0.7812916448740085}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating model 1 results\n",
    "model_1_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_1_preds\n",
    ")\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieving baseline results\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing model results\n",
    "import numpy as np\n",
    "\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising learned embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting vocabulary from the text vectorisation layer\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model 1 details\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 0.03117545, -0.0198781 ,  0.04902324, ..., -0.04492381,\n",
       "          -0.05209893,  0.04254517],\n",
       "         [ 0.02417207, -0.01064174,  0.00071459, ..., -0.01533931,\n",
       "          -0.0388462 ,  0.04234987],\n",
       "         [-0.0505834 , -0.02030688,  0.00483891, ..., -0.03868733,\n",
       "          -0.0411087 ,  0.04079808],\n",
       "         ...,\n",
       "         [ 0.04937395, -0.0193275 ,  0.01589176, ...,  0.01257899,\n",
       "           0.04665932, -0.00394964],\n",
       "         [ 0.01028025, -0.03333158,  0.07804684, ..., -0.06535052,\n",
       "          -0.07028744,  0.03675681],\n",
       "         [-0.02590463, -0.08515803,  0.05049384, ..., -0.10260323,\n",
       "          -0.10310195,  0.11368717]], dtype=float32)],\n",
       " (10000, 128))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the weights\n",
    "embed_weights = model_1.get_layer(\"embedding\").get_weights()\n",
    "embed_weights, embed_weights[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating embedding files (sample from TF Word Embedding documentation)\n",
    "import io\n",
    "\n",
    "out_v = io.open(\"vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
    "out_m = io.open(\"metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "    if index == 0:\n",
    "        continue # Skip 0, as it's a padding\n",
    "    vec = embed_weights[0][index]\n",
    "    out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated vectors.tsv and metadata.tsv can be uploaded into Tensorflow Embedding Projector tool at https://projector.tensorflow.org/ to visualise weights in 3D space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - RNN (Recurrent Neural Network) with LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# CReating an RNN model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "print(x.shape)\n",
    "# x = layers.LSTM(units=64, return_sequences=True)(x) # Sequences required when you stack LSTM layers\n",
    "# print(x.shape)\n",
    "x = layers.LSTM(64)(x)\n",
    "print(x.shape)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model's summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20230116-103129\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 18ms/step - loss: 0.2247 - accuracy: 0.9187 - val_loss: 0.5958 - val_accuracy: 0.7835\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.1560 - accuracy: 0.9423 - val_loss: 0.6173 - val_accuracy: 0.7874\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.1303 - accuracy: 0.9511 - val_loss: 0.7270 - val_accuracy: 0.7795\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.1080 - accuracy: 0.9578 - val_loss: 0.7674 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0856 - accuracy: 0.9666 - val_loss: 1.0402 - val_accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "# Fittting the model\n",
    "history_2 = model_2.fit(\n",
    "    x=train_sentences,\n",
    "    y=train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_2_LSTM\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.08379915e-01],\n",
       "       [7.43641078e-01],\n",
       "       [9.99641776e-01],\n",
       "       [2.65806187e-02],\n",
       "       [2.02441894e-04],\n",
       "       [9.99169886e-01],\n",
       "       [9.18037057e-01],\n",
       "       [9.99792099e-01],\n",
       "       [9.99619246e-01],\n",
       "       [6.23820305e-01]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting pred probs to label format\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.95275590551181,\n",
       " 'precision': 0.7799065773530309,\n",
       " 'recall': 0.7795275590551181,\n",
       " 'f1': 0.7783167829714759}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate model 2 results\n",
    "model_2_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_2_preds\n",
    ")\n",
    "model_2_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 - RNN with GRU (gated recurrent unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.GRU(64, return_sequences=True)(x) # Sequences, if GRU are stuck on each other\n",
    "x = layers.GRU(64)(x)\n",
    "# x = layers.Dense(64, activation=\"relu\")(x)\n",
    "# x = layers.GlobalAveragePooling1D()(x) # If we want to consolidate GRU layer with sequences\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 64)                37248     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting model summary\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_3.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20230116-103150\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 19ms/step - loss: 0.1537 - accuracy: 0.9426 - val_loss: 0.6736 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0831 - accuracy: 0.9686 - val_loss: 0.9990 - val_accuracy: 0.7782\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0716 - accuracy: 0.9726 - val_loss: 0.8443 - val_accuracy: 0.7690\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0626 - accuracy: 0.9753 - val_loss: 0.9545 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0564 - accuracy: 0.9766 - val_loss: 0.9678 - val_accuracy: 0.7743\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_3 = model_3.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_3_GRU\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.65900637e-03],\n",
       "       [7.43340492e-01],\n",
       "       [9.99801517e-01],\n",
       "       [1.59227267e-01],\n",
       "       [2.54200248e-04],\n",
       "       [9.99493241e-01],\n",
       "       [6.09049141e-01],\n",
       "       [9.99903500e-01],\n",
       "       [9.99839962e-01],\n",
       "       [5.78665257e-01],\n",
       "       [8.11867532e-04],\n",
       "       [8.48473966e-01],\n",
       "       [6.93586306e-04],\n",
       "       [1.41044393e-01],\n",
       "       [2.36695734e-04],\n",
       "       [8.22120905e-03],\n",
       "       [2.15882156e-03],\n",
       "       [6.05901878e-04],\n",
       "       [5.87642156e-02],\n",
       "       [9.99629200e-01],\n",
       "       [9.98125613e-01],\n",
       "       [1.13471207e-04],\n",
       "       [9.99618411e-01],\n",
       "       [7.02270400e-03],\n",
       "       [9.99822915e-01],\n",
       "       [9.99863327e-01],\n",
       "       [5.19790500e-03],\n",
       "       [2.83036754e-03],\n",
       "       [1.12335628e-03],\n",
       "       [3.29441369e-01],\n",
       "       [9.54154134e-01],\n",
       "       [5.31938858e-03],\n",
       "       [6.24567866e-01],\n",
       "       [4.92135668e-03],\n",
       "       [5.11452019e-01],\n",
       "       [1.45058215e-01],\n",
       "       [9.99590993e-01],\n",
       "       [3.01710695e-01],\n",
       "       [4.24492545e-02],\n",
       "       [9.99869883e-01],\n",
       "       [3.62982452e-01],\n",
       "       [1.12436137e-04],\n",
       "       [4.21873182e-02],\n",
       "       [5.58498548e-04],\n",
       "       [9.66013372e-01],\n",
       "       [9.99627709e-01],\n",
       "       [9.91083086e-01],\n",
       "       [9.53381538e-01],\n",
       "       [1.63908135e-02],\n",
       "       [1.38315156e-01],\n",
       "       [2.12455858e-02],\n",
       "       [5.53830564e-01],\n",
       "       [3.78064513e-02],\n",
       "       [2.05123406e-02],\n",
       "       [7.34864652e-01],\n",
       "       [2.74413936e-02],\n",
       "       [3.38559435e-03],\n",
       "       [9.99860585e-01],\n",
       "       [7.50579638e-04],\n",
       "       [1.58785318e-03],\n",
       "       [7.76392743e-02],\n",
       "       [9.99718189e-01],\n",
       "       [9.98519182e-01],\n",
       "       [3.21078338e-02],\n",
       "       [9.99894559e-01],\n",
       "       [9.99926925e-01],\n",
       "       [9.84398007e-01],\n",
       "       [4.84434515e-03],\n",
       "       [9.66421068e-01],\n",
       "       [6.74985349e-02],\n",
       "       [2.74847448e-02],\n",
       "       [6.13181107e-02],\n",
       "       [9.99893486e-01],\n",
       "       [2.85687689e-02],\n",
       "       [9.79159057e-01],\n",
       "       [9.93601799e-01],\n",
       "       [8.24452117e-02],\n",
       "       [9.99156713e-01],\n",
       "       [2.74658531e-01],\n",
       "       [3.13432008e-01],\n",
       "       [3.31751467e-03],\n",
       "       [1.26925424e-01],\n",
       "       [9.99890566e-01],\n",
       "       [3.78762488e-03],\n",
       "       [6.18112460e-03],\n",
       "       [9.26626194e-03],\n",
       "       [1.86900736e-03],\n",
       "       [1.26119249e-03],\n",
       "       [8.48055910e-03],\n",
       "       [9.99647975e-01],\n",
       "       [9.99662220e-01],\n",
       "       [2.25073600e-04],\n",
       "       [9.92328823e-01],\n",
       "       [3.76242620e-04],\n",
       "       [9.99877810e-01],\n",
       "       [7.68147826e-01],\n",
       "       [8.33592474e-01],\n",
       "       [9.99915242e-01],\n",
       "       [9.98961568e-01],\n",
       "       [9.98940587e-01],\n",
       "       [9.99968052e-01],\n",
       "       [4.43128236e-02],\n",
       "       [2.65183276e-04],\n",
       "       [9.76342201e-01],\n",
       "       [9.99182343e-01],\n",
       "       [9.19529945e-02],\n",
       "       [9.90171909e-01],\n",
       "       [9.86572444e-01],\n",
       "       [3.65298986e-03],\n",
       "       [9.99602318e-01],\n",
       "       [9.95956361e-01],\n",
       "       [4.38304356e-04],\n",
       "       [5.86814225e-01],\n",
       "       [4.38615168e-03],\n",
       "       [1.53615139e-03],\n",
       "       [1.47875190e-01],\n",
       "       [8.17322850e-01],\n",
       "       [9.99644160e-01],\n",
       "       [6.35403618e-02],\n",
       "       [1.17174489e-03],\n",
       "       [9.99898911e-01],\n",
       "       [8.16005690e-04],\n",
       "       [4.68307815e-04],\n",
       "       [8.66317034e-01],\n",
       "       [2.03497201e-01],\n",
       "       [1.26205878e-02],\n",
       "       [9.99659240e-01],\n",
       "       [1.90226972e-04],\n",
       "       [7.46094063e-03],\n",
       "       [9.88375545e-01],\n",
       "       [1.50220124e-02],\n",
       "       [9.99898911e-01],\n",
       "       [9.99935925e-01],\n",
       "       [9.99863327e-01],\n",
       "       [9.99618530e-01],\n",
       "       [7.90537242e-03],\n",
       "       [9.99752462e-01],\n",
       "       [1.48192659e-01],\n",
       "       [1.35735087e-02],\n",
       "       [4.24454827e-03],\n",
       "       [9.99929249e-01],\n",
       "       [8.01396847e-01],\n",
       "       [1.41044393e-01],\n",
       "       [9.99393284e-01],\n",
       "       [1.47373319e-01],\n",
       "       [2.48078741e-02],\n",
       "       [4.32704110e-04],\n",
       "       [1.46117323e-04],\n",
       "       [1.15939058e-01],\n",
       "       [9.99707580e-01],\n",
       "       [5.70361083e-03],\n",
       "       [4.13177945e-02],\n",
       "       [3.60489972e-02],\n",
       "       [7.16456678e-04],\n",
       "       [1.48564100e-03],\n",
       "       [9.99544501e-01],\n",
       "       [8.78073871e-01],\n",
       "       [2.97676120e-02],\n",
       "       [9.96147096e-01],\n",
       "       [7.74014217e-04],\n",
       "       [9.99387920e-01],\n",
       "       [6.70554629e-03],\n",
       "       [1.26810342e-01],\n",
       "       [9.88133073e-01],\n",
       "       [1.65951908e-01],\n",
       "       [2.54254352e-04],\n",
       "       [9.99863148e-01],\n",
       "       [1.00414827e-01],\n",
       "       [9.99732196e-01],\n",
       "       [8.62737417e-01],\n",
       "       [9.99837279e-01],\n",
       "       [9.96129870e-01],\n",
       "       [9.99133050e-01],\n",
       "       [5.44146053e-04],\n",
       "       [9.99965727e-01],\n",
       "       [2.51766481e-03],\n",
       "       [2.88951360e-02],\n",
       "       [7.29802102e-02],\n",
       "       [9.41987514e-01],\n",
       "       [9.99847472e-01],\n",
       "       [1.84238749e-03],\n",
       "       [9.97928381e-01],\n",
       "       [9.99794543e-01],\n",
       "       [9.99823987e-01],\n",
       "       [9.99818802e-01],\n",
       "       [1.81577099e-03],\n",
       "       [2.38447310e-03],\n",
       "       [9.99967456e-01],\n",
       "       [2.79632921e-04],\n",
       "       [2.19428257e-04],\n",
       "       [5.93037484e-03],\n",
       "       [9.98785555e-01],\n",
       "       [1.93798647e-03],\n",
       "       [1.37037702e-03],\n",
       "       [1.08320126e-03],\n",
       "       [5.85473841e-03],\n",
       "       [9.55670490e-04],\n",
       "       [5.55254659e-03],\n",
       "       [9.99507666e-01],\n",
       "       [1.00728357e-02],\n",
       "       [7.26855025e-02],\n",
       "       [9.99800563e-01],\n",
       "       [9.99758303e-01],\n",
       "       [7.60832429e-03],\n",
       "       [9.53910232e-04],\n",
       "       [9.99782503e-01],\n",
       "       [9.99619246e-01],\n",
       "       [9.99406934e-01],\n",
       "       [9.96853352e-01],\n",
       "       [9.87792313e-01],\n",
       "       [4.19320583e-01],\n",
       "       [9.99754071e-01],\n",
       "       [9.39030375e-04],\n",
       "       [8.93588457e-03],\n",
       "       [3.91916983e-04],\n",
       "       [3.51985625e-04],\n",
       "       [9.99873579e-01],\n",
       "       [9.75956440e-01],\n",
       "       [9.96178627e-01],\n",
       "       [3.06425959e-01],\n",
       "       [3.70756239e-02],\n",
       "       [3.69591918e-03],\n",
       "       [4.35136110e-02],\n",
       "       [1.04754651e-02],\n",
       "       [9.99697626e-01],\n",
       "       [2.41730615e-01],\n",
       "       [6.77269325e-02],\n",
       "       [9.99948263e-01],\n",
       "       [9.95463014e-01],\n",
       "       [8.77227366e-01],\n",
       "       [8.71543016e-04],\n",
       "       [1.73423402e-02],\n",
       "       [9.98104870e-01],\n",
       "       [2.89785564e-01],\n",
       "       [3.30343574e-01],\n",
       "       [4.14431058e-02],\n",
       "       [3.06457132e-01],\n",
       "       [5.90655580e-02],\n",
       "       [2.93271313e-03],\n",
       "       [1.60801469e-03],\n",
       "       [9.98492539e-01],\n",
       "       [3.84124070e-02],\n",
       "       [9.99790132e-01],\n",
       "       [9.99708354e-01],\n",
       "       [2.22107675e-03],\n",
       "       [3.24023189e-04],\n",
       "       [9.99535143e-01],\n",
       "       [8.43256363e-04],\n",
       "       [2.95439381e-02],\n",
       "       [3.22821051e-01],\n",
       "       [2.75944709e-03],\n",
       "       [9.98657405e-01],\n",
       "       [1.86977137e-04],\n",
       "       [7.16161216e-03],\n",
       "       [9.99559045e-01],\n",
       "       [1.36679277e-01],\n",
       "       [9.99655128e-01],\n",
       "       [9.99940574e-01],\n",
       "       [1.50017917e-01],\n",
       "       [5.71608427e-04],\n",
       "       [5.64941438e-03],\n",
       "       [8.20476154e-04],\n",
       "       [9.49527384e-05],\n",
       "       [9.99388576e-01],\n",
       "       [9.99806404e-01],\n",
       "       [4.64439332e-01],\n",
       "       [9.99415338e-01],\n",
       "       [5.25834272e-03],\n",
       "       [5.21454029e-02],\n",
       "       [6.59475685e-04],\n",
       "       [1.55477563e-03],\n",
       "       [7.78373040e-04],\n",
       "       [9.99642968e-01],\n",
       "       [1.36361243e-02],\n",
       "       [3.22929613e-04],\n",
       "       [9.99451339e-01],\n",
       "       [6.95995754e-04],\n",
       "       [2.00866302e-03],\n",
       "       [9.99524355e-01],\n",
       "       [4.10777284e-04],\n",
       "       [5.36585972e-02],\n",
       "       [5.97998151e-04],\n",
       "       [9.99623358e-01],\n",
       "       [7.66598523e-01],\n",
       "       [4.83058542e-01],\n",
       "       [5.33826232e-01],\n",
       "       [9.98607457e-01],\n",
       "       [9.09330975e-03],\n",
       "       [9.99624193e-01],\n",
       "       [2.96902042e-02],\n",
       "       [9.10151720e-01],\n",
       "       [9.59180057e-01],\n",
       "       [9.63807642e-01],\n",
       "       [3.17042209e-02],\n",
       "       [2.37503834e-03],\n",
       "       [5.72427273e-01],\n",
       "       [1.01549700e-01],\n",
       "       [3.03682964e-02],\n",
       "       [6.16587652e-03],\n",
       "       [4.61929329e-02],\n",
       "       [1.01430880e-04],\n",
       "       [4.59301565e-03],\n",
       "       [3.85578983e-02],\n",
       "       [9.99870956e-01],\n",
       "       [2.81600910e-03],\n",
       "       [3.95964049e-02],\n",
       "       [1.05932772e-01],\n",
       "       [2.31286481e-01],\n",
       "       [1.33239850e-01],\n",
       "       [2.77442136e-03],\n",
       "       [6.24215871e-04],\n",
       "       [9.99377906e-01],\n",
       "       [2.96385705e-01],\n",
       "       [3.14046979e-01],\n",
       "       [9.99956787e-01],\n",
       "       [8.85538640e-04],\n",
       "       [9.27636921e-01],\n",
       "       [1.27177954e-01],\n",
       "       [5.26730949e-03],\n",
       "       [1.27313167e-01],\n",
       "       [8.61840846e-04],\n",
       "       [4.69797440e-02],\n",
       "       [9.98816609e-01],\n",
       "       [6.98679090e-01],\n",
       "       [9.99706149e-01],\n",
       "       [2.29566574e-01],\n",
       "       [7.80967879e-04],\n",
       "       [9.99815464e-01],\n",
       "       [9.71166592e-04],\n",
       "       [9.99862134e-01],\n",
       "       [1.17751965e-02],\n",
       "       [9.14294831e-03],\n",
       "       [9.99813676e-01],\n",
       "       [8.89203104e-04],\n",
       "       [9.44555213e-04],\n",
       "       [9.99767542e-01],\n",
       "       [1.20689604e-03],\n",
       "       [6.19350653e-03],\n",
       "       [9.56186414e-01],\n",
       "       [9.98341680e-01],\n",
       "       [4.89400467e-04],\n",
       "       [2.58336663e-02],\n",
       "       [9.99631822e-01],\n",
       "       [9.99396086e-01],\n",
       "       [9.99205232e-01],\n",
       "       [1.99728787e-01],\n",
       "       [9.58331704e-01],\n",
       "       [9.96988714e-01],\n",
       "       [1.94841344e-02],\n",
       "       [1.60618697e-03],\n",
       "       [7.13235363e-02],\n",
       "       [9.93529186e-02],\n",
       "       [4.54308785e-04],\n",
       "       [6.75724804e-01],\n",
       "       [2.21989721e-01],\n",
       "       [4.86503937e-04],\n",
       "       [9.99459684e-01],\n",
       "       [9.99863327e-01],\n",
       "       [9.99866903e-01],\n",
       "       [3.29013844e-03],\n",
       "       [2.46413440e-01],\n",
       "       [1.59342527e-01],\n",
       "       [1.73317343e-01],\n",
       "       [9.85234439e-01],\n",
       "       [3.45763385e-01],\n",
       "       [3.51317198e-04],\n",
       "       [5.00788400e-03],\n",
       "       [2.36349064e-03],\n",
       "       [9.98872936e-01],\n",
       "       [1.95825147e-03],\n",
       "       [5.50303888e-03],\n",
       "       [1.35608471e-03],\n",
       "       [2.33976659e-03],\n",
       "       [2.74840504e-01],\n",
       "       [9.78438079e-01],\n",
       "       [9.59551483e-02],\n",
       "       [1.31039228e-03],\n",
       "       [5.07808402e-02],\n",
       "       [4.19107685e-03],\n",
       "       [9.99884546e-01],\n",
       "       [9.98874605e-01],\n",
       "       [5.80780327e-01],\n",
       "       [9.49313700e-01],\n",
       "       [3.78384080e-04],\n",
       "       [9.55250382e-01],\n",
       "       [9.99843478e-01],\n",
       "       [9.68462229e-01],\n",
       "       [1.49921790e-01],\n",
       "       [9.99113619e-01],\n",
       "       [3.30367535e-02],\n",
       "       [9.99897718e-01],\n",
       "       [9.66433715e-03],\n",
       "       [7.19077513e-03],\n",
       "       [2.93970734e-01],\n",
       "       [4.77445237e-02],\n",
       "       [9.99692738e-01],\n",
       "       [1.22796588e-01],\n",
       "       [1.86309946e-04],\n",
       "       [1.51427952e-03],\n",
       "       [3.45763385e-01],\n",
       "       [9.99973297e-01],\n",
       "       [1.64336452e-04],\n",
       "       [2.35858575e-01],\n",
       "       [9.99944329e-01],\n",
       "       [9.03974651e-05],\n",
       "       [9.99898911e-01],\n",
       "       [3.15780751e-03],\n",
       "       [6.08992949e-03],\n",
       "       [8.91590025e-04],\n",
       "       [9.99611199e-01],\n",
       "       [9.99283731e-01],\n",
       "       [4.91907634e-03],\n",
       "       [9.26922483e-04],\n",
       "       [9.98989761e-01],\n",
       "       [9.99816775e-01],\n",
       "       [6.23096883e-01],\n",
       "       [1.30103179e-03],\n",
       "       [7.39298901e-03],\n",
       "       [2.66606748e-01],\n",
       "       [2.67962809e-03],\n",
       "       [9.99904990e-01],\n",
       "       [4.45858926e-01],\n",
       "       [9.99905229e-01],\n",
       "       [9.99736309e-01],\n",
       "       [5.02990782e-02],\n",
       "       [2.44185135e-01],\n",
       "       [1.34038040e-03],\n",
       "       [9.99379873e-01],\n",
       "       [9.94476974e-01],\n",
       "       [9.80290294e-01],\n",
       "       [1.14229051e-02],\n",
       "       [4.30737138e-02],\n",
       "       [5.09318197e-03],\n",
       "       [3.80939688e-04],\n",
       "       [6.68974668e-02],\n",
       "       [4.33977284e-02],\n",
       "       [9.20728564e-01],\n",
       "       [1.30320648e-02],\n",
       "       [9.99930143e-01],\n",
       "       [9.99896884e-01],\n",
       "       [9.33733396e-03],\n",
       "       [7.43340492e-01],\n",
       "       [3.37377675e-02],\n",
       "       [1.32522627e-03],\n",
       "       [3.82794529e-01],\n",
       "       [9.90820944e-01],\n",
       "       [1.24444319e-02],\n",
       "       [1.23680957e-01],\n",
       "       [3.08378047e-04],\n",
       "       [2.25007106e-02],\n",
       "       [6.58908393e-05],\n",
       "       [9.99883533e-01],\n",
       "       [9.97614145e-01],\n",
       "       [9.99830127e-01],\n",
       "       [9.64456439e-01],\n",
       "       [9.38266218e-01],\n",
       "       [3.27999480e-02],\n",
       "       [3.04972171e-04],\n",
       "       [5.90364695e-01],\n",
       "       [9.99122381e-01],\n",
       "       [9.99812722e-01],\n",
       "       [7.32124085e-04],\n",
       "       [1.58070587e-02],\n",
       "       [3.82712972e-03],\n",
       "       [9.99841034e-01],\n",
       "       [9.99805748e-01],\n",
       "       [1.19087438e-03],\n",
       "       [1.80123728e-02],\n",
       "       [9.99922574e-01],\n",
       "       [1.90599151e-02],\n",
       "       [1.64223164e-02],\n",
       "       [9.89281237e-01],\n",
       "       [3.36586381e-03],\n",
       "       [4.15596785e-03],\n",
       "       [9.93288457e-01],\n",
       "       [2.33424440e-01],\n",
       "       [5.62482893e-01],\n",
       "       [9.99952734e-01],\n",
       "       [7.80271599e-04],\n",
       "       [6.39227219e-03],\n",
       "       [1.97343776e-04],\n",
       "       [5.04213618e-04],\n",
       "       [2.43479689e-03],\n",
       "       [9.99825478e-01],\n",
       "       [1.17639673e-03],\n",
       "       [8.27426791e-01],\n",
       "       [7.32494414e-01],\n",
       "       [8.97518545e-02],\n",
       "       [1.85413361e-01],\n",
       "       [1.34963033e-04],\n",
       "       [7.65016582e-03],\n",
       "       [9.99896765e-01],\n",
       "       [9.99434114e-01],\n",
       "       [1.52337784e-02],\n",
       "       [1.49220496e-03],\n",
       "       [2.64542061e-03],\n",
       "       [1.93581660e-03],\n",
       "       [9.97307777e-01],\n",
       "       [2.08392646e-03],\n",
       "       [9.96826530e-01],\n",
       "       [9.98512268e-01],\n",
       "       [8.29594433e-01],\n",
       "       [9.79359508e-01],\n",
       "       [1.84100673e-01],\n",
       "       [4.46142405e-02],\n",
       "       [1.25633394e-02],\n",
       "       [1.07047260e-01],\n",
       "       [8.10388327e-01],\n",
       "       [3.30137640e-01],\n",
       "       [1.69084236e-01],\n",
       "       [1.08118937e-03],\n",
       "       [1.73085558e-04],\n",
       "       [2.57646549e-03],\n",
       "       [1.35090709e-01],\n",
       "       [1.02907248e-01],\n",
       "       [1.34053439e-01],\n",
       "       [9.99906719e-01],\n",
       "       [9.99128938e-01],\n",
       "       [7.68147826e-01],\n",
       "       [9.99721825e-01],\n",
       "       [5.38416319e-02],\n",
       "       [8.53916164e-03],\n",
       "       [9.99440730e-01],\n",
       "       [7.01006595e-03],\n",
       "       [2.26381491e-03],\n",
       "       [1.75659150e-01],\n",
       "       [9.31960404e-01],\n",
       "       [1.74454486e-04],\n",
       "       [9.43671465e-01],\n",
       "       [9.86037791e-01],\n",
       "       [9.98857200e-01],\n",
       "       [9.99724805e-01],\n",
       "       [2.95584872e-02],\n",
       "       [8.62695277e-02],\n",
       "       [9.81820226e-01],\n",
       "       [7.24967394e-04],\n",
       "       [8.16423669e-02],\n",
       "       [2.95469105e-01],\n",
       "       [9.51170802e-01],\n",
       "       [9.37964141e-01],\n",
       "       [6.65362226e-03],\n",
       "       [1.09335836e-02],\n",
       "       [7.37303972e-01],\n",
       "       [3.54187912e-03],\n",
       "       [1.33661786e-02],\n",
       "       [2.42533046e-04],\n",
       "       [3.03478777e-01],\n",
       "       [9.99896586e-01],\n",
       "       [9.97695088e-01],\n",
       "       [1.22362031e-02],\n",
       "       [9.99881923e-01],\n",
       "       [9.99851465e-01],\n",
       "       [2.44691735e-04],\n",
       "       [9.99730408e-01],\n",
       "       [7.04803318e-02],\n",
       "       [9.92509484e-01],\n",
       "       [2.42324844e-01],\n",
       "       [6.71779132e-03],\n",
       "       [1.99039909e-03],\n",
       "       [7.79389520e-04],\n",
       "       [7.81053258e-03],\n",
       "       [5.40390552e-04],\n",
       "       [9.50911343e-01],\n",
       "       [1.50192366e-03],\n",
       "       [9.99795556e-01],\n",
       "       [4.87046037e-03],\n",
       "       [9.85589862e-01],\n",
       "       [8.97103250e-01],\n",
       "       [2.54717446e-03],\n",
       "       [1.24281330e-03],\n",
       "       [9.99945998e-01],\n",
       "       [1.43675804e-02],\n",
       "       [9.99791205e-01],\n",
       "       [2.57191628e-01],\n",
       "       [5.51332273e-02],\n",
       "       [3.45249981e-01],\n",
       "       [4.21997998e-03],\n",
       "       [1.34887099e-01],\n",
       "       [9.99851465e-01],\n",
       "       [3.68474401e-04],\n",
       "       [2.55236751e-03],\n",
       "       [6.45922050e-02],\n",
       "       [9.99848068e-01],\n",
       "       [4.53443006e-02],\n",
       "       [1.91400154e-03],\n",
       "       [9.95189250e-01],\n",
       "       [2.35760366e-04],\n",
       "       [1.09115848e-03],\n",
       "       [3.47829843e-03],\n",
       "       [2.77887046e-01],\n",
       "       [2.01323256e-02],\n",
       "       [2.48164013e-01],\n",
       "       [4.44542527e-01],\n",
       "       [5.16131967e-02],\n",
       "       [5.89542498e-04],\n",
       "       [5.46580590e-02],\n",
       "       [5.83465619e-04],\n",
       "       [9.99202013e-01],\n",
       "       [9.87935722e-01],\n",
       "       [2.11839408e-01],\n",
       "       [6.70409587e-04],\n",
       "       [9.67433210e-03],\n",
       "       [9.99901772e-01],\n",
       "       [9.63554025e-01],\n",
       "       [9.99948382e-01],\n",
       "       [3.20194778e-03],\n",
       "       [9.99338925e-01],\n",
       "       [4.95183514e-03],\n",
       "       [9.77794468e-01],\n",
       "       [9.52109993e-01],\n",
       "       [5.71991026e-04],\n",
       "       [9.99898016e-01],\n",
       "       [3.64447162e-02],\n",
       "       [9.86559391e-01],\n",
       "       [9.99953389e-01],\n",
       "       [4.00377139e-02],\n",
       "       [7.97226268e-04],\n",
       "       [9.83894825e-01],\n",
       "       [9.51161201e-04],\n",
       "       [3.45867090e-02],\n",
       "       [9.99782503e-01],\n",
       "       [3.55331957e-01],\n",
       "       [9.99402225e-01],\n",
       "       [1.22727863e-01],\n",
       "       [9.99609530e-01],\n",
       "       [6.11567676e-01],\n",
       "       [7.47267082e-02],\n",
       "       [5.94431767e-04],\n",
       "       [9.91865039e-01],\n",
       "       [9.97029012e-04],\n",
       "       [1.87165618e-01],\n",
       "       [9.99870420e-01],\n",
       "       [9.95029986e-01],\n",
       "       [9.99889433e-01],\n",
       "       [9.99543250e-01],\n",
       "       [1.79627553e-01],\n",
       "       [9.92861688e-01],\n",
       "       [7.41518626e-04],\n",
       "       [7.86485076e-01],\n",
       "       [9.80922282e-01],\n",
       "       [9.99246716e-01],\n",
       "       [1.82969868e-03],\n",
       "       [9.94481504e-01],\n",
       "       [9.99828577e-01],\n",
       "       [3.02427392e-02],\n",
       "       [1.94387846e-02],\n",
       "       [1.69084236e-01],\n",
       "       [6.62129559e-03],\n",
       "       [6.14132226e-01],\n",
       "       [9.85855401e-01],\n",
       "       [9.99838531e-01],\n",
       "       [9.16386209e-03],\n",
       "       [5.68493211e-04],\n",
       "       [1.08712597e-03],\n",
       "       [1.42874062e-01],\n",
       "       [3.15998052e-03],\n",
       "       [5.51740974e-02],\n",
       "       [9.43416953e-01],\n",
       "       [4.43719618e-04],\n",
       "       [2.48740241e-01],\n",
       "       [3.21703367e-02],\n",
       "       [1.59569904e-01],\n",
       "       [9.99624312e-01],\n",
       "       [2.30688825e-02],\n",
       "       [9.98657703e-01],\n",
       "       [2.45745275e-02],\n",
       "       [1.45738843e-04],\n",
       "       [1.53805048e-03],\n",
       "       [9.99885082e-01],\n",
       "       [7.41263330e-01],\n",
       "       [6.21493557e-04],\n",
       "       [3.08238477e-01],\n",
       "       [2.51093239e-01],\n",
       "       [4.54025256e-04],\n",
       "       [9.99623001e-01],\n",
       "       [9.51355416e-03],\n",
       "       [9.83450890e-01],\n",
       "       [2.97832966e-01],\n",
       "       [2.23199860e-03],\n",
       "       [4.21127439e-01],\n",
       "       [2.85781711e-01],\n",
       "       [4.48736250e-02],\n",
       "       [9.99832273e-01],\n",
       "       [9.63164791e-02],\n",
       "       [2.71294385e-01],\n",
       "       [9.99543369e-01],\n",
       "       [5.01923203e-01],\n",
       "       [3.11117411e-01],\n",
       "       [1.74454486e-04],\n",
       "       [2.40271971e-01],\n",
       "       [7.33436525e-01],\n",
       "       [9.99898911e-01],\n",
       "       [9.92158055e-01],\n",
       "       [2.26505399e-02],\n",
       "       [9.99864876e-01],\n",
       "       [1.68725431e-01],\n",
       "       [9.99649942e-01],\n",
       "       [1.68725431e-01],\n",
       "       [9.99886453e-01],\n",
       "       [2.57257459e-04],\n",
       "       [3.06683220e-02],\n",
       "       [2.79764412e-04],\n",
       "       [9.99915898e-01],\n",
       "       [6.16974663e-03],\n",
       "       [1.68089662e-02],\n",
       "       [7.93870597e-04],\n",
       "       [1.51145570e-02],\n",
       "       [1.71761028e-03],\n",
       "       [3.87354335e-03],\n",
       "       [5.20607643e-02],\n",
       "       [7.80313089e-03],\n",
       "       [1.36244949e-02],\n",
       "       [9.99267876e-01],\n",
       "       [3.85147450e-03],\n",
       "       [4.76810001e-02],\n",
       "       [3.75918532e-03],\n",
       "       [4.13684640e-04],\n",
       "       [1.09907292e-01],\n",
       "       [9.96552467e-01],\n",
       "       [7.78193912e-03],\n",
       "       [7.81369284e-02],\n",
       "       [1.83398984e-02],\n",
       "       [9.99053001e-01],\n",
       "       [9.99675333e-01],\n",
       "       [1.74666126e-03],\n",
       "       [7.13473011e-04],\n",
       "       [9.96360439e-04],\n",
       "       [9.76892261e-05],\n",
       "       [9.99843955e-01],\n",
       "       [4.13684640e-04],\n",
       "       [1.16893537e-01],\n",
       "       [9.97960269e-01],\n",
       "       [9.99821246e-01],\n",
       "       [9.99819398e-01],\n",
       "       [9.99949753e-01],\n",
       "       [9.99988139e-01],\n",
       "       [2.05664337e-03],\n",
       "       [2.88540992e-04],\n",
       "       [7.18801990e-02],\n",
       "       [9.93908107e-01],\n",
       "       [9.99901772e-01],\n",
       "       [9.43233907e-01],\n",
       "       [2.26333775e-02],\n",
       "       [9.98766422e-01],\n",
       "       [6.57855272e-01],\n",
       "       [2.76312727e-04],\n",
       "       [6.99189608e-04],\n",
       "       [2.16140728e-02],\n",
       "       [5.03454059e-02],\n",
       "       [3.06498667e-04],\n",
       "       [1.38695491e-02],\n",
       "       [9.95391488e-01],\n",
       "       [9.99929070e-01],\n",
       "       [1.63439254e-03],\n",
       "       [9.99753892e-01],\n",
       "       [6.94158852e-01],\n",
       "       [6.79889321e-02],\n",
       "       [4.06674594e-02],\n",
       "       [8.87250528e-02],\n",
       "       [7.18318224e-01],\n",
       "       [7.83237070e-02],\n",
       "       [4.06696199e-04]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meking predictions\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting model 3 pred probs to label format\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.42782152230971,\n",
       " 'precision': 0.7757380419380466,\n",
       " 'recall': 0.7742782152230971,\n",
       " 'f1': 0.7723566516531356}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 3 results\n",
    "model_3_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_3_preds\n",
    ")\n",
    "model_3_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 - Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_bidir\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              98816     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model details\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_4.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_bidir/20230116-103211\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 22ms/step - loss: 0.1056 - accuracy: 0.9682 - val_loss: 0.9006 - val_accuracy: 0.7730\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0525 - accuracy: 0.9781 - val_loss: 1.1231 - val_accuracy: 0.7717\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0440 - accuracy: 0.9787 - val_loss: 1.4404 - val_accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0430 - accuracy: 0.9801 - val_loss: 1.5227 - val_accuracy: 0.7756\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.0426 - accuracy: 0.9812 - val_loss: 1.2675 - val_accuracy: 0.7743\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_4 = model_4.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_4_bidir\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.2413623e-01],\n",
       "       [6.3701016e-01],\n",
       "       [9.9989742e-01],\n",
       "       [1.3428456e-01],\n",
       "       [1.6744674e-05],\n",
       "       [9.9727756e-01],\n",
       "       [8.9310348e-01],\n",
       "       [9.9995303e-01],\n",
       "       [9.9972731e-01],\n",
       "       [9.6627390e-01]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting model's probs to the label format\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.42782152230971,\n",
       " 'precision': 0.7745797612274115,\n",
       " 'recall': 0.7742782152230971,\n",
       " 'f1': 0.7730386111374632}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking results of predictions\n",
    "model_4_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_4_preds\n",
    ")\n",
    "model_4_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 - Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing embedding layer\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding_test = embedding(text_vectorizer(\"This is a test sentence\"))\n",
    "# print(embedding_test.shape)\n",
    "embedding_test = tf.expand_dims(embedding_test, axis=0)\n",
    "# print(embedding_test.shape)\n",
    "conv_1d = layers.Conv1D(\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    activation=\"relu\",\n",
    "    padding=\"valid\"\n",
    ")\n",
    "conv_1d_output = conv_1d(embedding_test)\n",
    "max_pool = layers.GlobalMaxPool1D()\n",
    "max_pool_output = max_pool(conv_1d_output)\n",
    "\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 - 1D Convolutional Network layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"input_layer\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Conv1D(\n",
    "    filters=64,\n",
    "    kernel_size=5,\n",
    "    strides=1,\n",
    "    activation=\"relu\",\n",
    "    padding=\"valid\"\n",
    ")(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_conv1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5_conv1d\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321,089\n",
      "Trainable params: 1,321,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model details\n",
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_5.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_conv1d/20230116-103237\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 14ms/step - loss: 0.1226 - accuracy: 0.9622 - val_loss: 0.9535 - val_accuracy: 0.7717\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0765 - accuracy: 0.9717 - val_loss: 1.0210 - val_accuracy: 0.7664\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0610 - accuracy: 0.9766 - val_loss: 1.1577 - val_accuracy: 0.7651\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0554 - accuracy: 0.9791 - val_loss: 1.1890 - val_accuracy: 0.7585\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0504 - accuracy: 0.9788 - val_loss: 1.2463 - val_accuracy: 0.7572\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_5 = model_5.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_5_conv1d\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.89870685e-01],\n",
       "       [8.83843005e-01],\n",
       "       [9.99887943e-01],\n",
       "       [1.09054685e-01],\n",
       "       [1.31184677e-07],\n",
       "       [9.96619225e-01],\n",
       "       [9.56514895e-01],\n",
       "       [9.99980628e-01],\n",
       "       [9.99997675e-01],\n",
       "       [8.88097584e-01]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_5_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting probs into label format\n",
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.7217847769029,\n",
       " 'precision': 0.7576149234046069,\n",
       " 'recall': 0.7572178477690289,\n",
       " 'f1': 0.7555947144839635}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model's predictions\n",
    "model_5_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_5_preds\n",
    ")\n",
    "model_5_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6 - TensorflowHub pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01602832  0.01068848  0.02425467 -0.01405769  0.01434426  0.08292625\n",
      "  0.01963372  0.06160142 -0.00352702 -0.01216412  0.00978647 -0.01248495\n",
      "  0.01232345  0.09748451  0.06141113 -0.03728353  0.01860884 -0.04669856\n",
      "  0.00413913 -0.06363907 -0.02469898  0.02713691  0.02284444 -0.00210026\n",
      " -0.00630592 -0.03964961  0.02220404  0.00115077 -0.03132177  0.00119527\n",
      " -0.0401255   0.04561892 -0.01530598 -0.00175918  0.02173131 -0.08450424\n",
      "  0.03340026  0.04604554 -0.0248025  -0.08681665  0.00702694 -0.00770478\n",
      " -0.01434539  0.07814164 -0.10676058 -0.05152997 -0.00858155 -0.03232232\n",
      " -0.03871097  0.02581467], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Reusing USE (Universal Sentence Encoder) model\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "embed_samples = embed([\n",
    "    sample_sentence,\n",
    "    \"When you apple USE to text, it converts it into numbers\"\n",
    "])\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling shape\n",
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "# Creating layer with USE pretrained model\n",
    "sentence_encoder_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "    input_shape=[],\n",
    "    dtype=tf.string,\n",
    "    trainable=False,\n",
    "    name=\"USE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a new model with pretrained layer\n",
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    # layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model_6.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_6_use/20230116-103312\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 17ms/step - loss: 0.6493 - accuracy: 0.7306 - val_loss: 0.6154 - val_accuracy: 0.7651\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.5820 - accuracy: 0.7840 - val_loss: 0.5660 - val_accuracy: 0.7743\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.5392 - accuracy: 0.7904 - val_loss: 0.5338 - val_accuracy: 0.7795\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.5106 - accuracy: 0.7961 - val_loss: 0.5127 - val_accuracy: 0.7848\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.4905 - accuracy: 0.7990 - val_loss: 0.4985 - val_accuracy: 0.7861\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_6 = model_6.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_6_use\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_use\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,798,337\n",
      "Trainable params: 513\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking the model details\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.37535816],\n",
       "       [0.68599105],\n",
       "       [0.858224  ],\n",
       "       [0.33574876],\n",
       "       [0.64923936],\n",
       "       [0.72946644],\n",
       "       [0.81911504],\n",
       "       [0.83147806],\n",
       "       [0.75724036],\n",
       "       [0.20284742]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting prediction probs into label format\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.60892388451444,\n",
       " 'precision': 0.7863431959164349,\n",
       " 'recall': 0.7860892388451444,\n",
       " 'f1': 0.7850582651599072}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating model's performance metrics\n",
    "model_6_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_6_preds\n",
    ")\n",
    "model_6_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 - Pretrained USE with 10% of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761, 761)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## THIS IS WRONG WAY TO SPLIT, because of potential data leak,\n",
    "##  i.e. some data may end up in validation seubset\n",
    "\n",
    "# Creating subset of 10% training data\n",
    "train_data_10p = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
    "train_sentences_10p = train_data_10p[\"text\"].to_list()\n",
    "train_labels_10p = train_data_10p[\"target\"].to_list()\n",
    "len(train_sentences_10p), len(train_labels_10p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685, 685)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MAKING A BETTER SPLIT\n",
    "\n",
    "# Creating 10% subset\n",
    "train_10p_split = int(0.1 * len(train_sentences))\n",
    "train_sentences_10p = train_sentences[:train_10p_split]\n",
    "train_labels_10p = train_labels[:train_10p_split]\n",
    "len(train_sentences_10p), len(train_labels_10p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7613"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the length of original dataset\n",
    "len(train_df_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    413\n",
       "1    348\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of targets - 10%\n",
    "train_data_10p[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of targets - Full set\n",
    "train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_use\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,798,337\n",
      "Trainable params: 513\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Cloning model 6\n",
    "model_7 = tf.keras.models.clone_model(model_6)\n",
    "\n",
    "# Compiling the model\n",
    "model_7.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Checking the model details\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_7_use/20230116-184029\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 8s 94ms/step - loss: 0.6909 - accuracy: 0.5285 - val_loss: 0.6875 - val_accuracy: 0.5761\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.6776 - accuracy: 0.6993 - val_loss: 0.6785 - val_accuracy: 0.6601\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.6655 - accuracy: 0.7547 - val_loss: 0.6696 - val_accuracy: 0.6995\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.6544 - accuracy: 0.7723 - val_loss: 0.6611 - val_accuracy: 0.7008\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 0.6435 - accuracy: 0.7854 - val_loss: 0.6530 - val_accuracy: 0.7192\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "history_7 = model_7.fit(\n",
    "    train_sentences_10p,\n",
    "    train_labels_10p,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_7_use\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.46963853],\n",
       "       [0.5124494 ],\n",
       "       [0.57981694],\n",
       "       [0.47460523],\n",
       "       [0.50114006],\n",
       "       [0.51902497],\n",
       "       [0.54269725],\n",
       "       [0.49833354],\n",
       "       [0.52545536],\n",
       "       [0.45071054]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions\n",
    "model_7_pred_probs = model_7.predict(val_sentences)\n",
    "model_7_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 0., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting pred probs to label format\n",
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
    "model_7_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 71.91601049868767,\n",
       " 'precision': 0.730288919910709,\n",
       " 'recall': 0.7191601049868767,\n",
       " 'f1': 0.7101609145220378}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating model predictions\n",
    "model_7_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=model_7_preds\n",
    ")\n",
    "model_7_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing performance of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_baseline</th>\n",
       "      <td>79.265092</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>78.477690</td>\n",
       "      <td>0.790955</td>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.781292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_lstm</th>\n",
       "      <td>77.952756</td>\n",
       "      <td>0.779907</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.778317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_gru</th>\n",
       "      <td>77.427822</td>\n",
       "      <td>0.775738</td>\n",
       "      <td>0.774278</td>\n",
       "      <td>0.772357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_bidirectional</th>\n",
       "      <td>77.427822</td>\n",
       "      <td>0.774580</td>\n",
       "      <td>0.774278</td>\n",
       "      <td>0.773039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_conv1d</th>\n",
       "      <td>75.721785</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.757218</td>\n",
       "      <td>0.755595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tfhub_use</th>\n",
       "      <td>78.608924</td>\n",
       "      <td>0.786343</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.785058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tfhub_use10p</th>\n",
       "      <td>71.916010</td>\n",
       "      <td>0.730289</td>\n",
       "      <td>0.719160</td>\n",
       "      <td>0.710161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  accuracy  precision    recall        f1\n",
       "0_baseline       79.265092   0.811139  0.792651  0.786219\n",
       "1_simple_dense   78.477690   0.790955  0.784777  0.781292\n",
       "2_lstm           77.952756   0.779907  0.779528  0.778317\n",
       "3_gru            77.427822   0.775738  0.774278  0.772357\n",
       "4_bidirectional  77.427822   0.774580  0.774278  0.773039\n",
       "5_conv1d         75.721785   0.757615  0.757218  0.755595\n",
       "6_tfhub_use      78.608924   0.786343  0.786089  0.785058\n",
       "7_tfhub_use10p   71.916010   0.730289  0.719160  0.710161"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining model results into a single dataframe\n",
    "all_model_results = pd.DataFrame({\n",
    "    \"0_baseline\": baseline_results,\n",
    "    \"1_simple_dense\": model_1_results,\n",
    "    \"2_lstm\": model_2_results,\n",
    "    \"3_gru\": model_3_results,\n",
    "    \"4_bidirectional\": model_4_results,\n",
    "    \"5_conv1d\": model_5_results,\n",
    "    \"6_tfhub_use\": model_6_results,\n",
    "    \"7_tfhub_use10p\": model_7_results\n",
    "})\n",
    "\n",
    "all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.790955</td>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.781292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_lstm</th>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.779907</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.778317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_gru</th>\n",
       "      <td>0.774278</td>\n",
       "      <td>0.775738</td>\n",
       "      <td>0.774278</td>\n",
       "      <td>0.772357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_bidirectional</th>\n",
       "      <td>0.774278</td>\n",
       "      <td>0.774580</td>\n",
       "      <td>0.774278</td>\n",
       "      <td>0.773039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_conv1d</th>\n",
       "      <td>0.757218</td>\n",
       "      <td>0.757615</td>\n",
       "      <td>0.757218</td>\n",
       "      <td>0.755595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tfhub_use</th>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.786343</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.785058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tfhub_use10p</th>\n",
       "      <td>0.719160</td>\n",
       "      <td>0.730289</td>\n",
       "      <td>0.719160</td>\n",
       "      <td>0.710161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 accuracy  precision    recall        f1\n",
       "0_baseline       0.792651   0.811139  0.792651  0.786219\n",
       "1_simple_dense   0.784777   0.790955  0.784777  0.781292\n",
       "2_lstm           0.779528   0.779907  0.779528  0.778317\n",
       "3_gru            0.774278   0.775738  0.774278  0.772357\n",
       "4_bidirectional  0.774278   0.774580  0.774278  0.773039\n",
       "5_conv1d         0.757218   0.757615  0.757218  0.755595\n",
       "6_tfhub_use      0.786089   0.786343  0.786089  0.785058\n",
       "7_tfhub_use10p   0.719160   0.730289  0.719160  0.710161"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting accuracy scale\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"] / 100\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19e2b1022b0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all model results\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising F1 score\n",
    "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8230a386d8e0083990873cddb8ebb5b6213275a10339230a8504f0ef8ce7f888"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
